{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [DataCamp Course](https://www.datacamp.com/courses/machine-learning-with-tree-based-models-in-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Classification-tree in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Import accuracy_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'indian_liver_patient_preprocessed.csv'\n",
    "data = pd.read_csv(url, index_col=0)\n",
    "\n",
    "X = data.drop(labels=['Total_Bilirubin_std',\n",
    "                      'Liver_disease',\n",
    "                     'Direct_Bilirubin_std',\n",
    "                     'Alkaline_Phosphotase_std',\n",
    "                     'Alamine_Aminotransferase_std',\n",
    "                     'Aspartate_Aminotransferase_std',\n",
    "                     'Albumin_std',\n",
    "                     'Albumin_and_Globulin_Ratio_std',\n",
    "                     'Is_male_std'], axis=1)\n",
    "y = data.Liver_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_std</th>\n",
       "      <th>Total_Bilirubin_std</th>\n",
       "      <th>Direct_Bilirubin_std</th>\n",
       "      <th>Alkaline_Phosphotase_std</th>\n",
       "      <th>Alamine_Aminotransferase_std</th>\n",
       "      <th>Aspartate_Aminotransferase_std</th>\n",
       "      <th>Total_Protiens_std</th>\n",
       "      <th>Albumin_std</th>\n",
       "      <th>Albumin_and_Globulin_Ratio_std</th>\n",
       "      <th>Is_male_std</th>\n",
       "      <th>Liver_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.247403</td>\n",
       "      <td>-0.420320</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>-0.355832</td>\n",
       "      <td>-0.319111</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>1.218936</td>\n",
       "      <td>1.423518</td>\n",
       "      <td>1.675083</td>\n",
       "      <td>-0.093573</td>\n",
       "      <td>-0.035962</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>-0.648461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>0.640375</td>\n",
       "      <td>0.926017</td>\n",
       "      <td>0.816243</td>\n",
       "      <td>-0.115428</td>\n",
       "      <td>-0.146459</td>\n",
       "      <td>0.478274</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.178707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815511</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.388807</td>\n",
       "      <td>-0.449416</td>\n",
       "      <td>-0.366760</td>\n",
       "      <td>-0.312205</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.679294</td>\n",
       "      <td>0.093956</td>\n",
       "      <td>0.179766</td>\n",
       "      <td>-0.395996</td>\n",
       "      <td>-0.295731</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>-0.930414</td>\n",
       "      <td>-1.713237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age_std  Total_Bilirubin_std  Direct_Bilirubin_std  \\\n",
       "0  1.247403            -0.420320             -0.495414   \n",
       "1  1.062306             1.218936              1.423518   \n",
       "2  1.062306             0.640375              0.926017   \n",
       "3  0.815511            -0.372106             -0.388807   \n",
       "4  1.679294             0.093956              0.179766   \n",
       "\n",
       "   Alkaline_Phosphotase_std  Alamine_Aminotransferase_std  \\\n",
       "0                 -0.428870                     -0.355832   \n",
       "1                  1.675083                     -0.093573   \n",
       "2                  0.816243                     -0.115428   \n",
       "3                 -0.449416                     -0.366760   \n",
       "4                 -0.395996                     -0.295731   \n",
       "\n",
       "   Aspartate_Aminotransferase_std  Total_Protiens_std  Albumin_std  \\\n",
       "0                       -0.319111            0.293722     0.203446   \n",
       "1                       -0.035962            0.939655     0.077462   \n",
       "2                       -0.146459            0.478274     0.203446   \n",
       "3                       -0.312205            0.293722     0.329431   \n",
       "4                       -0.177537            0.755102    -0.930414   \n",
       "\n",
       "   Albumin_and_Globulin_Ratio_std  Is_male_std  Liver_disease  \n",
       "0                       -0.147390            0              1  \n",
       "1                       -0.648461            1              1  \n",
       "2                       -0.178707            1              1  \n",
       "3                        0.165780            1              1  \n",
       "4                       -1.713237            1              1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 579 entries, 0 to 582\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Age_std             579 non-null    float64\n",
      " 1   Total_Protiens_std  579 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 13.6 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   stratify=y,\n",
    "                                                   random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6724137931034483"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "# Evaluate test-set accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Regions\n",
    "region in the feature space where all instances are assigned to one class label\n",
    "## Decision Boundary\n",
    "surface separating different decision regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
    "dt = DecisionTreeClassifier(max_depth=6, random_state=1)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "print(y_pred[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Compute test set accuracy  \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy: {:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression vs classification tree\n",
    "\n",
    "A classification tree divides the feature space into rectangular regions. In contrast, a linear model such as logistic regression produces only a single linear decision boundary dividing the feature space into two decision regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_regions(X, y, clf,\n",
    "                          feature_index=None,\n",
    "                          filler_feature_values=None,\n",
    "                          filler_feature_ranges=None,\n",
    "                          ax=None,\n",
    "                          X_highlight=None,\n",
    "                          res=0.02, legend=1,\n",
    "                          hide_spines=True,\n",
    "                          markers='s^oxv<>',\n",
    "                          colors='red,blue,limegreen,gray,cyan'):\n",
    "                              \"\"\"Plot decision regions of a classifier.\n",
    "                          \n",
    "                              Please note that this functions assumes that class labels are\n",
    "                              labeled consecutively, e.g,. 0, 1, 2, 3, 4, and 5. If you have class\n",
    "                              labels with integer labels > 4, you may want to provide additional colors\n",
    "                              and/or markers as `colors` and `markers` arguments.\n",
    "                              See http://matplotlib.org/examples/color/named_colors.html for more\n",
    "                              information.\n",
    "                          \n",
    "                              Parameters\n",
    "                              ----------\n",
    "                              X : array-like, shape = [n_samples, n_features]\n",
    "                                  Feature Matrix.\n",
    "                              y : array-like, shape = [n_samples]\n",
    "                                  True class labels.\n",
    "                              clf : Classifier object.\n",
    "                                  Must have a .predict method.\n",
    "                              feature_index : array-like (default: (0,) for 1D, (0, 1) otherwise)\n",
    "                                  Feature indices to use for plotting. The first index in\n",
    "                                  `feature_index` will be on the x-axis, the second index will be\n",
    "                                  on the y-axis.\n",
    "                              filler_feature_values : dict (default: None)\n",
    "                                  Only needed for number features > 2. Dictionary of feature\n",
    "                                  index-value pairs for the features not being plotted.\n",
    "                              filler_feature_ranges : dict (default: None)\n",
    "                                  Only needed for number features > 2. Dictionary of feature\n",
    "                                  index-value pairs for the features not being plotted. Will use the\n",
    "                                  ranges provided to select training samples for plotting.\n",
    "                              ax : matplotlib.axes.Axes (default: None)\n",
    "                                  An existing matplotlib Axes. Creates\n",
    "                                  one if ax=None.\n",
    "                              X_highlight : array-like, shape = [n_samples, n_features] (default: None)\n",
    "                                  An array with data points that are used to highlight samples in `X`.\n",
    "                              res : float or array-like, shape = (2,) (default: 0.02)\n",
    "                                  Grid width. If float, same resolution is used for both the x- and\n",
    "                                  y-axis. If array-like, the first item is used on the x-axis, the\n",
    "                                  second is used on the y-axis. Lower values increase the resolution but\n",
    "                                  slow down the plotting.\n",
    "                              hide_spines : bool (default: True)\n",
    "                                  Hide axis spines if True.\n",
    "                              legend : int (default: 1)\n",
    "                                  Integer to specify the legend location.\n",
    "                                  No legend if legend is 0.\n",
    "                              markers : str (default \\'s^oxv<>\\')\n",
    "                                  Scatterplot markers.\n",
    "                              colors : str (default \\'red,blue,limegreen,gray,cyan\\')\n",
    "                                  Comma separated list of colors.\n",
    "                          \n",
    "                              Returns\n",
    "                              ---------\n",
    "                              ax : matplotlib.axes.Axes object\n",
    "                          \n",
    "                              \"\"\"\n",
    "                          \n",
    "                              # check_Xy(X, y, y_int=True)  # Validate X and y arrays\n",
    "                              dim = X.shape[1]\n",
    "                          \n",
    "                              if ax is None:\n",
    "                                  ax = plt.gca()\n",
    "                          \n",
    "                              if isinstance(res, float):\n",
    "                                  xres, yres = res, res\n",
    "                              else:\n",
    "                                  try:\n",
    "                                      xres, yres = res\n",
    "                                  except ValueError:\n",
    "                                      raise ValueError('Unable to unpack res. Expecting \\\n",
    "                                                       array-like input of length 2.')\n",
    "                          \n",
    "                              plot_testdata = True\n",
    "                              if not isinstance(X_highlight, np.ndarray):\n",
    "                                  if X_highlight is not None:\n",
    "                                      raise ValueError('X_highlight must be a NumPy array or None')\n",
    "                                  else:\n",
    "                                      plot_testdata = False\n",
    "                              elif len(X_highlight.shape) < 2:\n",
    "                                  raise ValueError('X_highlight must be a 2D array')\n",
    "                          \n",
    "                              if feature_index is not None:\n",
    "                                  # Unpack and validate the feature_index values\n",
    "                                  if dim == 1:\n",
    "                                      raise ValueError(\n",
    "                                          'feature_index requires more than one training feature')\n",
    "                                  try:\n",
    "                                      x_index, y_index = feature_index\n",
    "                                  except ValueError:\n",
    "                                      raise ValueError(\n",
    "                                          'Unable to unpack feature_index. Make sure feature_index \\\n",
    "                                          only has two dimensions.')\n",
    "                                  try:\n",
    "                                      X[:, x_index], X[:, y_index]\n",
    "                                  except IndexError:\n",
    "                                      raise IndexError(\n",
    "                                          'feature_index values out of range. X.shape is {}, but \\\n",
    "                                          feature_index is {}'.format(X.shape, feature_index))\n",
    "                              else:\n",
    "                                  feature_index = (0, 1)\n",
    "                                  x_index, y_index = feature_index\n",
    "                          \n",
    "                              # Extra input validation for higher number of training features\n",
    "                              if dim > 2:\n",
    "                                  if filler_feature_values is None:\n",
    "                                      raise ValueError('Filler values must be provided when \\\n",
    "                                                       X has more than 2 training features.')\n",
    "                          \n",
    "                                  if filler_feature_ranges is not None:\n",
    "                                      if not set(filler_feature_values) == set(filler_feature_ranges):\n",
    "                                          raise ValueError(\n",
    "                                              'filler_feature_values and filler_feature_ranges must \\\n",
    "                                              have the same keys')\n",
    "                          \n",
    "                                  # Check that all columns in X are accounted for\n",
    "                                  column_check = np.zeros(dim, dtype=bool)\n",
    "                                  for idx in filler_feature_values:\n",
    "                                      column_check[idx] = True\n",
    "                                  for idx in feature_index:\n",
    "                                      column_check[idx] = True\n",
    "                                  if not all(column_check):\n",
    "                                      missing_cols = np.argwhere(~column_check).flatten()\n",
    "                                      raise ValueError(\n",
    "                                          'Column(s) {} need to be accounted for in either \\\n",
    "                                          feature_index or filler_feature_values'.format(missing_cols))\n",
    "                          \n",
    "                              marker_gen = cycle(list(markers))\n",
    "                          \n",
    "                              n_classes = np.unique(y).shape[0]\n",
    "                              colors = colors.split(',')\n",
    "                              colors_gen = cycle(colors)\n",
    "                              colors = [next(colors_gen) for c in range(n_classes)]\n",
    "                          \n",
    "                              # Get minimum and maximum\n",
    "                              x_min, x_max = X[:, x_index].min() - 1, X[:, x_index].max() + 1\n",
    "                              if dim == 1:\n",
    "                                  y_min, y_max = -1, 1\n",
    "                              else:\n",
    "                                  y_min, y_max = X[:, y_index].min() - 1, X[:, y_index].max() + 1\n",
    "                          \n",
    "                              xx, yy = np.meshgrid(np.arange(x_min, x_max, xres),\n",
    "                                                   np.arange(y_min, y_max, yres))\n",
    "                          \n",
    "                              if dim == 1:\n",
    "                                  X_predict = np.array([xx.ravel()]).T\n",
    "                              else:\n",
    "                                  X_grid = np.array([xx.ravel(), yy.ravel()]).T\n",
    "                                  X_predict = np.zeros((X_grid.shape[0], dim))\n",
    "                                  X_predict[:, x_index] = X_grid[:, 0]\n",
    "                                  X_predict[:, y_index] = X_grid[:, 1]\n",
    "                                  if dim > 2:\n",
    "                                      for feature_idx in filler_feature_values:\n",
    "                                          X_predict[:, feature_idx] = filler_feature_values[feature_idx]\n",
    "                              Z = clf.predict(X_predict)\n",
    "                              Z = Z.reshape(xx.shape)\n",
    "                              # Plot decision region\n",
    "                              ax.contourf(xx, yy, Z,\n",
    "                                          alpha=0.3,\n",
    "                                          colors=colors,\n",
    "                                          levels=np.arange(Z.max() + 2) - 0.5)\n",
    "                              # ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n",
    "                              ax.axis([xx.min(), xx.max(), yy.min(), yy.max()])\n",
    "                          \n",
    "                              # Scatter training data samples\n",
    "                              for idx, c in enumerate(np.unique(y)):\n",
    "                                  if dim == 1:\n",
    "                                      y_data = [0 for i in X[y == c]]\n",
    "                                      x_data = X[y == c]\n",
    "                                  elif dim == 2:\n",
    "                                      y_data = X[y == c, y_index]\n",
    "                                      x_data = X[y == c, x_index]\n",
    "                                  elif dim > 2 and filler_feature_ranges is not None:\n",
    "                                      class_mask = y == c\n",
    "                                      feature_range_mask = get_feature_range_mask(\n",
    "                                                      X, filler_feature_values=filler_feature_values,\n",
    "                                                      filler_feature_ranges=filler_feature_ranges)\n",
    "                                      y_data = X[class_mask & feature_range_mask, y_index]\n",
    "                                      x_data = X[class_mask & feature_range_mask, x_index]\n",
    "                                  else:\n",
    "                                      continue\n",
    "                          \n",
    "                                  ax.scatter(x=x_data,\n",
    "                                             y=y_data,\n",
    "                                             alpha=0.8,\n",
    "                                             c=colors[idx],\n",
    "                                             marker=next(marker_gen),\n",
    "                                             edgecolor='black',\n",
    "                                             label=c)\n",
    "                          \n",
    "                              if hide_spines:\n",
    "                                  ax.spines['right'].set_visible(False)\n",
    "                                  ax.spines['top'].set_visible(False)\n",
    "                                  ax.spines['left'].set_visible(False)\n",
    "                                  ax.spines['bottom'].set_visible(False)\n",
    "                              ax.yaxis.set_ticks_position('left')\n",
    "                              ax.xaxis.set_ticks_position('bottom')\n",
    "                              if dim == 1:\n",
    "                                  ax.axes.get_yaxis().set_ticks([])\n",
    "                          \n",
    "                              if legend:\n",
    "                                  if dim > 2 and filler_feature_ranges is None:\n",
    "                                      pass\n",
    "                                  else:\n",
    "                                      handles, labels = ax.get_legend_handles_labels()\n",
    "                                      ax.legend(handles, labels,\n",
    "                                                framealpha=0.3, scatterpoints=1, loc=legend)\n",
    "                          \n",
    "                              if plot_testdata:\n",
    "                                  if dim == 1:\n",
    "                                      x_data = X_highlight\n",
    "                                      y_data = [0 for i in X_highlight]\n",
    "                                  elif dim == 2:\n",
    "                                      x_data = X_highlight[:, x_index]\n",
    "                                      y_data = X_highlight[:, y_index]\n",
    "                                  else:\n",
    "                                      feature_range_mask = get_feature_range_mask(\n",
    "                                              X_highlight, filler_feature_values=filler_feature_values,\n",
    "                                              filler_feature_ranges=filler_feature_ranges)\n",
    "                                      y_data = X_highlight[feature_range_mask, y_index]\n",
    "                                      x_data = X_highlight[feature_range_mask, x_index]\n",
    "                          \n",
    "                                  ax.scatter(x_data,\n",
    "                                             y_data,\n",
    "                                             c='',\n",
    "                                             edgecolor='black',\n",
    "                                             alpha=1.0,\n",
    "                                             linewidths=1,\n",
    "                                             marker='o',\n",
    "                                             s=80)\n",
    "                          \n",
    "                              return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_labeled_decision_regions(X,y, models):\n",
    "    '''Function producing a scatter plot of the instances contained\n",
    "    in the 2D dataset (X,y) along with the decision\n",
    "    regions of two trained classification models contained in the\n",
    "    list 'models'.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pandas DataFrame corresponding to two numerical features\n",
    "    y: pandas Series corresponding the class labels\n",
    "    models: list containing two trained classifiers\n",
    "    \n",
    "    '''\n",
    "    if len(models) != 2:\n",
    "        raise Exception('''\n",
    "        Models should be a list containing only two trained classifiers.\n",
    "        ''')\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        raise Exception('''\n",
    "        X has to be a pandas DataFrame with two numerical features.\n",
    "        ''')\n",
    "    if not isinstance(y, pd.Series):\n",
    "        raise Exception('''\n",
    "        y has to be a pandas Series corresponding to the labels.\n",
    "        ''')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(6.0,2.7), sharey=True)\n",
    "    for i, model in enumerate(models):\n",
    "        plot_decision_regions(X.values,y.values, model, legend= 2, ax = ax[i])\n",
    "        ax[i].set_title(model.__class__.__name__)\n",
    "        ax[i].set_xlabel(X.columns[0])\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel(X.columns[1])\n",
    "        ax[i].set_ylim(X.values[:,1].min(), X.values[:,1].max())\n",
    "        ax[i].set_xlim(X.values[:,0].min(), X.values[:,0].max())\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression from sklearn.linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x194.4 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 202,
       "width": 364
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instatiate logreg\n",
    "logreg = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit logreg to the training set\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Define a list called clfs containing the two classifiers logreg and dt\n",
    "clfs = [logreg, dt]\n",
    "\n",
    "# Review the decision regions of the two classifiers\n",
    "plot_labeled_decision_regions(X_test, y_test, clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision-Tree\n",
    "\n",
    "Data structure consisting of a hierarchy of nodes\n",
    "\n",
    "## Node\n",
    "\n",
    "question or prediction\n",
    "\n",
    "## Root\n",
    "\n",
    "_no_ parent node, question giving rise to _two_ children nodes\n",
    "\n",
    "## Internal node\n",
    "\n",
    "_one_ parent node, question giving rise to _two_ children nodes\n",
    "\n",
    "## Leaf\n",
    "\n",
    "_one_ parent node, _no_ children nodes. This is where predictions are made\n",
    "\n",
    "## Information Gain (IG)\n",
    "\n",
    "How does the algorithm know which feature and which split-point to choose? It does so by maximizing information gain. The tree considers that each node contains information and aims at maximizing the information gain after each split. \n",
    "\n",
    "- The existence of a node depends on the state of its predecessors.\n",
    "- The impurity of a node can be determined using different criteria such as entropy and the gini-index.\n",
    "- When the information gain resulting from splitting a node is null, the node is declared as a leaf.\n",
    "- When an internal node is split, the split is performed in such a way so that information gain is maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = pd.read_csv('wbc.csv', index_col=0)\n",
    "y = breast_cancer.diagnosis\n",
    "\n",
    "mapping = {'M':1, 'B':0}\n",
    "y = y.map(mapping)\n",
    "\n",
    "X = breast_cancer.drop('diagnosis', axis=1)\n",
    "X = X.iloc[:, :30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                         \n",
       "842302           M        17.99         10.38          122.80     1001.0   \n",
       "842517           M        20.57         17.77          132.90     1326.0   \n",
       "84300903         M        19.69         21.25          130.00     1203.0   \n",
       "84348301         M        11.42         20.38           77.58      386.1   \n",
       "84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "          smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                            \n",
       "842302            0.11840           0.27760          0.3001   \n",
       "842517            0.08474           0.07864          0.0869   \n",
       "84300903          0.10960           0.15990          0.1974   \n",
       "84348301          0.14250           0.28390          0.2414   \n",
       "84358402          0.10030           0.13280          0.1980   \n",
       "\n",
       "          concave points_mean  symmetry_mean  ...  texture_worst  \\\n",
       "id                                            ...                  \n",
       "842302                0.14710         0.2419  ...          17.33   \n",
       "842517                0.07017         0.1812  ...          23.41   \n",
       "84300903              0.12790         0.2069  ...          25.53   \n",
       "84348301              0.10520         0.2597  ...          26.50   \n",
       "84358402              0.10430         0.1809  ...          16.67   \n",
       "\n",
       "          perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "id                                                                           \n",
       "842302             184.60      2019.0            0.1622             0.6656   \n",
       "842517             158.80      1956.0            0.1238             0.1866   \n",
       "84300903           152.50      1709.0            0.1444             0.4245   \n",
       "84348301            98.87       567.7            0.2098             0.8663   \n",
       "84358402           152.20      1575.0            0.1374             0.2050   \n",
       "\n",
       "          concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "id                                                                \n",
       "842302             0.7119                0.2654          0.4601   \n",
       "842517             0.2416                0.1860          0.2750   \n",
       "84300903           0.4504                0.2430          0.3613   \n",
       "84348301           0.6869                0.2575          0.6638   \n",
       "84358402           0.4000                0.1625          0.2364   \n",
       "\n",
       "          fractal_dimension_worst  Unnamed: 32  \n",
       "id                                              \n",
       "842302                    0.11890          NaN  \n",
       "842517                    0.08902          NaN  \n",
       "84300903                  0.08758          NaN  \n",
       "84348301                  0.17300          NaN  \n",
       "84358402                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 569 entries, 842302 to 92751\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   radius_mean              569 non-null    float64\n",
      " 1   texture_mean             569 non-null    float64\n",
      " 2   perimeter_mean           569 non-null    float64\n",
      " 3   area_mean                569 non-null    float64\n",
      " 4   smoothness_mean          569 non-null    float64\n",
      " 5   compactness_mean         569 non-null    float64\n",
      " 6   concavity_mean           569 non-null    float64\n",
      " 7   concave points_mean      569 non-null    float64\n",
      " 8   symmetry_mean            569 non-null    float64\n",
      " 9   fractal_dimension_mean   569 non-null    float64\n",
      " 10  radius_se                569 non-null    float64\n",
      " 11  texture_se               569 non-null    float64\n",
      " 12  perimeter_se             569 non-null    float64\n",
      " 13  area_se                  569 non-null    float64\n",
      " 14  smoothness_se            569 non-null    float64\n",
      " 15  compactness_se           569 non-null    float64\n",
      " 16  concavity_se             569 non-null    float64\n",
      " 17  concave points_se        569 non-null    float64\n",
      " 18  symmetry_se              569 non-null    float64\n",
      " 19  fractal_dimension_se     569 non-null    float64\n",
      " 20  radius_worst             569 non-null    float64\n",
      " 21  texture_worst            569 non-null    float64\n",
      " 22  perimeter_worst          569 non-null    float64\n",
      " 23  area_worst               569 non-null    float64\n",
      " 24  smoothness_worst         569 non-null    float64\n",
      " 25  compactness_worst        569 non-null    float64\n",
      " 26  concavity_worst          569 non-null    float64\n",
      " 27  concave points_worst     569 non-null    float64\n",
      " 28  symmetry_worst           569 non-null    float64\n",
      " 29  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 137.8 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = DecisionTreeClassifier(criterion='entropy', random_state=1)\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_gini = DecisionTreeClassifier(criterion='gini', random_state=1)\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_gini.fit(X_train, y_train)\n",
    "\n",
    "y_pred_g = dt_gini.predict(X_test)\n",
    "\n",
    "accuracy_gini = accuracy_score(y_pred_g, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved by using entropy:  0.9473684210526315\n",
      "Accuracy achieved by using the gini index:  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Import accuracy_score from sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred = dt_entropy.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_entropy = accuracy_score(y_pred, y_test)\n",
    "\n",
    "# Print accuracy_entropy\n",
    "print('Accuracy achieved by using entropy: ', accuracy_entropy)\n",
    "\n",
    "# Print accuracy_gini\n",
    "print('Accuracy achieved by using the gini index: ', accuracy_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree for regression\n",
    "```python\n",
    "# Import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable needs to be continuous in a regression problem. Therefore, the outcome of the model will be a *real number*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=3)\n",
    "# Instantiate a DecisionTreeRegressor 'dt'\n",
    "dt = DecisionTreeRegressor(max_depth=4,\n",
    "                          min_samples_leaf=0.1,\n",
    "                          random_state=3)\n",
    "\n",
    "#Fit 'dt' to the training-set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "#Predict test-set labels\n",
    "y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2637620950775572\n"
     ]
    }
   ],
   "source": [
    "#Compute test-set MSE\n",
    "mse_dt = MSE(y_test, y_pred)\n",
    "\n",
    "#Compute test-set RMSE\n",
    "rmse_dt = mse_dt**(1/2)\n",
    "\n",
    "# Print rmse_dt\n",
    "print(rmse_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://schellenbergers3bucket.s3-us-west-2.amazonaws.com/Info+Criterion+for+Regression-Tree.png\" width=\"100%\" alt=\"Info Criterion for Regression-Tree.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>yr</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>marker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "      <td>US</td>\n",
       "      <td>ford mustang</td>\n",
       "      <td>red</td>\n",
       "      <td>27.370336</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>70</td>\n",
       "      <td>US</td>\n",
       "      <td>hi 1200d</td>\n",
       "      <td>green</td>\n",
       "      <td>62.199511</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.1</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>78</td>\n",
       "      <td>Asia</td>\n",
       "      <td>honda civic cvcc</td>\n",
       "      <td>blue</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>77</td>\n",
       "      <td>US</td>\n",
       "      <td>ford granada</td>\n",
       "      <td>red</td>\n",
       "      <td>34.515625</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.3</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>80</td>\n",
       "      <td>Europe</td>\n",
       "      <td>audi 4000</td>\n",
       "      <td>blue</td>\n",
       "      <td>13.298178</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cyl  displ   hp  weight  accel  yr  origin              name  color  \\\n",
       "0  18.0    6  250.0   88    3139   14.5  71      US      ford mustang    red   \n",
       "1   9.0    8  304.0  193    4732   18.5  70      US          hi 1200d  green   \n",
       "2  36.1    4   91.0   60    1800   16.4  78    Asia  honda civic cvcc   blue   \n",
       "3  18.5    6  250.0   98    3525   19.0  77      US      ford granada    red   \n",
       "4  34.3    4   97.0   78    2188   15.8  80  Europe         audi 4000   blue   \n",
       "\n",
       "        size marker  \n",
       "0  27.370336      o  \n",
       "1  62.199511      o  \n",
       "2   9.000000      x  \n",
       "3  34.515625      o  \n",
       "4  13.298178      s  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv(\"auto.csv\")\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>yr</th>\n",
       "      <th>size</th>\n",
       "      <th>origin_Asia</th>\n",
       "      <th>origin_Europe</th>\n",
       "      <th>...</th>\n",
       "      <th>name_vw rabbit c (diesel)</th>\n",
       "      <th>name_vw rabbit custom</th>\n",
       "      <th>color_black</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_purple</th>\n",
       "      <th>color_red</th>\n",
       "      <th>marker_o</th>\n",
       "      <th>marker_s</th>\n",
       "      <th>marker_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "      <td>27.370336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>70</td>\n",
       "      <td>62.199511</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.1</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>78</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>77</td>\n",
       "      <td>34.515625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.3</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>80</td>\n",
       "      <td>13.298178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cyl  displ   hp  weight  accel  yr       size  origin_Asia  \\\n",
       "0  18.0    6  250.0   88    3139   14.5  71  27.370336            0   \n",
       "1   9.0    8  304.0  193    4732   18.5  70  62.199511            0   \n",
       "2  36.1    4   91.0   60    1800   16.4  78   9.000000            1   \n",
       "3  18.5    6  250.0   98    3525   19.0  77  34.515625            0   \n",
       "4  34.3    4   97.0   78    2188   15.8  80  13.298178            0   \n",
       "\n",
       "   origin_Europe  ...  name_vw rabbit c (diesel)  name_vw rabbit custom  \\\n",
       "0              0  ...                          0                      0   \n",
       "1              0  ...                          0                      0   \n",
       "2              0  ...                          0                      0   \n",
       "3              0  ...                          0                      0   \n",
       "4              1  ...                          0                      0   \n",
       "\n",
       "   color_black  color_blue  color_green  color_purple  color_red  marker_o  \\\n",
       "0            0           0            0             0          1         1   \n",
       "1            0           0            1             0          0         1   \n",
       "2            0           1            0             0          0         0   \n",
       "3            0           0            0             0          1         1   \n",
       "4            0           1            0             0          0         0   \n",
       "\n",
       "   marker_s  marker_x  \n",
       "0         0         0  \n",
       "1         0         0  \n",
       "2         0         1  \n",
       "3         0         0  \n",
       "4         1         0  \n",
       "\n",
       "[5 rows x 320 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_encoded = pd.get_dummies(auto)\n",
    "auto_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cyl  displ   hp  weight  accel  yr       size  origin_Asia  \\\n",
      "0      6  250.0   88    3139   14.5  71  27.370336            0   \n",
      "1      8  304.0  193    4732   18.5  70  62.199511            0   \n",
      "2      4   91.0   60    1800   16.4  78   9.000000            1   \n",
      "3      6  250.0   98    3525   19.0  77  34.515625            0   \n",
      "4      4   97.0   78    2188   15.8  80  13.298178            0   \n",
      "..   ...    ...  ...     ...    ...  ..        ...          ...   \n",
      "387    6  250.0   88    3021   16.5  73  25.351225            0   \n",
      "388    4  151.0   90    2950   17.3  82  24.173611            0   \n",
      "389    4   98.0   68    2135   16.6  78  12.661736            1   \n",
      "390    6  250.0  110    3520   16.4  77  34.417778            0   \n",
      "391    4  140.0   88    2720   15.4  78  20.551111            0   \n",
      "\n",
      "     origin_Europe  origin_US  ...  name_vw rabbit c (diesel)  \\\n",
      "0                0          1  ...                          0   \n",
      "1                0          1  ...                          0   \n",
      "2                0          0  ...                          0   \n",
      "3                0          1  ...                          0   \n",
      "4                1          0  ...                          0   \n",
      "..             ...        ...  ...                        ...   \n",
      "387              0          1  ...                          0   \n",
      "388              0          1  ...                          0   \n",
      "389              0          0  ...                          0   \n",
      "390              0          1  ...                          0   \n",
      "391              0          1  ...                          0   \n",
      "\n",
      "     name_vw rabbit custom  color_black  color_blue  color_green  \\\n",
      "0                        0            0           0            0   \n",
      "1                        0            0           0            1   \n",
      "2                        0            0           1            0   \n",
      "3                        0            0           0            0   \n",
      "4                        0            0           1            0   \n",
      "..                     ...          ...         ...          ...   \n",
      "387                      0            0           0            0   \n",
      "388                      0            0           1            0   \n",
      "389                      0            0           1            0   \n",
      "390                      0            0           0            0   \n",
      "391                      0            0           1            0   \n",
      "\n",
      "     color_purple  color_red  marker_o  marker_s  marker_x  \n",
      "0               0          1         1         0         0  \n",
      "1               0          0         1         0         0  \n",
      "2               0          0         0         0         1  \n",
      "3               0          1         1         0         0  \n",
      "4               0          0         0         1         0  \n",
      "..            ...        ...       ...       ...       ...  \n",
      "387             0          1         1         0         0  \n",
      "388             0          0         1         0         0  \n",
      "389             0          0         0         0         1  \n",
      "390             0          1         1         0         0  \n",
      "391             0          0         1         0         0  \n",
      "\n",
      "[392 rows x 319 columns]\n",
      "0      18.0\n",
      "1       9.0\n",
      "2      36.1\n",
      "3      18.5\n",
      "4      34.3\n",
      "       ... \n",
      "387    18.0\n",
      "388    27.0\n",
      "389    29.5\n",
      "390    17.5\n",
      "391    25.1\n",
      "Name: mpg, Length: 392, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = auto_encoded.drop(columns='mpg')\n",
    "print(X)\n",
    "y = auto_encoded['mpg']\n",
    "print(y)\n",
    "\n",
    "# Split data into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=8, min_samples_leaf=0.13, random_state=3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeRegressor from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeRegressor(max_depth=8,\n",
    "             min_samples_leaf=0.13,\n",
    "            random_state=3)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of dt: 4.18\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute y_pred\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Compute mse_dt\n",
    "mse_dt = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute rmse_dt\n",
    "rmse_dt = mse_dt**(1/2)\n",
    "\n",
    "# Print rmse_dt\n",
    "print(\"Test set RMSE of dt: {:.2f}\".format(rmse_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to linear regression\n",
    "After instantiating a linear model and fitting our test set to the our new `lr` linear regression model, we can compare the root mean squared errors of the two predictions:\n",
    "\n",
    "```Python\n",
    "# Predict test set labels \n",
    "y_pred_lr = dt.predict(X_test)\n",
    "\n",
    "# Compute mse_lr\n",
    "mse_lr = MSE(y_test, y_pred_lr)\n",
    "\n",
    "# Compute rmse_lr\n",
    "rmse_lr = mse_lr**(1/2)\n",
    "\n",
    "# Print rmse_lr\n",
    "print('Linear Regression test set RMSE: {:.2f}'.format(rmse_lr))\n",
    "\n",
    "# Print rmse_dt\n",
    "print('Regression Tree test set RMSE: {:.2f}'.format(rmse_dt))\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "Linear Regression test set RMSE: 5.10\n",
    "Regression Tree test set RMSE: 4.37\n",
    "\n",
    "Therefore we have demonstrably lower error by using a tree regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization Error\n",
    "## Goals of Supervised Learning\n",
    "\n",
    "- Find a model $\\hat{f}$ that best approximates $f:\\hat{f} \\approx f$\n",
    "- $\\hat{f}$ can be Logistic Regression, Decision Tree, Neural Network ...\n",
    "- Discard noise as much as possible.\n",
    "- **End goal:** $\\hat{f}$ should acheive a low predictive error on unseen datasets.\n",
    "\n",
    "## Difficulties in Approximating $f$\n",
    "\n",
    "- **Overfitting:** $\\hat{f}(x)$ fits the training set noise.\n",
    "- **Underfitting:** $\\hat{f}$ is not flexible enough to approximate $f$.\n",
    "\n",
    "## Generalization Error\n",
    "- **Generalization Error of** $\\hat{f}$: Does $\\hat{f}$ generalize well on unseen data?\n",
    "- It can be decomposed as follows: Generalization Error of $\\hat{f} = bias^2 + variance + \\text{irreducible error}$\n",
    "    - Where the irreducible error is the error contribution from noise.\n",
    "    \n",
    "## Bias\n",
    "- **Bias:** error term that tells you, on average, how much $\\hat{f} \\neq f$.\n",
    "- High bias models lead to underfitting\n",
    "\n",
    "## Variance\n",
    "- **Variance:** tells you how much $\\hat{f}$ is inconsistent over different training sets.\n",
    "- High variance models lead to overfitting\n",
    "\n",
    "## Model Complexity\n",
    "- **Model Complexity:** sets the flexibility of $\\hat{f}$.\n",
    "- Example: Maximum tree depth, Minimum samples per leaf, ...\n",
    "\n",
    "## Bias - Variance Trade-off\n",
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/biasvariance.png\" alt=\"Bias Variance Tradeoff\" width=\"100%\">\n",
    "<img src=\"https://alinguistinfrance.files.wordpress.com/2017/09/screen-shot-2017-09-15-at-17-27-53.png?w=1024\" alt=\"Bias Variance Target Visual\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the Generalization Error\n",
    "- How do we estimate the generalization error of a model?\n",
    "- Cannot be done directly because:\n",
    "    - $f$ is unknown,\n",
    "    - usually you only have one dataset,\n",
    "    - noise is unpredictable\n",
    "\n",
    "## Solution:\n",
    "- split the data to training and test sets,\n",
    "- fit $\\hat{f}$ to the training set,\n",
    "- evaluate the error of $\\hat{f}$ on the unseen test set.\n",
    "- generalization error of $\\hat{f} \\approx \\text{test set error of} \\hat{f}$.\n",
    "\n",
    "## Better Model Evaluation with Cross-Validation\n",
    "- Test set should not be touched until we are confident about $\\hat{f}$'s performance.\n",
    "- Evaluating $\\hat{f}$ on training set: biased estimate, $\\hat{f}$ has already seen all training points.\n",
    "- Solution --> Cross-Validation (CV):\n",
    "    - K-Fold CV,\n",
    "    - Hold-Out CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnose Variance Problems\n",
    "- If $\\hat{f}$ suffers from **high variance**: CV error of $\\hat{f}$ > training set error of $\\hat{f}$.\n",
    "- $\\hat{f}$ is said to over fit the training set. To remedy overfitting:\n",
    "    - decrease model complexity,\n",
    "    - for example: decrease max depth, increase min samples per leaf, etc.\n",
    "    - gather more data, etc.\n",
    "    \n",
    "# Diagnose Bias Problems\n",
    "- if $\\hat{f}$ suffers from **high bias**: CV error of $\\hat{f}$ $\\approx$ training set error of $\\hat{f}$ >> desired error.\n",
    "- $\\hat{f}$ is said to underfit the training set. to remedy underfitting:\n",
    "    - increase model complexity\n",
    "    - for example: increase max depth, decrese min samples per leaf, etc.\n",
    "    - gather more relevant features\n",
    "    \n",
    "```Python\n",
    "# Import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 123\n",
    "\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
    "                                                  test_size=0.3,\n",
    "                                                  random_state=SEED)\n",
    "# Instantiate a DecisionTreeRegressor 'dt'\n",
    "dt = DecisionTreeRegressor(max_depth=4,\n",
    "                          min_samples_leaf=0.14,\n",
    "                          random_state=SEED)\n",
    "\n",
    "# Evaluate the list of MSE obtained by 10-fold CV\n",
    "# Set n_jobs to -1 in order to exploit all CPU cores in computation\n",
    "MSE_CV = cross_val_score(dt, X_train, y_train, cv=10, scoring ='neg_mean_squared_error', n_jobs = -1)\n",
    "\n",
    "# You can multiply the result by -1 to obtain an array of the cross-validation MSEs\n",
    "#Fit 'dt' to the training-set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "#Predict training-set labels\n",
    "y_pred_train = dt.predict(X_train)\n",
    "\n",
    "#Predict test-set labels\n",
    "y_pred_test = dt.predict(X_test)\n",
    "\n",
    "# CV MSE\n",
    "print('CV MSE: {:.2f}'.format(MSE_CV.mean()))\n",
    "\n",
    "# Training set MSE\n",
    "print('Train MSE: {:.2f}'.format(MSE(y_train, y_predict_train)))\n",
    "\n",
    "# Test set MSE\n",
    "print('Test MSE: {:.2f}'.format(MSE(y_test, y_predict_test)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cyl  displ   hp  weight  accel  yr       size  origin_Asia  \\\n",
      "0      6  250.0   88    3139   14.5  71  27.370336            0   \n",
      "1      8  304.0  193    4732   18.5  70  62.199511            0   \n",
      "2      4   91.0   60    1800   16.4  78   9.000000            1   \n",
      "3      6  250.0   98    3525   19.0  77  34.515625            0   \n",
      "4      4   97.0   78    2188   15.8  80  13.298178            0   \n",
      "..   ...    ...  ...     ...    ...  ..        ...          ...   \n",
      "387    6  250.0   88    3021   16.5  73  25.351225            0   \n",
      "388    4  151.0   90    2950   17.3  82  24.173611            0   \n",
      "389    4   98.0   68    2135   16.6  78  12.661736            1   \n",
      "390    6  250.0  110    3520   16.4  77  34.417778            0   \n",
      "391    4  140.0   88    2720   15.4  78  20.551111            0   \n",
      "\n",
      "     origin_Europe  origin_US  ...  name_vw rabbit c (diesel)  \\\n",
      "0                0          1  ...                          0   \n",
      "1                0          1  ...                          0   \n",
      "2                0          0  ...                          0   \n",
      "3                0          1  ...                          0   \n",
      "4                1          0  ...                          0   \n",
      "..             ...        ...  ...                        ...   \n",
      "387              0          1  ...                          0   \n",
      "388              0          1  ...                          0   \n",
      "389              0          0  ...                          0   \n",
      "390              0          1  ...                          0   \n",
      "391              0          1  ...                          0   \n",
      "\n",
      "     name_vw rabbit custom  color_black  color_blue  color_green  \\\n",
      "0                        0            0           0            0   \n",
      "1                        0            0           0            1   \n",
      "2                        0            0           1            0   \n",
      "3                        0            0           0            0   \n",
      "4                        0            0           1            0   \n",
      "..                     ...          ...         ...          ...   \n",
      "387                      0            0           0            0   \n",
      "388                      0            0           1            0   \n",
      "389                      0            0           1            0   \n",
      "390                      0            0           0            0   \n",
      "391                      0            0           1            0   \n",
      "\n",
      "     color_purple  color_red  marker_o  marker_s  marker_x  \n",
      "0               0          1         1         0         0  \n",
      "1               0          0         1         0         0  \n",
      "2               0          0         0         0         1  \n",
      "3               0          1         1         0         0  \n",
      "4               0          0         0         1         0  \n",
      "..            ...        ...       ...       ...       ...  \n",
      "387             0          1         1         0         0  \n",
      "388             0          0         1         0         0  \n",
      "389             0          0         0         0         1  \n",
      "390             0          1         1         0         0  \n",
      "391             0          0         1         0         0  \n",
      "\n",
      "[392 rows x 319 columns]\n",
      "0      18.0\n",
      "1       9.0\n",
      "2      36.1\n",
      "3      18.5\n",
      "4      34.3\n",
      "       ... \n",
      "387    18.0\n",
      "388    27.0\n",
      "389    29.5\n",
      "390    17.5\n",
      "391    25.1\n",
      "Name: mpg, Length: 392, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intantiate the model\n",
    "\n",
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set SEED for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Instantiate a DecisionTreeRegressor dt\n",
    "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.26, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 5.14\n"
     ]
    }
   ],
   "source": [
    "# import cross_val_score from sklearn.model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Compute the array containing the 10-folds CV MSEs\n",
    "MSE_CV_scores = - cross_val_score(dt, X_train, y_train, cv=10, \n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Compute the 10-folds CV RMSE\n",
    "RMSE_CV = (MSE_CV_scores.mean())**(1/2)\n",
    "\n",
    "# Print RMSE_CV\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_CV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A very good practice is to keep the test set untouched until you are confident about your model's performance. CV is a great technique to get an estimate of a model's performance without affecting the test set.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 5.15\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the training set\n",
    "y_pred_train = dt.predict(X_train)\n",
    "\n",
    "# Evaluate the training set RMSE of dt\n",
    "RMSE_train = (MSE(y_train, y_pred_train))**(1/2)\n",
    "\n",
    "# Print RMSE_train\n",
    "print('Train RMSE: {:.2f}'.format(RMSE_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dt` suffers from high bias because `RMSE_CV` $\\approx$ `RMSE_train` and both scores are greater than `baseline_RMSE`\n",
    "\n",
    "- `dt` is indeed underfitting the training set as the model is too constrained to capture the nonlinear dependencies between features and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning\n",
    "\n",
    "## Advantages of CARTs (Classification And Regression Trees)\n",
    "- Simple to understand\n",
    "- Simple to interpret\n",
    "- Easy to use\n",
    "- Flexibility: ability to describe non-linear dependencies.\n",
    "- Preprocessing: no need to standardize or normalize features, etc.\n",
    "\n",
    "## Limitations of CARTs\n",
    "- Classification: can only produce orthogonal decision boundaries\n",
    "- Sensitive to small variations in the training set\n",
    "- High variance: unconstrained CARTs may overfit the training set\n",
    "- Solution: ensemble learning\n",
    "\n",
    "# Ensemble\n",
    "- Train different models on the same dataset\n",
    "- Let each model make its predictions\n",
    "- Met-model: aggregates predictions of individual models\n",
    "- Final prediction: more robust and less prone to errors\n",
    "- Best results: models are skillful in different ways.\n",
    "\n",
    "## Voting Classifier\n",
    "- Binary classification task\n",
    "- N classifiers make predictions: $P_{1},P_{2},\\cdots,P_{N} \\text{with } P_{i} = 0\\text{ or }1$\n",
    "- Meta-model prediction: hard voting.\n",
    "\n",
    "<img src=\"https://www.lucidchart.com/publicSegments/view/0cfbfe59-44d9-4508-b300-e3f3c2990b99/image.png\" width=\"100%\" alt=\"Hard Voting Visual Description\">\n",
    "\n",
    "# Voting Classifier in sklearn (Breast-Cancer dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions to compute accuracy and split data\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import models, including VotingClassifier meta-model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_cancer = pd.read_csv(\"wbc.csv\")\n",
    "b_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "b_cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   radius_mean              569 non-null    float64\n",
      " 1   texture_mean             569 non-null    float64\n",
      " 2   perimeter_mean           569 non-null    float64\n",
      " 3   area_mean                569 non-null    float64\n",
      " 4   smoothness_mean          569 non-null    float64\n",
      " 5   compactness_mean         569 non-null    float64\n",
      " 6   concavity_mean           569 non-null    float64\n",
      " 7   concave points_mean      569 non-null    float64\n",
      " 8   symmetry_mean            569 non-null    float64\n",
      " 9   fractal_dimension_mean   569 non-null    float64\n",
      " 10  radius_se                569 non-null    float64\n",
      " 11  texture_se               569 non-null    float64\n",
      " 12  perimeter_se             569 non-null    float64\n",
      " 13  area_se                  569 non-null    float64\n",
      " 14  smoothness_se            569 non-null    float64\n",
      " 15  compactness_se           569 non-null    float64\n",
      " 16  concavity_se             569 non-null    float64\n",
      " 17  concave points_se        569 non-null    float64\n",
      " 18  symmetry_se              569 non-null    float64\n",
      " 19  fractal_dimension_se     569 non-null    float64\n",
      " 20  radius_worst             569 non-null    float64\n",
      " 21  texture_worst            569 non-null    float64\n",
      " 22  perimeter_worst          569 non-null    float64\n",
      " 23  area_worst               569 non-null    float64\n",
      " 24  smoothness_worst         569 non-null    float64\n",
      " 25  compactness_worst        569 non-null    float64\n",
      " 26  concavity_worst          569 non-null    float64\n",
      " 27  concave points_worst     569 non-null    float64\n",
      " 28  symmetry_worst           569 non-null    float64\n",
      " 29  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "X = b_cancer.drop(columns=[\"id\", \"diagnosis\"])\n",
    "X = X.iloc[:,:30]\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      M\n",
      "1      M\n",
      "2      M\n",
      "3      M\n",
      "4      M\n",
      "      ..\n",
      "564    M\n",
      "565    M\n",
      "566    M\n",
      "567    M\n",
      "568    B\n",
      "Name: diagnosis, Length: 569, dtype: object\n",
      "\n",
      "\n",
      "Unique Values in Series: \n",
      " ['M' 'B']\n"
     ]
    }
   ],
   "source": [
    "y = b_cancer[\"diagnosis\"]\n",
    "print(y)\n",
    "print(\"\\n\\nUnique Values in Series: \\n\", y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=SEED)\n",
    "\n",
    "# Instantiate individual classifiers\n",
    "lr = LogisticRegression(random_state=SEED, max_iter=10000)\n",
    "knn = KNN()\n",
    "dt = DecisionTreeClassifier(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list called classifier that contains the tuples (classifier_name, classifier)\n",
    "classifiers = [('Logistic Regression', lr),\n",
    "              ('K Nearest Neighbours', knn),\n",
    "              ('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.947\n",
      "K Nearest Neighbours : 0.930\n",
      "Classification Tree : 0.930\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the dfined list of tuples containing the classifiers\n",
    "for clf_name, clf in classifiers:\n",
    "    # fit clf to the training set\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the labels of the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate the accuracy of clf on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.953\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a VotingClassifier 'vc'\n",
    "vc = VotingClassifier(estimators=classifiers)\n",
    "\n",
    "# Fit 'vc' to the training set and predict test set labels\n",
    "vc.fit(X_train, y_train)\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Evaluate the test-set accuracy of 'vc'\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED=1\n",
    "\n",
    "# Instantiate lr\n",
    "lr = LogisticRegression(random_state=SEED, max_iter=10000)\n",
    "\n",
    "# Instantiate knn\n",
    "knn = KNN(n_neighbors=27)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=SEED)\n",
    "\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.947\n",
      "K Nearest Neighbours : 0.912\n",
      "Classification Tree : 0.854\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf in classifiers:    \n",
    " \n",
    "    # Fit clf to the training set\n",
    "    clf.fit(X_train, y_train)    \n",
    "   \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred) \n",
    "   \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.918\n"
     ]
    }
   ],
   "source": [
    "# Import VotingClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)    \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train) \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging (Bootstrap Aggregation)\n",
    "## Ensemble Methods\n",
    "### Voting Classifier\n",
    "- same training set,\n",
    "- $\\neq$ algorithms (using different algorithms)\n",
    "### Bagging\n",
    "- one or same algorithm\n",
    "- $\\neq$ subsets of the training set (trained on different subsets of the training data)\n",
    "\n",
    "- Uses a technique known as the bootstrap\n",
    "- Reduces variance of individual models in the ensemble\n",
    "\n",
    "<img src=\"https://www.lucidchart.com/publicSegments/view/443a42fa-6b0d-497b-9ab1-c5e59f13f3bb/image.png\" width=100% alt=\"Bootstrap Method Visualization\">\n",
    "\n",
    "### Bagging Training \n",
    "\n",
    "<img src=\"https://www.lucidchart.com/publicSegments/view/2707f4d3-0f61-4f25-ac09-8d077e849541/image.png\" width=100% alt=\"Bagging Training Visualization\">\n",
    "\n",
    "### Bagging Prediction\n",
    "\n",
    "<img src=\"https://www.lucidchart.com/publicSegments/view/e6a62f9e-f878-4d27-9c43-7ab54f988d47/image.png\" width=100% alt=\"Bagging Prediction Visualization\">\n",
    "\n",
    "# Bagging: Classification & Regression\n",
    "## Classification:\n",
    "- Aggregates predictions by majority voting\n",
    "- `Bagging Classifier` in scikit-learn\n",
    "## Regression:\n",
    "- Aggregates predictions through averaging.\n",
    "- `BaggingRegressor` scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
      "0                   0.07871  ...        25.380          17.33   \n",
      "1                   0.05667  ...        24.990          23.41   \n",
      "2                   0.05999  ...        23.570          25.53   \n",
      "3                   0.09744  ...        14.910          26.50   \n",
      "4                   0.05883  ...        22.540          16.67   \n",
      "..                      ...  ...           ...            ...   \n",
      "564                 0.05623  ...        25.450          26.40   \n",
      "565                 0.05533  ...        23.690          38.25   \n",
      "566                 0.05648  ...        18.980          34.12   \n",
      "567                 0.07016  ...        25.740          39.42   \n",
      "568                 0.05884  ...         9.456          30.37   \n",
      "\n",
      "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
      "0             184.60      2019.0           0.16220            0.66560   \n",
      "1             158.80      1956.0           0.12380            0.18660   \n",
      "2             152.50      1709.0           0.14440            0.42450   \n",
      "3              98.87       567.7           0.20980            0.86630   \n",
      "4             152.20      1575.0           0.13740            0.20500   \n",
      "..               ...         ...               ...                ...   \n",
      "564           166.10      2027.0           0.14100            0.21130   \n",
      "565           155.00      1731.0           0.11660            0.19220   \n",
      "566           126.70      1124.0           0.11390            0.30940   \n",
      "567           184.60      1821.0           0.16500            0.86810   \n",
      "568            59.16       268.6           0.08996            0.06444   \n",
      "\n",
      "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0             0.7119                0.2654          0.4601   \n",
      "1             0.2416                0.1860          0.2750   \n",
      "2             0.4504                0.2430          0.3613   \n",
      "3             0.6869                0.2575          0.6638   \n",
      "4             0.4000                0.1625          0.2364   \n",
      "..               ...                   ...             ...   \n",
      "564           0.4107                0.2216          0.2060   \n",
      "565           0.3215                0.1628          0.2572   \n",
      "566           0.3403                0.1418          0.2218   \n",
      "567           0.9387                0.2650          0.4087   \n",
      "568           0.0000                0.0000          0.2871   \n",
      "\n",
      "     fractal_dimension_worst  \n",
      "0                    0.11890  \n",
      "1                    0.08902  \n",
      "2                    0.08758  \n",
      "3                    0.17300  \n",
      "4                    0.07678  \n",
      "..                       ...  \n",
      "564                  0.07115  \n",
      "565                  0.06637  \n",
      "566                  0.07820  \n",
      "567                  0.12400  \n",
      "568                  0.07039  \n",
      "\n",
      "[569 rows x 30 columns]\n",
      "0      M\n",
      "1      M\n",
      "2      M\n",
      "3      M\n",
      "4      M\n",
      "      ..\n",
      "564    M\n",
      "565    M\n",
      "566    M\n",
      "567    M\n",
      "568    B\n",
      "Name: diagnosis, Length: 569, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bagging Classifier: 0.854\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=4, min_samples_leaf=0.16, random_state=SEED)\n",
    "\n",
    "# Instantiate a BaggingClassifier 'bc'\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=300, n_jobs=-1)\n",
    "\n",
    "# Fit 'bc' to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate and print test-set accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy of Bagging Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1)\n",
    "\n",
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of Bag Evaluation\n",
    "## Bagging\n",
    "- Some instances may be sampled several times for one model\n",
    "- Other instances may not be sampled at all\n",
    "\n",
    "## Out of Bag (OOB) instances\n",
    "- On average, for each model, **63%** of the training instances are sampled\n",
    "- The remaining **37%** constitute the OOB instances.\n",
    "- Because the model does not see this *37%*, we can use this to validate the model instead of using Cross-Validation\n",
    "- This is refered to as **OOB Evaluation**\n",
    "\n",
    "## OOB Evaluation\n",
    "<img src=\"https://www.lucidchart.com/publicSegments/view/1405e3ef-f127-4573-9e31-71e620077519/image.png\" width=\"100%\" alt=\"OOB Evaluation Visualization\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=4,\n",
    "                           min_samples_leaf=0.16,\n",
    "                           random_state=SEED)\n",
    "\n",
    "# Instantiate a BaggingClassifier 'bc'; set oob_score=True\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=300, oob_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "In Scikit-Learn, the OOB scores corresponds to **accuracy** for *classifiers* and $r^2$ score for *regressors*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit 'bc' to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = bc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.854\n"
     ]
    }
   ],
   "source": [
    "# Evaluate test set accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Extract the OOB accuracy from 'bc'\n",
    "oob_accuracy = bc.oob_score_\n",
    "\n",
    "# Print test set accuracy\n",
    "print('Test set accuracy: {:.3f}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB accuracy: 0.940\n"
     ]
    }
   ],
   "source": [
    "# Print OOB accuracy\n",
    "print('OOB accuracy: {:.3f}'.format(oob_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=8, random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, \n",
    "            n_estimators=50,\n",
    "            oob_score=True,\n",
    "            random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.912, OOB accuracy: 0.955\n"
     ]
    }
   ],
   "source": [
    "# Fit bc to the training set \n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate test set accuracy\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Evaluate OOB accuracy\n",
    "acc_oob = bc.oob_score_\n",
    "\n",
    "# Print acc_test and acc_oob\n",
    "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "\n",
    "## Bagging\n",
    "- Base estimator: Decision Tree, Logistic Regression, Neural Net, etc.\n",
    "- Each estimator is trained on a distinct bootstap sample of the training set\n",
    "- Estimators use all features for training and prediction\n",
    "\n",
    "## Further Diversity with Random Forests (RF)\n",
    "- Base estimator: Decision Tree\n",
    "- Each estimator is trained on a different bootstrap sample having the same size as the training set\n",
    "- RF introduces further randomization in the training of individual trees\n",
    "- $d$ freatures are sampled at each node without replacement\n",
    "    - where: $d < \\text{ total number of features}$\n",
    "\n",
    "<img src=\"https://www.lucidchart.com/publicSegments/view/88980cfd-b9e4-4dc8-ab45-06d425c04e2d/image.png\" width=\"100%\" alt=\"Random Forests: Training Visualization\">\n",
    "\n",
    "## Note:\n",
    "- in Scikit-Learn $d$ defaults to the $\\sqrt{\\text{number of features}}$\n",
    "\n",
    "## Random Forests: Prediction\n",
    "\n",
    "<img src=\"https://www.lucidchart.com/publicSegments/view/8778b12c-5a21-4947-b108-c84758775866/image.png\" width=\"100%\" alt=\"Random Forest: Prediction Visualization\">\n",
    "\n",
    "## Random Forests: Classification & Regression\n",
    "\n",
    "### Classification:\n",
    "- Aggregates predictions by majority voting\n",
    "- `RandomForestClassifier` in scikit-learn\n",
    "### Regression:\n",
    "- Aggregates predictions through averaging\n",
    "- `RandomForestRegressor` in scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cyl  displ   hp  weight  accel  yr       size  origin_Asia  \\\n",
      "0      6  250.0   88    3139   14.5  71  27.370336            0   \n",
      "1      8  304.0  193    4732   18.5  70  62.199511            0   \n",
      "2      4   91.0   60    1800   16.4  78   9.000000            1   \n",
      "3      6  250.0   98    3525   19.0  77  34.515625            0   \n",
      "4      4   97.0   78    2188   15.8  80  13.298178            0   \n",
      "..   ...    ...  ...     ...    ...  ..        ...          ...   \n",
      "387    6  250.0   88    3021   16.5  73  25.351225            0   \n",
      "388    4  151.0   90    2950   17.3  82  24.173611            0   \n",
      "389    4   98.0   68    2135   16.6  78  12.661736            1   \n",
      "390    6  250.0  110    3520   16.4  77  34.417778            0   \n",
      "391    4  140.0   88    2720   15.4  78  20.551111            0   \n",
      "\n",
      "     origin_Europe  origin_US  ...  name_vw rabbit c (diesel)  \\\n",
      "0                0          1  ...                          0   \n",
      "1                0          1  ...                          0   \n",
      "2                0          0  ...                          0   \n",
      "3                0          1  ...                          0   \n",
      "4                1          0  ...                          0   \n",
      "..             ...        ...  ...                        ...   \n",
      "387              0          1  ...                          0   \n",
      "388              0          1  ...                          0   \n",
      "389              0          0  ...                          0   \n",
      "390              0          1  ...                          0   \n",
      "391              0          1  ...                          0   \n",
      "\n",
      "     name_vw rabbit custom  color_black  color_blue  color_green  \\\n",
      "0                        0            0           0            0   \n",
      "1                        0            0           0            1   \n",
      "2                        0            0           1            0   \n",
      "3                        0            0           0            0   \n",
      "4                        0            0           1            0   \n",
      "..                     ...          ...         ...          ...   \n",
      "387                      0            0           0            0   \n",
      "388                      0            0           1            0   \n",
      "389                      0            0           1            0   \n",
      "390                      0            0           0            0   \n",
      "391                      0            0           1            0   \n",
      "\n",
      "     color_purple  color_red  marker_o  marker_s  marker_x  \n",
      "0               0          1         1         0         0  \n",
      "1               0          0         1         0         0  \n",
      "2               0          0         0         0         1  \n",
      "3               0          1         1         0         0  \n",
      "4               0          0         0         1         0  \n",
      "..            ...        ...       ...       ...       ...  \n",
      "387             0          1         1         0         0  \n",
      "388             0          0         1         0         0  \n",
      "389             0          0         0         0         1  \n",
      "390             0          1         1         0         0  \n",
      "391             0          0         1         0         0  \n",
      "\n",
      "[392 rows x 319 columns]\n",
      "0      18.0\n",
      "1       9.0\n",
      "2      36.1\n",
      "3      18.5\n",
      "4      34.3\n",
      "       ... \n",
      "387    18.0\n",
      "388    27.0\n",
      "389    29.5\n",
      "390    17.5\n",
      "391    25.1\n",
      "Name: mpg, Length: 392, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = auto_encoded.drop(columns='mpg')\n",
    "print(X)\n",
    "y = auto_encoded['mpg']\n",
    "print(y)\n",
    "\n",
    "# Split data into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a random forests regressor 'rf' 400 estimators\n",
    "rf = RandomForestRegressor(n_estimators=400,\n",
    "                          min_samples_leaf=0.12,\n",
    "                          random_state=SEED)\n",
    "\n",
    "# min_samples_leaf set to 0.12 ensures that each leaf \n",
    "# contains at least 12% of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit 'rf' to the training set\n",
    "rf.fit(X_train, y_train)\n",
    "# Predict the test set labels 'y_pred'\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 4.37\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print the test set RMSE\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "Tree-based methods: enable measureing the importance of each feature in prediction\n",
    "\n",
    "In `sklearn`:\n",
    "- how much the tree nodes use a particular feature (weighted average) to reduce impurity\n",
    "- accessed using the attribute `feature_importance_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 462,
       "width": 845
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a pd.Series of feature importances\n",
    "importances_rf = pd.Series(rf.feature_importances_, index = X.columns)\n",
    "\n",
    "# Sort importances_rf\n",
    "sorted_importances_rf = importances_rf.sort_values()\n",
    "\n",
    "# Filter for non-zero importances\n",
    "importances_valued = sorted_importances_rf[sorted_importances_rf > 0]\n",
    "\n",
    "# Make a horizontal bar plot\n",
    "importances_valued.plot(kind='barh', color='lightgreen')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Share Demand Dataset from Kaggle\n",
    "## [Bike Sharing Demand](https://www.kaggle.com/c/bike-sharing-demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-01-01 05:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.84</td>\n",
       "      <td>12.880</td>\n",
       "      <td>75</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.20</td>\n",
       "      <td>12.880</td>\n",
       "      <td>86</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011-01-01 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011-01-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.12</td>\n",
       "      <td>17.425</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2011-01-01 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.58</td>\n",
       "      <td>19.695</td>\n",
       "      <td>76</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011-01-01 11:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.76</td>\n",
       "      <td>16.665</td>\n",
       "      <td>81</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2011-01-01 12:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.22</td>\n",
       "      <td>21.210</td>\n",
       "      <td>77</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>29</td>\n",
       "      <td>55</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2011-01-01 13:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18.86</td>\n",
       "      <td>22.725</td>\n",
       "      <td>72</td>\n",
       "      <td>19.9995</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2011-01-01 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18.86</td>\n",
       "      <td>22.725</td>\n",
       "      <td>72</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>35</td>\n",
       "      <td>71</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
       "0   2011-01-01 00:00:00       1        0           0        1   9.84  14.395   \n",
       "1   2011-01-01 01:00:00       1        0           0        1   9.02  13.635   \n",
       "2   2011-01-01 02:00:00       1        0           0        1   9.02  13.635   \n",
       "3   2011-01-01 03:00:00       1        0           0        1   9.84  14.395   \n",
       "4   2011-01-01 04:00:00       1        0           0        1   9.84  14.395   \n",
       "5   2011-01-01 05:00:00       1        0           0        2   9.84  12.880   \n",
       "6   2011-01-01 06:00:00       1        0           0        1   9.02  13.635   \n",
       "7   2011-01-01 07:00:00       1        0           0        1   8.20  12.880   \n",
       "8   2011-01-01 08:00:00       1        0           0        1   9.84  14.395   \n",
       "9   2011-01-01 09:00:00       1        0           0        1  13.12  17.425   \n",
       "10  2011-01-01 10:00:00       1        0           0        1  15.58  19.695   \n",
       "11  2011-01-01 11:00:00       1        0           0        1  14.76  16.665   \n",
       "12  2011-01-01 12:00:00       1        0           0        1  17.22  21.210   \n",
       "13  2011-01-01 13:00:00       1        0           0        2  18.86  22.725   \n",
       "14  2011-01-01 14:00:00       1        0           0        2  18.86  22.725   \n",
       "\n",
       "    humidity  windspeed  casual  registered  count  \n",
       "0         81     0.0000       3          13     16  \n",
       "1         80     0.0000       8          32     40  \n",
       "2         80     0.0000       5          27     32  \n",
       "3         75     0.0000       3          10     13  \n",
       "4         75     0.0000       0           1      1  \n",
       "5         75     6.0032       0           1      1  \n",
       "6         80     0.0000       2           0      2  \n",
       "7         86     0.0000       1           2      3  \n",
       "8         75     0.0000       1           7      8  \n",
       "9         76     0.0000       8           6     14  \n",
       "10        76    16.9979      12          24     36  \n",
       "11        81    19.0012      26          30     56  \n",
       "12        77    19.0012      29          55     84  \n",
       "13        72    19.9995      47          47     94  \n",
       "14        72    19.0012      35          71    106  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_share_train = pd.read_csv(\"bike_share_train.csv\")\n",
    "bike_share_train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bike_share_train[\"count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I will attempt to split the datetime column into component yr, month, day, hour columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime = bike_share_train.datetime\n",
    "type(datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_share_train[\"year\"] = [x[:4] for x in datetime]\n",
    "bike_share_train[\"month\"] = [x[5:7] for x in datetime]\n",
    "bike_share_train[\"day\"] = [x[8:10] for x in datetime]\n",
    "bike_share_train[\"hour\"] = [x[11:13] for x in datetime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bike_share_train.drop(['datetime', 'count', 'registered', 'casual'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>2011</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>2011</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>2011</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>2011</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  year month day hour  \n",
       "0        81        0.0       3          13     16  2011    01  01   00  \n",
       "1        80        0.0       8          32     40  2011    01  01   01  \n",
       "2        80        0.0       5          27     32  2011    01  01   02  \n",
       "3        75        0.0       3          10     13  2011    01  01   03  \n",
       "4        75        0.0       0           1      1  2011    01  01   04  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_share_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16\n",
       "1    40\n",
       "2    32\n",
       "3    13\n",
       "4     1\n",
       "5     1\n",
       "6     2\n",
       "7     3\n",
       "8     8\n",
       "9    14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=25, random_state=2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestRegressor(n_estimators=25,\n",
    "            random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 47.02\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABqMAAAO6CAYAAAAb6C0NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAABYlAAAWJQFJUiTwAACXRklEQVR4nOzdd5gW5fk24GsR6ShosESxuwsiRRHBiGIBFStojB1RY0xsaOwxn0nsJUaJvxjT7MYEFSWoGKNRI1EQsStFLAhWinQEkf3+4Ng3bkBDG9bV8zwOD/d9Zp6Ze2bf5x+uvWfKKisrKwMAAAAAAAAFqFPTBQAAAAAAAPD1JYwCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKU7emCwAAAGq3ioqKpd63T58+Of/88wus5ovNnz8/H374YVq2bFkj51+VBg4cmPPOOy8bbLBB/vnPf9Z0OavUG2+8kc0337ymywAAAD5HGAUAAKwU5eXladKkyZfuU1NB0L///e/84he/SJ8+fXLkkUfWSA0Ua9KkSbnkkksyYcKE3HPPPTVdDgAA8DnCKAAAYKX46U9/ms6dO9d0GUt0ww03ZPz48TVdBgV68sknM2TIkLRp06amSwEAAP6Ld0YBAAAAAABQGGEUAAAAAAAAhRFGAQAANeqRRx7Jcccdl86dO6dt27bp3r17Lr744nz00UdfOOexxx7LKaeckm7duqVt27bZZptt0rNnz1x22WWZNGlSab/hw4enoqIizzzzTJLkoosuSkVFRa677rokyXXXXZeKioqceuqpSzzPFVdckYqKipx77rmlsYkTJ6aioiL77rtvxo0bl0MOOSRt27ZN165dc/vtt5f2mz9/fm6++eYcdNBB2WabbdKhQ4f07t07f/rTnzJv3rwlnm/48OE58cQTs8MOO6RNmzbZYYcdctxxx+XBBx9c+hv6JQYOHJiKiopccsklmTx5ci644IJ07do17dq1y957753bbrstSVJZWZm//OUv2X///dOuXbt06dIlZ5555mK/k6r7e9xxx2XmzJn5+c9/nq5du6Z9+/bZb7/9vvRa582bl5tuuinf/e53s80226R9+/bZd999c+2112b69OmL7X/UUUeloqIizz33XH7xi19k2223zbbbbpu+fftml112yXnnnZckefXVV1NRUZHddtut2vwJEybkkksuyX777Zdtt902W2+9dbp27ZqTTjopw4YNW+x85557bioqKvLQQw9l9OjROeWUU9KlS5e0bds2e++9d2644YbMnz9/iddWda499tgj7dq1y/bbb5/jjjsuQ4cOXeL+U6ZMyRVXXJE999wz7dq1S6dOnXL00UfnoYceWuL+lZWVueuuu3L44YeXrmWXXXbJGWeckZdeemmJcwAAoCZ5ZxQAAFAjKisrc8EFF2TAgAFJkhYtWmTLLbfMW2+9ldtuuy0PPPBAfv/736dt27bV5p1//vm5++67kyTf/va3U15ensmTJ+fNN9/Mm2++mSFDhmTQoEFp3rx5mjZtmm233TZjx47NrFmz0rJly7Ro0SLrr7/+Ctc/c+bMHHfccZkxY0a22GKLvPnmm9l8882TJNOmTcvxxx+fl156KXXq1EnLli3ToEGDjBkzJq+99loeeOCB/OlPf0rz5s1Lxxs8eHDOPvvsLFy4MOutt15atWqVyZMnZ+jQoRk6dGhefvnlnHPOOStcd5K899576dWrVz7++ONsvvnmKSsryxtvvJGLL744c+fOzVtvvZWBAwemRYsW2XTTTTN27NgMHjw4r732WgYNGpTVV1+92vHmzJmTI488MqNHj07Lli3TvHnzvP7667nyyivzz3/+M7/73e/SpEmT0v5Tp05N3759M2bMmJSVlWWzzTZLvXr18vrrr+e3v/1tBg0alD/+8Y+l+/l5V1xxRV544YWUl5dn2rRpadGiRdZYY43Ur18/b7/9dho1apRWrVqlRYsWpTlDhw7NSSedlE8++SRNmzbNRhttlHnz5mXChAl55JFH8uijj+aXv/xl9t1338XON2zYsJx55plJkk033TQNGzbMG2+8kWuuuSYvvvhifvvb31bb/9///nf69euXmTNnplGjRtliiy0yadKk0u/xkksuyXe/+93S/q+++mqOP/74TJkyJfXq1cumm26aOXPmZNiwYRk2bFgOPPDAXHrppSkrKyvN+dnPfpa//vWvKSsry8Ybb5zGjRtn4sSJuf/++zNkyJD8+te/Tvfu3ZfxWwEAAAWqBAAAWAHl5eWV5eXllcOGDVumeTfeeGNleXl5ZdeuXSufeuqp0vjs2bMrf/7zn1eWl5dXduvWrXLmzJmlbY8++mhleXl5ZYcOHSqffvrpascbPnx4ZYcOHSrLy8srf//731fbduSRR1aWl5dX3nbbbdXGf/3rX1eWl5dXnnLKKUus8fLLL68sLy+vPOecc0pjEyZMKF3zHnvsUTl58uTKysrKyo8//rhy4cKFlZWVlZUnnHBCZXl5eeUhhxxSOX78+NLc9957r/Lwww+vLC8vr/zRj35UGv/ss88qv/Od71SWl5dXPvDAA9VquPfeeysrKioqW7VqVTlhwoQvvqGfc88991SWl5dX7rrrrkscLy8vr+zZs2eptoULF1aef/75leXl5ZWtWrWq3HrrravV8dxzz1W2adOmsry8vPKRRx4pjQ8bNqx0vLZt21YOGTKktG3UqFGVO+20U2V5eXnlZZddVq2Oo446qrK8vLxy3333rRw3blxp/IMPPqjs06dP6d5+8sknpW1Vv8Py8vLKhx9+uHTfPv7442rX1rt372rnmjdvXmXXrl0ry8vLKy+99NLKefPmlbZNmjSpsm/fvqX78XnnnHNO6Xw/+MEPKidNmlTadsstt5S2vfjii6XxKVOmVHbu3LmyvLy88qc//WnlrFmzSvf3pptuqiwvL69s06ZN6fc4Y8aMym7dulWWl5dXnn/++dW+688++2yp7ptuuqk0Pnbs2Mry8vLKLl26VI4dO7badVatm913370SAAC+SjymDwAAWCn69OmTioqKL/zvkUceKe07b9683HDDDUmSq666KjvssENpW6NGjfKzn/0s7du3z/vvv5977rmntO2pp57K6quvniOPPDJdunSpdv7tt98+e++9d5LkjTfeKPJSS4499tisvfbaSZJmzZqlrKwsL7/8ch577LE0b948119/fTbaaKPS/uuvv35+/etfp1GjRnn00UczevToJIse0zZ58uSsueaa6dmzZ7Vz9OrVK9/73veyzz77ZNasWSut9osuuqhUW1lZWb7//e8nSRYuXJijjz66dC+TZJtttsl2222XJBk1atQSj3fmmWdmr732Kn1u1apVrrzyyiTJ7bffXqr92WefzfDhw1O/fv3ccMMN1bqf1l133fzmN7/Jeuutl7fffrva7/7ztfTo0SNJUqdOnTRr1uxLr/OVV17JnDlzsu666+bss89OvXr1Stu+9a1v5aSTTkqSvPXWW1m4cOFi85s1a5b+/fvnW9/6VmmsT58+pXv3wgsvlMYHDBiQjz/+OB06dMiFF16Yxo0bJ1l0f6seJ/jpp5+WHrs4YMCAvP/++9l+++1z0UUXVese69ixYy6++OIkye9///t8+umnSZKxY8eW7sOWW25Z2r9evXo5++yzs+OOO6ZLly6ZPXv2l94XAABYlTymDwAAWCnKy8ur/WP6f/t8aPDcc89l2rRp+da3vrVYqFRl7733zosvvph//etfOfroo5MkP/3pT3Peeefls88+W+Kchg0bJknmzp27nFexbDp06LDY2KOPPpok2WGHHbLWWmsttn3ttdfODjvskEcffTT/+te/0qpVq9IjBadPn56f/OQnOfbYY6sFDRdeeOFKrbvq8YWf9+1vf7v084477rjEupMsMeRo0KBBDj744MXGu3Tpko022ijvvPNOnnrqqeyxxx55/PHHkyTdunXLBhtssNicJk2a5MADD8z111+fxx9/PIcffni17Uu6519m2223zciRI/PJJ59ktdVWW2x71Xdm4cKFmTdvXulzle233z4NGjRYbN6mm26ad955p1pAWHVtvXv3rvZYvSq/+MUv8umnn5auu+q7svfeey9x/5133jlrrrlmpkyZkldffTUdOnRIy5YtkyRPPPFE/vjHP2a//fbLuuuuW7qWG2+88X/eEwAAWNWEUQAAwErx05/+NJ07d16qfceNG5dk0buGDjvssCXuM3369CSLOlY+b7XVVsu8efMybNiwvPHGG5kwYULGjx+fV199NR9//HGSRe+jWhU+/16iKlVdWc8+++wXXtvEiROT/Ofa6tatm1NPPTWXXHJJBg4cmIEDB2b99dfPjjvumG7dumWnnXZaLCRZ0br/O/z4fMfQkkK0/35P1OdtvvnmX1jflltumXfeeSfjx49Pkrz99ttJktatW3/h8dq0aVNt3/+ufXk0aNAgr776al577bW88847eeeddzJ27Nhq368ldUZVBT1LOt5/z5kwYUKSVAsSP2+99dar9rnqu3Lbbbflb3/72xLnVHVEvfXWW+nQoUPatWuXHj165B//+EeuuuqqXHXVVamoqEjXrl2z6667pmPHjqlTx0NQAAD4ahFGAQAAq1xVN8mcOXPy3HPPLdW+yaJ/+P/d736Xm2++OdOmTSuN169fP+3atcvChQszcuTIQmpekvr16y82VlXvRx99lI8++uhL58+cObP0c58+fbLxxhvn5ptvzjPPPJP3338/d999d+6+++40btw43//+93PiiSeulLr/V7C1pC6dL7Pmmmt+4baqR9VV3Zeqzqqq8SVp1KhRtX0/b0n3/H8ZMWJELrvssrz66qulsbKysmy88cbZb7/9vjAISr48hEuqB59V38kvu7bPq7onS/NYyc9/V/r3758777wzd911V0aPHp0xY8ZkzJgx+dOf/pQNNtggP/nJT9K9e/elqgEAAFYFYRQAALDKVYUhu+yyS373u98t9bz+/fvnhhtuSN26dXPkkUdm++23z5ZbbpmNNtoodevWza9+9avlCqO+qJNqeR73V3VtZ599do477rhlmtutW7d069YtM2fOzPDhw/PUU0/lsccey3vvvZf+/funcePGpUcWfpV82X2qClyaN2+e5D9B05e9/6oqeKnad0WMHTs2xx57bObPn5/tttsuBxxwQCoqKrL55punSZMmeeutt740jFoWDRo0yKxZszJnzpyl2r9hw4aZOXNm7r777rRt23apz7PaaqvlyCOPzJFHHpn3338/Tz/9dP7973/n8ccfz7vvvptTTz01AwYMyNZbb728lwIAACuV3n0AAGCV22STTZIkb7755hfuM3HixLzwwguZMmVKkkWPK7v11luTJBdffHH+3//7f9lzzz2z2WabpW7dRX9n98EHHyxTHVXvEJo/f/4St0+aNGmZjpckG2+8cZIvv7bXXnsto0aNKgUy8+fPz9ixYzNq1Kgki97p1L1791xwwQV59NFH07t37yRZaaHJyvbWW28t8RF3STJmzJgkix7llyx611KS0rUuSVUH00YbbbTCtd12222ZP39+dthhh9x666353ve+l/bt25feb7as35kvU/W9/qJOp8ceeyxHHHFE/u///i/J0n1Xhg8fnjfeeKP0HZ01a1ZeeumlvPvuu0mS9ddfPwceeGCuvvrqPP744ykvL89nn32WBx54YGVdFgAArDBhFAAAsMptt912adSoUd5555089dRTS9zn/PPPzyGHHJLLL788STJ16tRSx8mS3jc0ZcqUPP7440mSBQsWVNtW9di5/+6Aqnq83H+/lypZ1J0zYsSIZbiqRXbZZZckycMPP5ypU6cu8bh9+/ZNr169MmTIkCTJP/7xj+y3334544wzFquxTp066dKlS5Ilv9Poq2DatGl57LHHFht/6qmn8u6776Zp06al94lV3Z8nnniiFKh83qxZs3LfffclSbp27brUNXzRe5KqzlFRUVEKHz/v7rvvLv382WefLfX5lqSq3kGDBi1x++DBg/Pss8+W3odWdS8GDBiwxO68ESNGpE+fPtlnn33y3nvvJUmuvPLKHHzwwUvsKGzatGmpG+qr+l0BAOCbSRgFAACsck2aNEnfvn2TJGeeeWa1QOqTTz7JpZdemmHDhmW11VYrPZZu7bXXzhprrJEkufHGG6t1M40aNSrHHXdc6R/5582bV+18VY97q/oH/SrbbLNNkmT8+PG5+eabS+OTJ0/OaaedVjresujcuXM6deqUGTNm5IQTTsj48eNL2z788MOceOKJmT59elq0aJH99tsvyaJQonHjxnnjjTdy6aWXVnvs3bvvvps//elPSZKdd955metZVS644IK8+OKLpc8vv/xyzj777CTJj370o9SrVy/JoiCyc+fOmT9/fn74wx9W6yL68MMPc9JJJ+XDDz9My5Ytc/DBBy/1+at+xx999FG170ZVt9KDDz5Y7Xcxffr0XHrppbn//vtLY//9vVlWRxxxRNZYY42MGDEil156ael4lZWVue222/LAAw9k9dVXzxFHHJEkOfzww9O8efM8++yz+clPflLtvVAvv/xyfvzjHydJdt9999J1VH1n7r777gwaNKhaiPXMM8/koYceSvLV/q4AAPDN451RAABAjTjppJPy5ptv5qGHHsoxxxyTDTbYIM2aNcv48eNLj6/7xS9+Uer0qFu3bk466aRcdtllGTRoUB5//PFsuOGGmT59eiZOnJhkURA0fPjwfPTRR9XOVVFRkcceeyy33HJLnn766fTs2TMnnHBCttpqq+yxxx55+OGHc9lll+WWW27JmmuumXHjxqVu3bo57rjjSkHQsrj66qtz3HHH5aWXXsqee+6ZLbbYInXq1Mmbb76ZTz/9NE2aNMkf/vCHNGjQIEnSuHHjXHnllTn55JNz66235p577slGG22U+fPnZ/z48VmwYEHatGmT448/fkVueWEaNWqU+vXr53vf+1622GKLlJWV5fXXX0+S7Lvvvou95+rqq6/Osccem7Fjx2afffbJFltskbp16+b111/PggULssEGG+T//u//So/SWxpbbrllysrKMmnSpOy5555Zb731cuedd+aYY47J4MGD89FHH2XvvffOpptumrKysrz99tuZP39+WrVqlQ8++CDTpk3LRx99lBYtWiz3fVhnnXXyq1/9KqecckpuueWWDBw4MBtvvHHef//9TJkyJauttlouvPDCUrC09tpr57rrrsuJJ56YgQMH5oEHHsgWW2yRWbNmlYKzioqKXHbZZaVzdOrUKcccc0xuuummnH322bniiiuy/vrr5+OPPy51gR1yyCHZcccdl/s6AABgZdMZBQAA1Ii6devm2muvzTXXXJMdd9wxs2fPzpgxY1K/fv306NEjd9xxx2KdMX379s0NN9yQTp06ZbXVVsvYsWMzf/78dO/ePbfcckt++9vfZvXVV8/rr7+eCRMmlOb94Ac/SO/evdOkSZO8+eabGTt2bGnbr371q5x99tkpLy/P5MmT8+GHH6Z79+4ZOHBgtt122+W6tnXXXTd33XVXzjrrrLRp0ybvvvtu3nzzzayzzjo55JBDMmjQoMUeNdi9e/fcfvvt2WOPPdK4ceO8/vrr+fDDD7PVVlvlnHPOyV/+8pdlCmdWpXr16uWvf/1rDjzwwEyePDnvvfdettlmm1xxxRX55S9/WXqnV5UWLVpkwIABOeuss7LVVlvl3Xffzfjx47P55punX79+uffee9OqVatlqmHTTTfNxRdfnI022iiTJk3KhAkTMnny5LRs2TKDBg1K7969s/766+ftt9/O+++/n1atWuW8887LXXfdVQpulvSowWW10047ZdCgQfnud7+bJk2aZMyYMfnss8/SvXv33HnnnTnwwAOr7d+pU6cMHjw4ffr0yfrrr59x48blgw8+SHl5eU499dTceeedpY7AKuecc04uv/zybL/99vnss88yevTozJkzJzvttFN+/etf58ILL1zh6wAAgJWprHJJD6YGAACA/2H48OHp06dPmjVrluHDh9d0OQAAwFeUzigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDBllZWVlTVdBAAAAAAAAF9POqMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAAChM3ZougFVj5MiRNV0CAAAAAABQy3Xs2HGZ5+iMAgAAAAAAoDA6o75hliexBL4aRo0alSRp3bp1DVcCLA9rGGo/6xhqP+sYaj/rGGo3a7h2W5EnsOmMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKU1ZZWVlZ00VQvJEjRyZJhm42tIYrAQAAAACAr5Z+zfvVdAlfeVU5Q8eOHZd5rs4oAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwqjlcO6556aioiKjRo2q6VIAAAAAAAC+0oRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGLUCZsyYkYsuuihdu3ZNu3bt0rt37wwZMqTaPvPnz88NN9yQvffeO1tvvXU6d+6cH/3oR3n55Zer7Tdw4MBUVFTk5ptvXuw8Rx11VCoqKjJjxowkyfDhw1NRUZE///nP+fGPf5x27dqla9euGTlyZGHXCgAAAAAAsDzq1nQBtdnpp5+e+vXrZ++9987s2bMzePDgnHbaaalXr1523333zJs3L8ccc0xGjhyZ8vLyHHbYYZk8eXIeeeSRPPnkk7n22mvTvXv35T7/b37zmzRq1ChHHnlkxo0blzZt2qzEqwMAAAAAAFhxwqgVsN566+W2225L48aNkyS77rprTjrppNx9993Zfffd88c//jEjR47MgQcemIsuuih16y663a+++moOP/zwnHfeeenSpUuaNGmyXOefPXt27rvvvrRo0WKlXRMAAAAAAHzTjBo1qqZL+FrzmL4V0KdPn1IQlSTdunVLnTp1MnHixCTJvffem4YNG+b8888vBVFJ0qZNmxx++OGZMWNGHn744eU+/7bbbiuIAgAAAAAAvtJ0Rq2ATTbZpNrn1VdfPY0bN87s2bMza9asTJgwIdtuu+0SO586duyYG2+8MaNHj17u82+44YbLPRcAAAAAAFikdevWNV3CV97IkSOXe67OqBVQv379L9w2e/bsJEnTpk2XuH2dddZJknzyySeFnB8AAAAAAOCrQBhVkKrH93344YdL3D5jxowkSbNmzZIkZWVlSZLKysrF9p07d24BFQIAAAAAABRPGFWQJk2aZMMNN8zbb7+dqVOnLrZ9xIgRSZItttgiyaJH/CXJnDlzqu1XWVmZCRMmFFwtAAAAAABAMYRRBerdu3c++eSTXHrppVmwYEFp/NVXX83tt9+eNdZYI7vttluSZLPNNkuSPPnkk/nss89K+/75z3/OtGnTVmndAAAAAAAAK0vdmi7g6+z444/P0KFDM3jw4IwZMyZdunTJlClT8sgjj6SysjLXXHNNmjRpkiTZaqut0qZNmzz//PM5/PDD06lTp4wZMybDhg1L+/bt8+KLL9bw1QAAAAAAACw7nVEFql+/fm6++eaceuqp+fTTT3PnnXdm2LBh2XXXXfPXv/413bt3r7b/7373u/Tu3Ttvv/12br/99sydOze33HJL2rdvX0NXAAAAAAAAsGLKKisrK2u6CIo3cuTIJMnQzYbWcCUAAAAAAPDV0q95v5ou4SuvKmfo2LHjMs/VGQUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYerWdAGsWv2a96vpEoDlNGrUqCRJ69ata7gSYHlYw1D7WcdQ+1nHUPtZx1C7WcPfXDqjAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAoTN2aLoBVq//H/Wu6BCBJv+b9aroEAAAAAIBVQmcUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRi2H3/zmN6moqMhdd9212LZ33303rVq1yhlnnJEkmTVrVn75y1+me/fu2XrrrbPTTjvlZz/7WaZMmbLEuT/72c/SvXv3tG3bNttss00OPPDA3HnnndX2u+6661JRUZGnn346Bx98cLbeeuvsueeemT17djEXDAAAAAAAsJyEUcvhgAMOSFlZWQYPHrzYtsGDB6eysjK9evXKzJkzc9hhh+UPf/hDNtxww/Tp0yfbbLNNBgwYkIMPPjgfffRRad7EiRNz0EEH5b777kuHDh3St2/f9OjRI2+88UZ+/vOf5/bbb1/sXGeeeWYaNGiQo446Kp07d07jxo0LvW4AAAAAAIBlVbemC6iNNtxww2y33XYZMWJEPvroo6yzzjqlbYMHD06LFi3yne98JxdffHHGjh2bCy64IEcccURpn0cffTQnnnhiLrnkkvTv3z9J8vvf/z4ff/xxbrrppnznO98p7XvkkUfm4IMPzv33358jjzyyWh3rrbdebrnlltSpI1OE2mbUqFHLPGfu3LnLPReoedYw1H7WMdR+1jHUftYx1G7W8DeXFGM59erVKwsXLsyDDz5YGnvttdcybty47LvvvqmsrMx9992XLbfcsloQlSS77757tt122/zjH//IrFmzkiT7779/Lr300mpBVJK0a9cuDRo0WOJj/Xr06CGIAgAAAAAAvtJ0Ri2nvfbaKxdddFEGDx6cvn37JknpsX0HHHBA3nrrrcyZMyefffZZrrvuusXmz5s3L5999lnGjBmTjh07Zrvttst2222XadOmZdSoUXnnnXfy1ltv5YUXXijt+9823HDDQq8RKE7r1q2XeU7VX4wsz1yg5lnDUPtZx1D7WcdQ+1nHULtZw7XbyJEjl3uuMGo5NWnSJN27d8/999+f8ePHp2XLlrn//vtTXl6e1q1bl34pb775Zv7v//7vC48zffr00v8vu+yy3H///fn0009TVlaWDTbYIF26dMlrr722xLkNGjRY+RcGAAAAAACwEgmjVkCvXr1y//33Z8iQIenYsWM++uijHH300UmSxo0bJ1nUJXXllVf+z2OdddZZeeKJJ3LooYfmgAMOSHl5eZo0aZLkPx1XAAAAAAAAtY0wagV85zvfSYsWLfLYY49lxowZqVOnTvbbb78kyaabbpp69erl1VdfTWVlZcrKyqrNvfnmmzNnzpwcdthhWW211fLEE09k6623zi9+8Ytq+02cODHz5s1LZWXlKrsuAAAAAACAlaVOTRdQm6222mrZb7/98tJLL+XBBx9Mly5dsu666yZJ6tevn7333jvjxo3LTTfdVG3e8OHDc+WVV+aee+7JmmuumdVXXz116tTJjBkzMn/+/NJ+n3zySS666KIkyaeffrrqLgwAAAAAAGAl0Rm1gnr37p0bb7wx77//fk477bRq284555w8//zzueKKK/Loo4+mXbt2+fDDD/Pwww+nbt26ufTSS1OnTp00bNgwPXr0yN///vccfPDB2XHHHTNnzpw89thjmTx5ctZcc83MnDkzCxcuTJ068kMAAAAAAKD2kGysoPLy8my++ealQOnz1lprrQwYMCDHHntsPvzww9x222159tlns9tuu2XAgAHp3Llzad9LL700Rx99dGbOnJnbb789Tz75ZNq2bZs777wzvXr1yieffJLhw4ev6ssDAAAAAABYITqjVtDMmTMzceLE7LnnnmncuPFi25s1a5Zzzjkn55xzzpcep0mTJvnJT36Sn/zkJ4tta9euXbXxU045JaeccsqKFw8AAAAAAFAwnVEr6A9/+EPmzZuX733vezVdCgAAAAAAwFeOzqjldMQRR2TatGkZN25cunTpkk6dOtV0SQAAAAAAAF85OqOW05prrpmJEydmxx13zNVXX13T5QAAAAAAAHwl6YxaTtdff31NlwAAAAAAAPCVpzMKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDC1K3pAli1+jXvV9MlAAAAAAAA3yA6owAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKEzdmi6AVav/x/1rugS+Zvo171fTJQAAAAAA8BWmMwoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKEytDaMGDhyYioqK3HzzzV+63/Dhw1NRUZFLLrlk1RS2BDNmzEhFRUWOOuqoGqsBAAAAAACgJtSt6QKKtsEGG+Tkk09O+/bta7oUAAAAAACAb5yvfRi14YYb5pRTTqnpMgAAAAAAAL6Rau1j+gAAAAAAAPjqW+4w6qCDDkrbtm0zb968auMHHnhgKioq8vTTT1cbv+SSS1JRUZEJEyYkSR588MEceuih6dChQ7bZZpsceuiheeCBB6rNmThxYioqKtK/f/9cfPHF6dChQzp37pwhQ4YssaaZM2emV69eadWqVe66664kS35n1FFHHZXddtstH3zwQc4444x07tw57du3zxFHHJHhw4cvdtx33nknP/7xj/Od73wn22yzTY4//vi88cYb6dGjx2LvgZo4cWLOPPPM0r4nn3xy3nvvvSXWO3Xq1FxxxRXp2bNn2rdvn/bt22efffbJDTfckAULFiRJ3nvvvbRq1SqHHXbYEo/Rp0+ftG/fPrNmzVridgAAAAAAgJq03I/p23nnnfPKK6/kueeeyw477JAkmT59ekaNGpUkGTFiRGk8SZ588slsvvnmadmyZa644orceOONadGiRfbdd98kyeOPP54f//jHee2113LWWWdVO9eAAQOSJIcddljefPPNdOjQYbGw65NPPskJJ5yQUaNG5YILLsjBBx/8pfXPnj07hx9+eBo2bJhevXpl8uTJefDBB3Pcccfl3nvvzZZbbpkkGT9+fA499NBMmzYt3bt3z4YbbpjHHnsshx9+eBYuXJj11luvdMwPPvgghx56aCZPnpzddtst3/72t/Pkk0/m+9///mLnnzlzZr73ve/l/fffz2677Zbu3btn6tSp+cc//pFrrrkm06dPzznnnJNvf/vb6dSpU0aMGJF33303G2ywQbXzjRgxIj179kyTJk2+/BcGAAAAAABQA5Y7jOrWrVuuv/76PP3006XQ6ZlnnsnChQvTqFGjjBgxorTvxIkT89Zbb+XYY4/Ns88+mxtvvDFbbbVV/vSnP2WttdZKsqhL6Oijj84f//jH7LLLLunUqVNp/pQpU3LfffelVatWS6zl008/zSmnnJKRI0fmvPPOyxFHHPE/6582bVo6duyY/v37Z/XVV0+SbLnllrnmmmsyaNCgnHnmmUmSyy67LFOnTk3//v2z1157JUlOP/309O3bNyNHjqx2zGuuuSaTJk3K5Zdfnt69eydJ5syZkxNOOCGTJk2qtu+dd96ZCRMm5OKLL64WnJ188snZY489Mnjw4JxzzjlJkl69euWZZ57JAw88kB/84Aelfe+///4sXLgwBxxwwP+8XihKVQBN8ebOnZvEPYfayhqG2s86htrPOobazzqG2s0a/uZa7sf0tWvXLs2bN6/WoTRs2LA0a9YsPXr0yEsvvZT58+cnSYYOHZok2WWXXTJw4MAkydlnn10KopJkrbXWyhlnnJEkueeee6qda+ONN/7CIKqysjLnnHNO/vWvf+WMM85I3759l/oajj322FIQlSwK2JLk3XffTbIoIHviiSey3XbblYKoJKlXr14prKoyf/78PPzww9lyyy1LQVSSNGrUaLF9k6Rr1675xS9+kV69elUbX3/99dOyZctMnTq1NLbnnnumYcOGuf/++6vt+7e//S1rr712dtxxx6W+ZgAAAAAAgFVpuTuj6tSpk65du+bBBx/MzJkz07Rp0wwbNiydOnVKhw4dMmjQoLz88svp2LFjnnzyyTRt2jQdO3bMFVdckTp16qRjx46LHbNqbPTo0dXGN9xwwy+s48Ybb8xHH32UOnXqZOedd16ma9hkk02qfa561F1ViPbqq69m4cKFadeu3WJz27dvn7p1/3P7JkyYkDlz5mTrrbdebN+tt966WuiVJFtttVW22mqrzJ49Oy+++GLGjx+ft99+Oy+//HLGjx+fzz77rFpd3bt3z+DBgzNu3LhsscUWGTt2bMaMGZM+ffpUqwNWtdatW9d0Cd8YVX8x4p5D7WQNQ+1nHUPtZx1D7WcdQ+1mDddu//20uGWx3J1RyaJOos8++yzDhw/P5MmTM27cuGy//fbZfvvtkyTPPvtsPv300wwbNixdu3ZN3bp1M2vWrNSvXz/16tVb7HhNmzZNw4YNS616VerXr/+FNXz00UfZbbfdsnDhwvy///f/snDhwqWu/79rKCsrS7Ko2ypJPv744yTJt771rcXmrrbaatU6u6ZPn54kady48RL3/e93Os2bNy+XXXZZdtxxxxxxxBH5yU9+kkGDBmXttddO8+bNFztGVQfV4MGDkyzqikriEX0AAAAAAMBX2gqFUV27dk2dOnUybNiwPPPMM0mS7bffPltssUXWXnvtjBgxIi+88EJmzZqVXXbZJcmisGbu3LmZMWPGYsebN29ePvnkkyWGMV/kgAMOyG9/+9vsu+++eemll3L77bevyCVVUxUgzZo1a4nbZ8+eXfp5zTXXTJLMnDlzsf0qKysXC9guv/zy3Hzzzdl5551z6623Zvjw4fnXv/6Vq6++Ok2bNl3sGN/5zney7rrr5qGHHkqSDBkyJFtsscUSO7EAAAAAAAC+KlYojGrevHnatWuXYcOGZeTIkWnWrFkqKiqSLAqlnnvuuTz++OPVHqFX9e6nJbVzjRw5MpWVldliiy2WuoatttoqSXLuueemSZMmufbaa/PBBx+syGWVtGnTJmVlZXnppZcW2zZu3LhqYdRGG22Upk2b5vnnn1/ivp988km1sfvvvz9rr712+vfvn86dO6dZs2ZJkk8++STvvfdekv90aCWLHou433775e23387DDz+ciRMn6ooCAAAAAAC+8lYojEqSnXfeOa+//noee+yxbLfddqVH3W2//faZPXt2/vrXv6Zdu3alR9odeOCBSZJf/epXmTp1auk4U6dOzZVXXplk+R4916JFi/Tr1y+zZ8/OhRdeuKKXlSRZd911s+OOO+app57KE088URqfP39+rrrqqmr7rr766tl3333zzjvv5Kabbqq279VXX73YsevXr5958+ZV6xD77LPPcskll5SCq08//bTanKpH9V1++eUpKyvLfvvtt8LXCAAAAAAAUKS6K3qAbt265de//nXefffdHH300aXxzp07J1n02Lpu3bqVxjt16pRjjjkmN910U/bff//suuuuSZLHHnsskyZNyvHHH59OnTotVy1HHHFE7r333jz66KP5xz/+kR49eqzAlS1y/vnn55BDDsmPfvSjdO/ePeuuu27+/e9/l4K0OnX+k+edfvrpefrpp3P55Zdn6NCh2XzzzfP0009n2rRpi733ar/99suNN96Ygw46KN27d8+CBQsydOjQvPXWW1lrrbUyderUTJs2Leuss05pzpZbbpk2bdrk1VdfTefOnbP++uuv8PUBAAAAAAAUaYU7o9q0aZMWLVok+U8AlSSbb755abzqfVFVzj333Fx11VXZYIMNMnjw4AwZMiSbbrpprrvuupx55pnLXctqq62Wn//85ykrK8tFF130he96WhabbbZZ7rzzznTr1i1PPfVU7rrrrmy00Ua55ZZbkiQNGzYs7bvmmmvmzjvvzKGHHpoxY8bkr3/9a771rW/l5ptvTr169aod9/TTT88pp5ySOnXq5M9//nMeeeSRbLDBBvnTn/6UH/7wh0lSrRurSs+ePZMsX/cYAAAAAADAqlZW+fkXE1HNwoULM2HChHz729/O6quvXm3bhAkT0r179xx22GH5+c9/vspqOuOMM/Loo49m6NChadKkyVLPq3pH19DNhhZVGt9Q/Zr3q+kSvjFGjRqVJGndunUNVwIsD2sYaj/rGGo/6xhqP+sYajdruHaryhk6duy4zHNXuDPq66ysrCy9evXKfvvtl/nz51fb9qc//SlJ9W6woo0ZMyYPP/xwevbsuUxBFAAAAAAAQE1Z4XdGfZ2VlZXl0EMPzY033pj9998/O++8c1ZbbbU899xzeeGFF9K1a9fstddehdfxxz/+MUOGDMm4ceNSVlaWE044ofBzAgAAAAAArAzCqP/hrLPOymabbZa77ror9957bxYsWJANN9wwZ5xxRo455piUlZUVXsM666yTt99+Oy1atMh5552XTTbZpPBzAgAAAAAArAzCqP+hTp06Ofjgg3PwwQfXWA37779/9t9//xo7PwAAAAAAwPLyzigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAApTt6YLYNXq17xfTZcAAAAAAAB8g+iMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMHVrugBWrf4f96/pEvia6Ne8X02XAAAAAABALaAzCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijltJLL72UoUOH1nQZAAAAAAAAtYowaik8/vjjOeSQQzJu3LiaLgUAAAAAAKBWEUYthalTp2bhwoU1XQYAAAAAAECtI4wCAAAAAACgMMKo/+Hcc8/NeeedlyS57LLLUlFRkYkTJyZJnn766RxzzDHp2LFjOnTokEMOOSQPPfTQYseoqKjI+eefn2eeeSaHH3542rdvn65du+ZXv/pVPvvss4wbNy7HHXdcttlmm+y000656KKLMnfu3NL84cOHp6KiInfddVfuuOOOdO/ePe3bt8/++++fgQMHrpobAQAAAAAAsByEUf9D9+7ds/vuuydJunbtmpNPPjlrrLFG7rrrrhxzzDEZM2ZM9t577xxyyCGZMmVK+vXrlxtuuGGx47z44os59thjs9Zaa+Wwww5LvXr18rvf/S4XXHBBDjvssCxcuDCHHXZY1lxzzdx+++255pprFjvGnXfemUsuuSTt27fPQQcdlGnTpuW8887LddddV/h9AAAAAAAAWB5llZWVlTVdxFfdwIEDc9555+W8885L375988EHH6RHjx5p2bJl7rjjjjRv3jxJ8sknn6Rv37558cUXM2jQoJSXlydZ1BmVpDQ/Sd5888307NkzSXLsscfmnHPOSZLMmjUr3bp1S/369fPUU08lWdQZ1adPnyRJ//79s9deeyVJpkyZkkMOOSTvv/9+HnjggWyyySZfeA0jR45MkgzdbOhKvDN8k+3xwR41XcI3TlXHZMOGDWu4EmB5WMNQ+1nHUPtZx1D7WcdQu1nDtducOXOSJB07dlzmuTqjlsPf/va3zJ8/P6eeemopiEqSBg0a5NRTT83ChQtz7733VptTr169HH744aXPm222WWnuscceWxpv0qRJNt9880yZMiWffPJJtWNsu+22pSAqSdZee+2ccMIJWbBgQYYMGbJSrxEAAAAAAGBlqFvTBdRGr7zySpJF74x6/fXXq22rSgZHjx5dbXz99ddPvXr1qo01atQoc+fOTYsWLaqN169fP0kyf/78NGjQoDS+/fbbL1ZLu3btlng+KFrr1q1ruoRvnFGjRiVx76G2soah9rOOofazjqH2s46hdrOGa7eqJ7AtD2HUcpg5c2aS5C9/+csX7jN9+vRqn7+o7XD11Vdf6vOus846i41VBVmzZs1a6uMAAAAAAACsKsKo5dCoUaMkySOPPJKWLVuusvPOmzdvsbEZM2YkSZo1a7bK6gAAAAAAAFha3hm1FMrKyqp9rqioSJK8/PLLi+379ttv54orrsg///nPlV7Hks73wgsvJEnat2+/0s8HAAAAAACwooRRS6Fu3UUNZJ9++mmSZP/9989qq62Wa6+9NpMmTSrtt2DBglx00UW58cYbM23atJVexz/+8Y88++yzpc+TJk3Kb3/72zRq1Cg9e/Zc6ecDAAAAAABYUR7TtxTWXXfdJMmdd96Z6dOn56ijjspZZ52Vyy+/PPvuu2922223rLnmmvnXv/6VN954I7vuumv233//lV5HgwYN0rdv3+y1115p0qRJHnnkkUyePDkXXXRR6d1RAAAAAAAAXyXCqKXQqVOnHHHEERk0aFDuuOOOfOc738kxxxyTzTbbLDfeeGMefvjhLFy4MC1btsy5556bI444otRNtTL16tUr6667bu64445MmzYtrVu3ziWXXJJu3bqt9HMBAAAAAACsDMKopVBWVpYLLrggF1xwQbXxbt26LVUQNGbMmCWOf9F7pW677bYvrOP444/P8ccf/z/PCQAAAAAA8FXgnVEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFMY7o2qBzp07f+F7pwAAAAAAAL7KdEYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFCYujVdAKtWv+b9aroEAAAAAADgG0RnFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhalb0wWwavX/uH9Nl8DXQL/m/Wq6BAAAAAAAagmdUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRXzEvvfRShg4dWvo8ceLEVFRU5MQTT6zBqgAAAAAAAJaPMOor5PHHH88hhxyScePG1XQpAAAAAAAAK4Uw6itk6tSpWbhwYU2XAQAAAAAAsNIIowAAAAAAACjMNzKMOvfcc7PVVlvl448/zk9/+tN06dIl22yzTY477ri88847mT9/fq666qp07do12267bY466qiMHj262jFeeumlnHjiiencuXPatm2bvffeOzfccEPmz59fbb+jjjoqu+22Wz744IOcccYZ6dy5c9q3b58jjjgiw4cPr1bTeeedlyS57LLLUlFRkYkTJ1Y71hNPPJHvfe97adeuXXbYYYecd955mTp1akF3CQAAAAAAYMXVrekCakplZWX69OmThQsXpnfv3hk7dmyGDh2aE044IRtvvHHGjh2bvfbaK5MmTcpDDz2UH/zgB/n73/+ehg0b5pFHHkm/fv1Sp06ddO/ePd/61rcybNiwXHPNNXnyySdz0003pV69eqVzzZ49O4cffngaNmyYXr16ZfLkyXnwwQdz3HHH5d57782WW26Z7t27Z8aMGXn00UfTtWvXdOjQIWussUZmzJiRJHnuuefy+OOPZ5dddsmRRx6Z4cOHZ+DAgRkzZkzuueeelJWV1dStBAAAAAAA+ELf2DBq4cKFadiwYW6//fZScHTooYfm+eefz/z58/O3v/0tTZo0SZKcd955GThwYJ555pl07NgxP/nJT9KgQYPceuutadOmTZJkwYIFOffcczN48OD84Q9/yEknnVQ617Rp09KxY8f0798/q6++epJkyy23zDXXXJNBgwblzDPPrBZG7bTTTunbt2+SlMKojz/+OL/85S+z3377ler/7ne/m1dffTWjRo3KVltttUruGyTJqFGjarqEb6S5c+cmcf+htrKGofazjqH2s46h9rOOoXazhr+5vpGP6aty2GGHVetg2mabbZIkhxxySCmISpJ27dolSd5999088sgjmT59evr06VMKopKkbt26pZDqnnvuWexcxx57bCmISpJu3bqVjrk0WrZsWQqikqROnTrZeeedkyQTJkxYqmMAAAAAAACsat/Yzqgk2Wijjap9btSoUZJkww03rDZev379JMn8+fPzzjvvJEk6deq02PHWWmutbLrpphk1alRmzpyZpk2blrZtsskm1fatCrv++x1TX2TjjTdebKxZs2ZJkjlz5izVMWBlad26dU2X8I1U9Rcj7j/UTtYw1H7WMdR+1jHUftYx1G7WcO02cuTI5Z77je6Mqgqf/tvnu6X+26xZs5KkWufU562zzjpJ/tNu+EXHrHrHU2Vl5VLVWhWILcnSHgMAAAAAAGBV+0aHUcujcePGSZKPPvpoidur3vFU1bUEAAAAAADwTSaMWkZV7YNLakebNWtWRo0alY033vhLu6u+SFW3FAAAAAAAwNeFMGoZde/ePU2bNs2f//znvPrqq6XxBQsW5JJLLsknn3ySAw44YLmOXbfuold4ffrppyulVgAAAAAAgJpWt6YLqG2aNGmSSy+9NKeffnoOPfTQ9OjRI2uvvXaGDRuWsWPHZrvttsvxxx+/XMded911kyR33nlnpk+fnqOOOmpllg4AAAAAALDK6YxaDnvssUf+/Oc/Z8cdd8yTTz6ZAQMGJEnOPvvs3Hzzzcv1iL4k6dSpU4444ohMnz49d9xxR954442VWTYAAAAAAMAqV1ZZWVlZ00VQvKp3XA3dbGgNV8LXQb/m/Wq6hG+kUaNGJfnPu+uA2sUahtrPOobazzqG2s86htrNGq7dqnKGjh07LvNcnVEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFKZuTRfAqtWveb+aLgEAAAAAAPgG0RkFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBh6tZ0Aaxa/T/uX9Ml1Cr9mver6RIAAAAAAKBW0xkFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFFL4a233sqQIUNqugwAAAAAAIBaRxj1P4wePTr77bdfnnvuuZouBQAAAAAAoNYRRv0P06dPz6efflrTZQAAAAAAANRKwigAAAAAAAAK840Oo8aOHZuzzjor3bp1y9Zbb51tt902hx56aP7+978nSa677rr06dMnSXLrrbemoqIiw4cPL81/9dVXc+KJJ6Zz585p165dDjjggNx5552prKysdp7ddtstffv2zZgxY3Lcccdlm222SefOnXPBBRdk7ty5+fDDD3PaaaelY8eO2WGHHXLmmWdm6tSppfkTJ05MRUVFrrnmmgwZMiT77LNP2rVrlz333DM33nhjFi5cuAruFgAAAAAAwLIrq/zv5OQb4qWXXspRRx2VevXqZY899shaa62V8ePH59FHH82CBQtyww03pFGjRrn33ntz7733pn379tlpp53Su3fvbLjhhnniiSdy8sknZ/XVVy/Nf/LJJzN27Nh873vfy0UXXVQ612677ZY6depk6tSp6dChQyoqKvLkk0/m9ddfz5577plXXnkl3/rWt9KxY8c8//zzef7559O9e/f85je/SbIojNp9993Tpk2bvPbaa9lll12y0UYb5Yknnsjbb7+d3r175/LLL//S6x05cmSSZOhmQ4u7qV9De3ywR02XACVz585NkjRs2LCGKwGWhzUMtZ91DLWfdQy1n3UMtZs1XLvNmTMnSdKxY8dlnlt3ZRdTW/Tv3z8LFizIwIEDs/nmm5fGH3zwwZx++um5//77c/XVVydJKYw65ZRTkixaMOeee26aNm2aAQMGZMMNN0ySnHnmmTnttNMyYMCAdO/ePd26dSsdd8KECenTp0/OP//8JMmPfvSj7Lzzzvn73/+evfbaK9dee23Kysry2WefpWfPnnnkkUcyd+7caovy1Vdfzdlnn53jjjsuSXLaaaflmGOOyb333pvevXunc+fOxd40AAAAAACAZfSNDaP69u2bgw46qFoQlaQU6EyZMuUL5/7zn//M1KlTc/bZZ5eCqCSpU6dOzjjjjPz973/PPffcUy2MqjpnlTXWWCObb755XnnllRxzzDEpKytLkqy22mpp06ZNxo8fn/fee69afRtssEGOPvro0udGjRrltNNOS9++fTN48GBhVAFat25d0yVAyahRo5L4XkJtZQ1D7WcdQ+1nHUPtZx1D7WYN125VT2BbHt/YMGqnnXZKkkyaNCmjR4/OO++8k7feeqt0Mz/77LMvnPvKK68kWdSpdN111y22fbXVVsvo0aOrja2++urZYIMNqo01atQoSaoFWklSv379JMn8+fOrjW+zzTapW7f6r6xt27ZJstj5AAAAAAAAvgq+sWHUe++9l4svvjj//Oc/U1lZmTp16mSTTTZJx44d89prr33p3JkzZyZJHnjggS/cZ/r06dU+N2jQ4Av3rVev3lLVvO666y421qRJkzRs2LBUEwAAAAAAwFfJNzKMqqyszAknnJBx48blhBNOSPfu3bPlllumQYMGmTx5cu66664vnV/V0XTzzTdnhx12WBUlJ0nmzZu32Nj8+fPzySefpHnz5qusDgAAAAAAgKVVp6YLqAljxozJ2LFj06NHj5x++ulp27ZtqXPpjTfeSLIosEpSepfT51VUVCT5z+P6Pm/atGm55JJLMmjQoJVe98svv7zY2IsvvpjKysq0b99+pZ8PAAAAAABgRX0jw6iqx+JNnTq12vi0adNy5ZVXJkkWLFiQJKV3NH366ael/Xr06JEmTZrkj3/8Y956661qx7jqqqty66235p133lnpdb/44ot58MEHS59nzZqVq6++OnXq1Env3r1X+vkAAAAAAABW1DfyMX2bbLJJ2rVrlxEjRuTwww/Ptttum48//jiPPPJI5s+fn4YNG+bjjz9O8p/3NA0ZMiSNGjVK7969s+WWW+biiy/OmWeemd69e6d79+5ZZ511MmLEiLz00ktp27Ztjj322JVed9OmTfPjH/84Q4YMybrrrpvHH388EyZMyIknnphWrVqt9PMBAAAAAACsqG9kZ1SdOnVy/fXX58ADD8zEiRNz22235dlnn83OO++ce+65JzvuuGPefvvtvPPOO9lggw1y2mmnpaysLHfccUdeeumlJEnPnj1z++23p0uXLnnyySdz++23Z9asWTnxxBNz8803p3Hjxiu97u233z6XXHJJxo4dm7vuuitrrLFGrrzyyvTr12+lnwsAAAAAAGBlKKusejkSX1kTJ07M7rvvnt133z3XX3/9ch1j5MiRSZKhmw1dmaV97fVrLujjq2PUqFFJktatW9dwJcDysIah9rOOofazjqH2s46hdrOGa7eqnKFjx47LPPcb2RkFAAAAAADAqiGMAgAAAAAAoDDCKAAAAAAAAApTt6YL4H/bcMMNM2bMmJouAwAAAAAAYJnpjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDB1a7oAVq1+zfvVdAkAAAAAAMA3iM4oAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKU7emC2DV6v9x/5ouodbo17xfTZcAAAAAAAC1ns4oAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwtSaMOvfcc1NRUZFRo0bVdCnVXHfddamoqMgjjzzyP/e95JJLUlFRkeHDh5fGdtttt2y33XbV9vvoo49yzz33rPRaAQAAAAAAVrW6NV1Abbf99tvn5JNPzqabbrpc8/v06ZP58+eXPk+ZMiV77bVXunTpkoMOOmhllQkAAAAAAFAjhFErqHPnzuncufNyz+/bt2+1z3Pnzs3s2bNXsCoAAAAAAICvhlrzmD4AAAAAAABqn1oXRs2YMSMXXXRRunbtmnbt2qV3794ZMmRIafuXvcPpv9/PNHz48FRUVGTQoEEZMGBAevbsmbZt22avvfbKoEGDkiSPPvpoDjzwwLRv3z577rln7rjjjmrH/KLz3X333dl///3Tvn377LHHHvnLX/6yxOv5fE0DBw7M7rvvXjpvRUVFBg4cmKOPPjoVFRUZP378YvPvu+++VFRUZMCAAUtz+wAAAAAAAFapWveYvtNPPz3169fP3nvvndmzZ2fw4ME57bTTUq9evVKQs6xuuummjB8/Pvvss0+6dOmSe++9N2effXZGjx6d2267LXvttVe22267/O1vf8uFF16YddddN927d//C41177bX57W9/mw022CDf/e53M2nSpFx44YVZa621vrSO1q1bp0+fPrn11luz6aabZp999knr1q1TVlaWYcOGZfDgwTn55JOrzfnb3/6W+vXrp2fPnst17QAAAAAAAEWqdWHUeuutl9tuuy2NGzdOkuy666456aSTcvfddy93GDV27NgMGDAgW2+9dZKkVatWueCCC3LjjTfmd7/7XXbZZZckSffu3XPUUUfl/vvv/8Iw6u23384f/vCHtG7dOrfeemvWWGONJMljjz2WH/3oR19aR+vWrXP00Ufn1ltvzWabbZZTTjklSbLRRhvlwgsvzAMPPFAtjJo0aVKGDRuWHj16pGnTpst17XyxUaNG1XQJUM3cuXOT+G5CbWUNQ+1nHUPtZx1D7WcdQ+1mDX9z1brH9PXp06cURCVJt27dUqdOnUycOHG5j9mxY8dSEJUk2267bZJk0003LQVRSdK+ffskybvvvvuFx3rooYeyYMGC/PCHPywFUcmi0Kxr167LVV/jxo3To0ePvPnmm3nttddK4w888EA+++yzHHDAAct1XAAAAAAAgKLVus6oTTbZpNrn1VdfPY0bN87s2bOX+5gbb7xxtc8NGzZMkmy44YbVxuvXr58kmT9//hcea/To0UlSLdyqss022+TJJ59crhp79eqVQYMGZfDgwdlqq62SLHpEX/PmzbPTTjst1zH5cq1bt67pEqCaqr8Y8d2E2skahtrPOobazzqG2s86htrNGq7dRo4cudxza11nVFUgtDJVhU//rV69est8rBkzZiRJte6tKs2aNVvm41Xp0qVL1ltvvQwZMiSVlZV544038uqrr2afffbJ6quvvtzHBQAAAAAAKFKtC6P+l7KysiTJwoULF9tW9TzKIlU9mm/WrFmLbVuR7q06depk//33z/vvv5/nn38+Q4YMSRKP6AMAAAAAAL7SvnZhVFWX0Jw5c6qNz5gxI9OmTSv8/G3atEmy5Ha1V1555X/OrwrTlqRXr15JksceeyyPP/54Nt1007Rr1275CgUAAAAAAFgFvnZh1GabbZYkefzxx6uN33DDDUvsllrZ9t5779SvXz+//e1vM2nSpNL4s88+m3/+85//c37duote4/Xpp58utm3zzTfP1ltvncGDB+eVV17RFQUAAAAAAHzl1a3pAla2bt26ZZ111smQIUMyc+bMtGrVKs8//3xef/31lJeX5/333y/0/BtssEHOOeecXHjhhendu3e6d++eWbNm5aGHHsr666+fd95550vnN2/ePPXq1cvw4cNz2WWXpUePHtluu+1K23v37p2LLrooZWVl2X///Qu9FgAAAAAAgBX1teuMqlevXm677bb06NEjL7zwQu688840bdo0d955Z1q2bLlKajjiiCPym9/8Juuvv37uvffePPvsszn11FNzxBFH/M+59erVywUXXJA111wzf/7znzNs2LBq23v27Jkk2W677bLBBhsUUj8AAAAAAMDKUlZZWVlZ00Ww9IYOHZrjjjsuF198cQ4++OClnlf1Dquhmw0tqrSvnX7N+9V0CVDNqFGjkiStW7eu4UqA5WENQ+1nHUPtZx1D7WcdQ+1mDdduVTlDx44dl3nu164z6uts/vz5+d3vfpcmTZpk7733rulyAAAAAAAA/qev3Tujvo7eeeednHLKKZk2bVo++OCDnHrqqWncuHFNlwUAAAAAAPA/6YyqBdZee+3MmDEjM2fOzJFHHpkTTjihpksCAAAAAABYKjqjaoHGjRvnscceq+kyAAAAAAAAlpnOKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAAClO3pgtg1erXvF9NlwAAAAAAAHyD6IwCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwdWu6AFat/h/3r5Hz9mver0bOCwAAAAAA1CydUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYtRLdf//9mTBhQunzwIEDU1FRkZtvvrnmigIAAAAAAKhBwqiV5KqrrsoZZ5yRWbNm1XQpAAAAAAAAXxnCqJVkypQpNV0CAAAAAADAV44wCgAAAAAAgMLUyjDqoIMOStu2bTNv3rxq4wceeGAqKiry9NNPVxu/5JJLUlFRUXqf09NPP51jjjkmHTt2TIcOHXLIIYfkoYceWuK57rvvvhx11FHp1KlTtt5663Tt2jVnnHFGtXdD7bbbbrn33nuTJL169cpuu+1W7RiVlZW56aabsueee2brrbfO7rvvnuuvvz4LFixY7HxLU9vEiRNTUVGR/v375+KLL06HDh3SuXPnDBkyZCnvIAAAAAAAwKpRt6YLWB4777xzXnnllTz33HPZYYcdkiTTp0/PqFGjkiQjRowojSfJk08+mc033zwtW7bMXXfdlf/3//5f1lprrey9995p1KhRHn300fTr1y+nn356fvjDH5bmXXHFFbnxxhvTqlWr9O7dO2VlZRkxYkTuv//+jBw5Mg899FAaNGiQPn365N57783o0aNzyCGHZLPNNqtW7x/+8IfMnTs3PXv2zM4775yHH344/fv3z/Tp03PeeeeV9luW2pJkwIABSZLDDjssb775Zjp06LBS7/PKVPW7AZbf3Llzk1hPUFtZw1D7WcdQ+1nHUPtZx1C7WcPfXLUyjOrWrVuuv/76PP3006XQ6ZlnnsnChQvTqFGjjBgxorTvxIkT89Zbb+XYY4/NBx98kAsvvDCbbbZZ7rjjjjRv3jxJcvrpp6dv377p379/dtttt5SXl+fDDz/MzTffnE6dOuWWW27JaqutVjrmD37wgzzxxBN59tln07Vr1/Tt2zejR4/O6NGjc9hhh6V169bV6p07d27uueeeUkj1/e9/P3vssUcGDhyYc845J3Xq1Fmm2qpMmTIl9913X1q1alXMjQYAAAAAAFhBtTKMateuXZo3b17tcXzDhg1Ls2bN0q1bt/z973/P/PnzU69evQwdOjRJsssuu+Rvf/tb5s+fn1NPPbUU9iRJgwYNcuqpp+aYY47Jvffem3POOSf16tXLlVdemS222KJaEJUknTp1yhNPPJEpU6YsVb09e/as1i217rrrpk2bNhk5cmSmT5+e5s2bL1NtVTbeeONaE0T9d0AHLLuqvxixnqB2soah9rOOofazjqH2s46hdrOGa7eRI0cu99xaGUbVqVMnXbt2zYMPPpiZM2emadOmGTZsWDp16pQOHTpk0KBBefnll9OxY8c8+eSTadq0aTp27Jg77rgjyaL3Mr3++uvVjjlnzpwkyejRo5MkzZs3z3777ZeFCxdm7NixeeONNzJhwoSMGTMmTz31VJJk4cKFS1XvJptssthYs2bNSudt3rx5XnnllaWurcqGG264VOcHAAAAAACoKbUyjEoWPapv8ODBGT58eDp06JBx48blkEMOyfbbb58kefbZZ9OuXbsMGzYsO+20U+rWrZuZM2cmSf7yl7984XGnT59e+vnhhx/O1VdfnbfffjtJ0qhRo2y99dZp1apVnnrqqVRWVi5VrfXq1fvCbVXHWNbakqR+/fpLdX4AAAAAAICaUmvDqK5du6ZOnToZNmxY5s+fnyTZfvvts8UWW2TttdfOiBEjsu2222bWrFnZZZddkiwKk5LkkUceScuWLb/0+C+++GL69euX9dZbL7/61a/Stm3btGzZMmVlZfn9739f6o5aWZalNgAAAAAAgNqiTk0XsLyaN29e6nwaOXJkmjVrloqKiiSLQqnnnnsujz/+eOrUqZOdd945SUrbX3755cWO9/bbb+eKK67IP//5zyTJAw88kIULF+ZnP/tZ9tlnn2y00UYpKytLkrz55ptJUq0zqmrb8lqW2gAAAAAAAGqLWhtGJcnOO++c119/PY899li22267UiC0/fbbZ/bs2fnrX/+adu3aZa211kqS7L///llttdVy7bXXZtKkSaXjLFiwIBdddFFuvPHGTJs2Lcl/HoE3efLkaud8+umnc//995fmValbd1GT2aeffrpc17IstQEAAAAAANQWtfYxfcmi90b9+te/zrvvvpujjz66NN65c+cki97D1K1bt9L4JptskrPOOiuXX3559t133+y2225Zc801869//StvvPFGdt111+y///5Jkr333js33XRTfvGLX2TEiBFp0aJFxowZk6FDh6Z58+aZMmVKtXBo3XXXTZJcfvnl+c53vpOTTz55ma5lWWoDAAAAAACoLWp1Z1SbNm3SokWLJP8JoJJk8803L41XvS+qyjHHHJPf//73adWqVR5++OH89a9/Td26dXPuuefm17/+danDqXXr1vn973+fNm3a5JFHHsmAAQMyefLknHrqqRk0aFDq1KmTJ554onTcww8/PDvuuGNeeeWV3HbbbZk9e/YyX8/S1gYAAAAAAFBblFV+/sVHfG2NHDkySTJ0s6E1cv5+zfvVyHnh62TUqFFJFoXlQO1jDUPtZx1D7WcdQ+1nHUPtZg3XblU5Q8eOHZd5bq3ujAIAAAAAAOCrTRgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFKZuTRfAqtWveb+aLgEAAAAAAPgG0RkFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAPz/9u48zq/x7h//K4tEyCKIJdQX1YyQhGSIfUkklmiRBImtBNFao2hxtzclFfSuJUqpvcTW0qhESSRSklZkwW1ppCi3xBKJbRLZM/P7I7+ZmiYUMydj4vl8PPKQuc51rs/7fDze5mNec50DhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhWlc1wWwag39cOgqeZ1BrQetktcBAAAAAAC+3uyMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4xahaZNm5aSkpKcd955dV0KAAAAAADAKiGMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwqiCvPzyyzn55JPTtWvX7Ljjjjn//PPz0UcfrTDvrbfeyoUXXpgePXqkY8eO6dy5c/r06ZN77rmnas6UKVNSUlKSc845Z6Wv1aNHj+y9994pLy8v6nIAAAAAAAC+ksZ1XcDqaNq0aTnqqKOyePHi7LfffmnZsmXGjh2b8ePHV5s3c+bMHHrooVmwYEF69uyZjTfeOLNmzcqoUaPy85//PMuWLcvRRx+d0tLSbLrpphk7dmwWLFiQZs2aVa3xzDPPZMaMGTnppJPSsKFsEQAAAAAA+HoRRhXgkksuycKFC3PLLbdkl112SZKcfvrpOeaYYzJ79uyqeTfeeGM+/PDD3Hbbbdl1112rxo8++ugcdthhGTlyZI4++ug0aNAgBx98cK677rqMGzcuvXr1qpo7YsSIJMnBBx+8iq7ui5k2bVpdlwCrnQULFiTRX1Bf6WGo//Qx1H/6GOo/fQz1mx7+5rKVppbNmjUrkydPzh577FEVRCXJuuuum1NPPbXa3IMOOihDhgypFkQlSadOnbLmmmvm/fffrxo75JBDkvwrfEqSJUuW5JFHHsm2226brbbaqoCrAQAAAAAAqBk7o2rZyy+/nCTp0KHDCsc6d+5c7esddtghO+ywQz766KNMmzYtb775Zl5//fU899xzWbRoUZYtW1Y1d7PNNkuXLl0yfvz4fPzxx2nVqlUmTJiQDz/8MD/84Q+LvaivoH379nVdAqx2Kn9jRH9B/aSHof7Tx1D/6WOo//Qx1G96uH6bOnXqVz5XGFXLysrKkiRrr732CsdatWpV7euPP/44l156aUaOHJklS5akQYMG2WSTTbLzzjvn73//+wrnH3LIIXnmmWcyevToHHbYYXnooYfSuHHjfPe73y3mYgAAAAAAAGrIbfpqWcuWLZMkc+fOXeHY/Pnzq3394x//OMOHD0/fvn1zzz33ZMqUKRk7dmwuueSSla59wAEHpGnTpnnkkUeyaNGijBs3LrvttlvWX3/92r8QAAAAAACAWmBnVC3bZptt0qBBgzzzzDMrHHvxxRer/l5WVpYnnngiHTp0yEUXXVRt3syZM7No0aJUVFRUG2/ZsmW6d++eMWPGZMyYMVmwYEEOPvjgYi4EAAAAAACgFtgZVcvatGmTPfbYIxMnTsyoUaOqxufNm5drr7226us11lgjDRs2TFlZWRYvXlw1vnDhwgwePDhJsmTJkhXWP+SQQ7JkyZJcccUVWXvttbPPPvsUeDUAAAAAAAA1Y2dUAS644IL0798/Z555Znr06JENN9ww48aNS8OG/8r+mjVrlp49e2bUqFE57LDDsttuu2X+/PkZN25c5syZk1atWmXu3LkpLy+vdt7uu++e9ddfP2+99Vb69OmTNddcsy4uEQAAAAAA4AuxM6oA3/rWt3LfffelV69emTx5ch544IFss802uf7666vNGzJkSI499tjMnTs3w4YNy/jx49OxY8fcc889OeSQQ7Jw4cI8/fTT1c5p3LhxevbsmSRu0QcAAAAAAHzt2RlVkE033TRXXHHFCuPTp0+v+nvz5s3zX//1X/mv//qvFeZ16tRppeNJ8vLLL6dt27bZaaedaq9gAAAAAACAAtgZVc9MmDAhzz77bPr27ZsGDRrUdTkAAAAAAACfy86oeuKSSy7J1KlTM3369LRu3TpHH310XZcEAAAAAADwH9kZVU9ssMEGef3117PFFlvk+uuvzzrrrFPXJQEAAAAAAPxHdkbVEwMHDszAgQPrugwAAAAAAIAvxc4oAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAK07iuC2DVGtR6UF2XAAAAAAAAfIPYGQUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGEa13UBrFpDPxxayLqDWg8qZF0AAAAAAKB+szMKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACjM1yaMmjlzZkpKSnLKKafU6rplZWUpKSnJMcccU6vrfh1ccsklKSkpydNPP13XpQAAAAAAAKxU47ouoFLLli1z2mmnZcstt6zrUgAAAAAAAKglX6sw6vTTT6/rMgAAAAAAAKhFX5vb9AEAAAAAALD6qfUwqm/fvunYsWMWLVpUbbxPnz4pKSnJU089VW288rlHM2bMWOGZUeedd15KSkry8ccf58ILL8xuu+2Wjh07pk+fPhk1atQKrz1z5sycc8452XXXXdO5c+ecdtppefvtt1da58iRI9O/f//suOOO6dy5c/r27Zu77747FRUVVXP++Mc/pqSkJOPHj8+1116bPfbYI9tvv3369euXcePGrXTdRx55JP3790/nzp3TpUuXHHvssZk4ceJK5z711FMZMGBASktLq9Z99NFHVzr3/vvvz0EHHZTtttsu++67b+69996VzgMAAAAAAPg6qfUwas8998zixYvzzDPPVI19/PHHmTZtWpJk8uTJ1eaPHz8+3/72t9OgQYPPXHPAgAEZP358DjjggHzve9/LK6+8kkGDBmXChAlVc9599930798/I0eOzPbbb5++ffvmlVdeyYknnrjCeg8//HDOPvvsfPjhh+ndu3f69euXsrKyXHTRRfnNb36zwvyrrroqN954Y/bcc88cdNBBeeONN3LyySfngQceqDZv6NChOfPMM/Pee++ld+/e6d27d1599dUMGDAgf/rTn6rN/cMf/pABAwZk+vTp6dWrV/r165f3338/gwYNyg033FBt7tVXX52f/vSnmTdvXg499NBsvfXWufjii/PII4985nsGAAAAAADwdVDrz4zaa6+98pvf/CZPPfVUdtlllyTJpEmTUl5enrXWWqtaGDVz5sy8/vrrOf744z93zUaNGmXkyJFZa621kiS77LJLzjnnnDzwwAPZfffdkywPjGbPnp3LLrssvXv3TpLMnz8/P/jBDzJ79uxq691yyy1Za6218sADD6R58+ZJktNOOy37779/hg0bllNOOaVaOPbyyy/n7rvvzvbbb58kOfHEE9O3b99ceuml6dmzZ1q2bJnnn38+119/fbp27Zobb7wxzZo1q1q3X79+ufDCC7PHHntk3XXXzbvvvpuLL744W265Ze666660bt06SfKjH/0oxx13XIYOHZru3bunXbt2eeONN3LTTTelffv2ueOOO9KyZcskybhx43LyySd/+X9BBakMG4HiLFiwIIl+g/pKD0P9p4+h/tPHUP/pY6jf9PA3V63vjOrUqVNat25d7XZ8EydOzDrrrJOePXvm+eefz+LFi5OkamfT3nvv/blrHnXUUVVBVLI88EqSt956K0myePHijB49Ot/5zneqgqgkWWuttXLOOeessF5FRUUWLlyYV155pWqsefPmuf/++zN27NgVdmn16tWrKohKks022yxHHXVU5s6dm7/85S9Jlt9Gr6KiIj/5yU+qgqgkad26dQYOHJgFCxZU7WR66KGHsnjx4pxxxhlVQVSSrLnmmjnjjDNSXl6e4cOHJ0keffTRLF26ND/84Q+rgqgk6datW1UQBwAAAAAA8HVV6zujGjZsmN133z1//vOfM3fu3LRo0SITJ07MjjvumO233z5/+tOf8sILL6S0tDTjx49PixYtUlpamnffffcz19xiiy2qfd2iRYskqQq1ZsyYkfnz56dDhw4rnNuhQ4esscYa1cYqdyr1798/JSUl2XPPPbPXXnultLQ0DRuumM917dp1hbFOnTolWb5r6qCDDspLL72UJBk9enRVQFWp8toq094XX3wxyfJnRn06EEuW7+aqXPfT/1zZtXXu3Dnjx49fYbwutG/fvq5LgNVe5X9D9BvUT3oY6j99DPWfPob6Tx9D/aaH67epU6d+5XNrPYxKlu9cGjFiRJ5++ulsv/32efXVV9OvX7+qUGfKlCnp1KlTJk6cmD322CONG39+GU2aNKn2deXOpYqKiiTLn0mVJGuvvfYK5zZq1KjqVnyV+vfvn/XWWy933HFHpk6dmunTp+emm27KhhtumPPOOy+9evWqNn/DDTdcYd31118/STJv3rwkydy5c5MkN95442deR2WdlXPvvffe/zi3rKzsM69tnXXW+czzAQAAAAAAvg4KCaN23333NGzYMBMnTqzavdS1a9dstdVWWW+99TJ58uR06dIl8+bN+4+36PsiWrVqleRfIc+nVVRUVN2H8tN69uyZnj17pqysLE8//XQef/zxjBgxImeffXa22mqrtGvXrmruwoULVzi/8rUqb7O31lprpVGjRvnf//3fFXZi/bvKWw6OGTMm3/rWtz53buWt+ebNm1ftln5J8sknn3zuuQAAAAAAAHWt1p8ZlSwPaCp3Pk2dOjXrrLNOSkpKkiwPpZ555pn85S9/ScOGDbPnnnvW+PU222yztGjRIs8+++wKx1599dVqYdLixYtz/fXX5/bbb0+yPOzp2bNnLr300px88skpLy9fYZ0XXnhhhXUr51Terq+kpCTLli1b6YPXnnvuufzqV7/KlClTquZ+1rpvvPFGLr/88jz++ONJkm233TbJyre/Vd7uDwAAAAAA4OuqkDAqSfbcc8+88sorGTduXHbYYYeqW+t17do1n3zySe6777506tQp6667bo1fa4011sh3v/vdvPnmm7ntttuqxhcvXpwrrrii2twmTZpk5MiRGTp0aGbMmFHt2FtvvZUkadu2bbXx3//+93nttdeqvn799ddz5513ZsMNN8zuu++eJOndu3eSZMiQIVW37kuW72j6+c9/nptuuinLli1Lkhx00EFp1KhRrr766syePbtq7tKlSzN48ODceuut+eijj5IkvXr1StOmTXP99ddXmztlypSqwAoAAAAAAODrqpDb9CXLnxt1zTXX5K233sqxxx5bNb7TTjslWX6bu7322qvWXu9HP/pRnnrqqVx22WWZMGFCvv3tb+epp57KRx99lKZNm1abe9ZZZ+XUU09N7969s//++6dVq1Z58cUXM3HixHTt2jW77bZbtfnl5eU5/PDDs//++6eioiKjR4/OwoUL88tf/rJq7Z133jnHHHNM7rzzzhx44IHZa6+90qRJk4wZMybvvPNO+vfvX3Xtm2++eX784x/nsssuy3e/+9107949rVq1ypNPPpnXXnst3bp1y0EHHZQk2WSTTXLuuefm4osvTu/evdOjR4/Mmzcvjz76aDbeeOO8+eabtfYeAgAAAAAA1LbCwqhtt902bdq0yezZs6tCmCT59re/XTVeG8+LqtSqVavcc889GTp0aMaOHZspU6akS5cuufrqq9OvX79qc/fZZ5/ccsstuemmmzJu3LiUlZWlbdu2OfXUUzNw4MA0bFh9w9gPfvCDfPTRRxk+fHgWLVqU7bffPqeffnq23377avN+9rOfpWPHjrnnnnvy0EMPpVGjRtliiy1y+umnV+2cqjRgwIBsueWWufXWWzN69OiUl5fnW9/6Vs4777wcddRRadz4X/9qjjrqqGy44Yb57W9/m+HDh6d169Y544wz0qRJk1x66aW19h4CAAAAAADUtgYVFRUVdV3E19Uf//jHnH/++Tn//PNz3HHH1XU5NVL5zKkJW04oZP1BrQcVsi7wL5XPpGvfvn0dVwJ8FXoY6j99DPWfPob6Tx9D/aaH67fKnKG0tPRLn1vYM6MAAAAAAABAGAUAAAAAAEBhhFEAAAAAAAAUpnFdF/B11qdPn/Tp06euywAAAAAAAKi37IwCAAAAAACgMMIoAAAAAAAACiOMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAK07iuC2DVGtR6UF2XAAAAAAAAfIPYGQUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGEa13UBrFpDPxz6pc8Z1HpQAZUAAAAAAADfBHZGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIVpXNcFFGHp0qW54YYbMmrUqMyYMSNNmjRJx44dc+KJJ2aXXXapmjdv3rzccMMNefTRR/Puu++mdevW6d69e84444yst9561dZ86623cuONN+avf/1rZs2alcaNG2eLLbbIYYcdliOOOKLa3JEjR2bYsGF57bXXsnTp0my55Zbp27dvjjjiiDRo0KBq3uLFi3PrrbfmoYceyptvvpm11147Xbp0ySmnnJKOHTtWzXv66afz/e9/P5deemnKy8vzu9/9Lm+88UZat26dAw88MGeccUaaNWtW0LsJAAAAAADw1a2WYdTgwYNz7733pmvXrtlzzz0zd+7c/PnPf84JJ5yQ2267LTvttFPmzp2bI488Mv/4xz+yyy67ZN99983MmTPz+9//PuPHj8+9996bDTbYIEkyc+bMHHrooVmwYEF69uyZjTfeOLNmzcqoUaPy85//PMuWLcvRRx+dJHn44Ydz9tlnZ/PNN0/v3r3TsGHDjB07NhdddFE+/PDDnHrqqUmSRYsWZcCAAZk6dWratWuXI444InPmzMmYMWMyfvz4XH311enRo0e16xo2bFj+8Y9/ZN99980ee+yRxx57LLfeemvee++9XHHFFav2TQYAAAAAAPgCGlRUVFTUdRG1ad68edlxxx1TWlqaYcOGVY2/8MILOfTQQ7PffvvlmmuuyUUXXZS77747F1xwQY466qiqeWPHjs0pp5yS/fffP0OHDk2SXHDBBbnvvvty2223Zdddd62a+/zzz+ewww5L586dc++99yZJ+vTpk9dffz3jx49P8+bNq2raf//9s2zZsvztb39LgwYNct111+Waa65Jnz59Mnjw4DRuvDwXfOmll3LkkUemSZMmGTduXJo3b161M6pRo0a566670rlz5yTJ3Llzs++++6asrCyTJk3K2muv/Znvy9SpU5MkE7ac8KXf033f3fdLnwPUvgULFiSJnZBQT+lhqP/0MdR/+hjqP30M9Zsert/mz5+fJCktLf3S5652z4wqLy9PRUVF3nnnncyePbtqvGPHjhkzZkyuuOKKLF26NA8++GC+853vVAuikmSfffZJly5d8thjj2XevHlJkoMOOihDhgypFkQlSadOnbLmmmvm/fffrxqrqKjIwoUL88orr1SNNW/ePPfff3/Gjh1bdZu+4cOHp1mzZvnpT39aFUQlybbbbpsjjzwyZWVlGT16dLXX23HHHauCqCRp0aJFOnfunKVLl+bdd9/9qm8ZAAAAAABAYVa72/S1bNkyvXr1ysMPP5xu3bqlc+fO2XPPPdOtW7dstdVWSZJXXnkl8+fPz7Jly/LrX/96hTUWLVqUZcuWZfr06SktLc0OO+yQHXbYIR999FGmTZuWN998M6+//nqee+65qrmV+vXrlwsvvDD9+/dPSUlJ9txzz+y1114pLS1Nw4bLs7958+ZlxowZ6dKlS9XuqU8rLS3Nrbfempdffrna+Oabb77C3BYtWiRJlixZ8pXfs/+kffv2ha0NfHHTpk1LoiehvtLDUP/pY6j/9DHUf/oY6jc9XL9V3oHtq1jtwqgkufzyy9OhQ4f88Y9/zKRJkzJp0qT86le/SocOHfKLX/yiaivZP//5z1x77bWfuc7HH39c9c9LL700I0eOzJIlS9KgQYNssskm2XnnnfP3v/+92jn9+/fPeuutlzvuuCNTp07N9OnTc9NNN2XDDTfMeeedl169euWTTz5J8q8g6d9VPqtq4cKF1cabNGmywtzKnVar2d0WAQAAAACA1cRqGUatscYaOf7443P88cfn7bffzl//+tc8+uijmTBhQn7wgx/kxhtvTJIcfPDB+eUvf/kf1/vxj3+cJ554Iv3798/BBx+cdu3aVe1oGjFixArze/bsmZ49e6asrCxPP/10Hn/88YwYMSJnn312ttpqq7Rt2zZJMmvWrJW+XllZWZJknXXW+SqXDwAAAAAA8LWx2j0zasaMGbnyyiszbty4JEnbtm1z2GGH5ZZbbsnOO+9cFQA1adIkL7300kp3FN1+++35zW9+kw8//DBlZWV54okn0qFDh1x00UXVbq03c+bMLFq0qGqNxYsX5/rrr8/tt9+eZPktA3v27JlLL700J598csrLy/Pss8+mefPm2XTTTfPGG2/kgw8+WOH1J0+enCRVtxUEAAAAAACor1a7MGrNNdfMTTfdlKFDh2bx4sVV44sXL87s2bPTpEmTbLrppunVq1deffXV3HbbbdXOf/rpp/PLX/4yDzzwQFq1apU11lgjDRs2TFlZWbX1Fi5cmMGDByf51/OamjRpkpEjR2bo0KGZMWNGtXXfeuutJKnaFdW7d+8sXLgwQ4YMydKlS6vmvfTSSxk2bFhatmyZ7t271+I7AwAAAAAAsOqtdrfpa9OmTY499tjcdttt+e53v5u99torDRs2zPjx4/Paa6/llFNOSfPmzXPuuefm2WefzeWXX56xY8emU6dOmTVrVkaPHp3GjRtnyJAhadiwYZo1a5aePXtm1KhROeyww7Lbbrtl/vz5GTduXObMmZNWrVpl7ty5KS8vT8OGDXPWWWfl1FNPTe/evbP//vunVatWefHFFzNx4sR07do1u+22W5Jk4MCBmTBhQkaMGJHp06dn5513zvvvv58xY8akoqIiV111VdUOLAAAAAAAgPpqtQujkuXPePp//+//5Q9/+EOGDx+eZcuWZauttspll12W3r17J0nWXXfd/P73v89vf/vbPPbYY7nzzjuz7rrrpnv37jnllFOy9dZbV603ZMiQbLTRRhkzZkyGDRuWNm3apGPHjjnppJMycuTI/O53v8vTTz+dXXbZJfvss09uueWW3HTTTRk3blzKysrStm3bnHrqqRk4cGAaNly+Ga1p06a5/fbbc8stt2TEiBG555570rJly3Tr1i0/+MEPss0229TJewcAAAAAAFCbGlSs7KFJrHamTp2aJJmw5YQvfe6g1oNquxzgK5g2bVqSpH379nVcCfBV6GGo//Qx1H/6GOo/fQz1mx6u3ypzhtLS0i997mr3zCgAAAAAAAC+PoRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGEa13UBrFqDWg+q6xIAAAAAAIBvEDujAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAojDAKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKMAAAAAAAAoTOO6LoBVa+iHQ1c6Pqj1oFVcCQAAAAAA8E1gZxQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUJjVNow677zzUlJSkmnTptXamn/84x9TUlKS22+/vWrsmGOOSUlJScrKyv7j+QcffHBKSkpqrR4AAAAAAICvu8Z1XUB917t373Tt2jVNmzat61IAAAAAAAC+doRRNdSnT5+6LgEAAAAAAOBra7W9TR8AAAAAAAB1b7UPo8rKyjJ48ODsvvvu6dSpU3r37p1HHnmk2pzFixfnhhtuSK9evdKhQ4fstNNOOfnkk/PCCy/8x/VX9syohQsX5sorr0z37t3TqVOnHH744Zk8efJKz1+yZEl+97vf5fDDD09paWk6dOiQbt265YILLsgHH3xQNa9nz57ZbrvtMm/evBXWuPbaa1NSUpK//vWvX/RtAQAAAAAAWCVW+zDqRz/6UR5//PH06tUr3/ve9/Laa6/lzDPPzNixY5MkixYtynHHHZerrroqjRo1yhFHHJFdd901EyZMyBFHHJExY8Z8qdcrLy/PwIED89vf/jbrrbdejjjiiDRu3DjHH3983nnnnRXmn3322RkyZEgaN26cww8/PP369UuTJk1y3333ZeDAgVXzDj744CxcuHCl9YwYMSIbbrhhdtllly/57gAAAAAAABRrtX9m1EYbbZQ777wza6+9dpKkW7duOfXUU3P//fdnn332yc0335ypU6emT58+GTx4cBo3Xv6WvPTSSznyyCNz/vnnZ+edd07z5s2/0OsNHz48kyZNSt++ffOLX/wiDRsuz/t++ctf5pZbbqk297nnnsuoUaPyve99L7/61a+qxpcuXZrevXvnxRdfzOuvv54tttgiBx98cK699tqMHDkyhxxySNXc559/Pm+88UZOOOGEqtf6KqZNm/aVzwVWjQULFiTRr1Bf6WGo//Qx1H/6GOo/fQz1mx7+5lrtd0Z9//vfrwqikmSvvfZKw4YNM3PmzCTLw6NmzZrlpz/9aVUQlSTbbrttjjzyyJSVlWX06NFf+PUefvjhNGjQIGeffXa1cOjMM89MixYtqs3daKONctlll2XQoEHVxhs3bpzS0tIkyfvvv58k+da3vpXS0tI89dRT1W7f99BDDyVZvnMKAAAAAADg62a13xm1+eabV/t6jTXWyNprr51PPvkk8+bNy4wZM9KlS5eV7nwqLS3NrbfempdffvkLv97LL7+ctm3bZr311qs23qRJk2y77baZOHFi1dhGG22U3r17Z+nSpXnppZfy+uuv580338y0adPyt7/9Lcny2/5VOuSQQzJlypQ88sgjOeqoo7Js2bI88sgj2XrrrVNSUvKFa1yZ9u3b1+h8oHiVvzGiX6F+0sNQ/+ljqP/0MdR/+hjqNz1cv02dOvUrn7va74xq2rTpZx775JNPkmSFHUuVNthggyTJwoULv/DrlZWVVduJ9WmtWrVaYezee+9Nt27d0qdPn5x99tm57bbbsmDBgnz7299OklRUVFTN3X///dO0adOMHDkySfLXv/41c+bMsSsKAAAAAAD42lrtw6jPUxkazZo1a6XHy8rKkiTrrLPOF16zZcuWmTt37kqPzZ8/v9rXjzzySC688MK0bt061113Xf7yl79k8uTJufnmm1eaDLdo0SI9evTIs88+m1mzZuWRRx5Jo0aN8r3vfe8L1wcAAAAAALAqfaPDqObNm2fTTTfNG2+8Ue05TJUmT56cJNlqq62+8Jrbbrtt3nnnnbz99tvVxpctW7bCQ9kqdzhdccUV6dGjRzbeeOOqY//85z+TVN8ZlSx/NlRFRUXGjh2bJ598MrvsskvatGnzhesDAAAAAABYlb7RYVSS9O7dOwsXLsyQIUOydOnSqvGXXnopw4YNS8uWLdO9e/cvtV6SXHbZZVmyZEnV+C233JI5c+ZUm1t5C8F/H3/wwQczadKkJKlWU5LsvvvuadOmTW6++Wa36AMAAAAAAL72Gtd1AXVt4MCBmTBhQkaMGJHp06dn5513zvvvv58xY8akoqIiV111VZo3b/6F1+vVq1dGjRqVRx99NK+//np22WWXvPrqq5k4cWI22WSTvPXWW1VzDzrooDz88MM57bTTcuCBB6Z58+Z54YUXMmnSpKy33np5//3389FHH1Vbv/K2fLfeemvWWmut9OzZs7beCgAAAAAAgFr3jd8Z1bRp09x+++0544wzsmTJktxzzz2ZOHFiunXrlvvuuy89evT40mteeeWVOeecc7J48eLcc889mT17dq699tpsvfXW1ebtvffeueqqq7LZZptlxIgRGT58eBYtWpQLLrggN998c5LkiSeeWGH9Aw44IEmy7777plmzZl/hqgEAAAAAAFaNBhX//lAivvbuu+++XHDBBbn99tuzyy67fKFzpk6dmiSZsOWElR4f1HpQrdUHFKPyuXPt27ev40qAr0IPQ/2nj6H+08dQ/+ljqN/0cP1WmTOUlpZ+6XO/8Tuj6pu5c+fmd7/7XTbbbLPsvPPOdV0OAAAAAADA5/rGPzOqvpg0aVIuvfTSvPvuu/nggw9y+eWXp0GDBnVdFgAAAAAAwOeyM6qe2GCDDTJ79uyUl5fnjDPOyCGHHFLXJQEAAAAAAPxHdkbVE5tvvnkmTFj5854AAAAAAAC+ruyMAgAAAAAAoDDCKAAAAAAAAAojjAIAAAAAAKAwwigAAAAAAAAKI4wCAAAAAACgMI3rugBWrUGtB9V1CQAAAAAAwDeInVEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABRGGAUAAAAAAEBhhFEAAAAAAAAURhgFAAAAAABAYYRRAAAAAAAAFEYYBQAAAAAAQGGEUQAAAAAAABSmQUVFRUVdF0Hxpk6dWtclAAAAAAAA9VxpaemXPsfOKAAAAAAAAApjZxQAAAAAAACFsTMKAAAAAACAwgijAAAAAAAAKIwwCgAAAAAAgMIIowAAAAAAACiMMAoAAAAAAIDCCKPquaVLl+b2229Pr1690qlTp+yzzz657rrrsmTJki90/kcffZSLL7443bt3z3bbbZc+ffrkz3/+c8FVA5Vq2sOfNm7cuJSUlGTatGkFVAp8lpr28YsvvphTTjklO+20Uzp06JAePXrkV7/6VebPn19w5UClmvbxK6+8ktNOOy277757OnfunCOOOCKjR48uuGrg02rzc/WyZcty+OGHp6SkpIBKgc9S0z4+8sgjU1JSstI/99xzT8HVAzXt4UWLFuXaa6/Nfvvtl44dO6ZHjx4ZMmRIysrKCq6cVaVBRUVFRV0XwVd3wQUX5L777ktpaWm6dOmSZ555JlOnTs1+++2Xa6655nPPnT9/fo4++uhMmzYt+++/fzbeeOOMHj06M2bMyH//93/n6KOPXkVXAd9cNenhT3vttddy1FFH5cMPP8yDDz6Y9u3bF1g18Gk16eOJEyfmxBNPTJLst99+2WCDDTJ58uS88MIL6dixY+666640bdp0VVwGfKPVpI9ffvnl9O/fPxUVFenVq1datGiRMWPG5K233sqPf/zjqh4HilVbn6uT5NZbb83ll1+eJJk+fXoR5QIrUdM+Li0tTZs2bXLggQeucGzvvfdOx44diygb+P/VpIeXLFmS448/PpMmTUrXrl3TsWPHvPDCC5k0aVK22267DBs2LE2aNFlFV0JhKqi3pk6dWtGuXbuK008/vaK8vLyioqKiory8vOInP/lJRbt27Soef/zxzz3/+uuvr2jXrl3FsGHDqsbmzp1bceCBB1Zst912FXPmzCm0fvimq2kPV3rqqacqdt5554p27dpVtGvXruLvf/97kWUDn1LTPt5///0rttlmm4r//d//rRorLy+v+NnPflbRrl27iltvvbXQ+oGa93G/fv0qtt1224oXXnihamzevHkVPXv2rOjYsWPFBx98UGj9QO19rq6oqKh44403Kjp16lT12RpYNWraxzNmzKho165dxZAhQ1ZFucC/qWkP33zzzRXt2rWruPzyy6uNX3TRRRXt2rWrGD58eFGlswq5TV89dtdddyVJTjvttDRo0CBJ0qBBg5x11llp0KBB/vCHP3zu+XfffXfWX3/99O/fv2qsefPm+eEPf5gFCxZkxIgRxRUP1LiHFy5cmJ/+9KcZMGBAysvLs+222xZeM1BdTfr41VdfzT//+c/ss88+6dSpU9V4gwYNcuqppyZJnnzyyQKrB5Ka9fG8efMyf/787L333unQoUPV+Nprr51u3bpl0aJFbp8Lq0BNP1dXqqioyM9+9rNssMEG2XzzzYsqF1iJmvZx5S5Gt9eEulHTHr7rrruyySab5Ec/+lG18eOPPz69e/d2x5DVhDCqHpsyZUpat26ddu3aVRvfcMMNs/nmm2fy5Mmfee6bb76ZWbNmpbS0NI0aNap2bKeddkqSzz0fqLma9HCSzJkzJ/fff3/22muvPPTQQyusAxSvJn3cvHnznHPOOenbt+8KxypvP+C5UVC8mvbxQw89lGuvvXaFY//85z+TJOutt17tFgysoKafqyvde++9mTRpUgYPHpw111yziFKBz1DTPhZGQd2qSQ+/+uqreeutt9K9e/esscYa1Y5tuummueyyy3LAAQcUUjerljCqnlq8eHHefffdbLbZZis9vskmm6SsrCwffPDBSo+/+eabSbLS89u0aZOmTZvmjTfeqLV6gepq2sNJ0qpVq9x999254YYbsuGGGxZVKvAZatrHG220UQYOHJi99tprhWOPPfZYkmSrrbaqvYKBFdTG9+NPW7ZsWf7v//4vv/jFL/Lkk0+mW7dufigGBautPn7nnXfyP//zPzn00EOz8847F1Eq8Blqo4+nT5+eBg0aZOrUqendu3e233777Lnnnrnkkksyd+7cokoHUvMe/sc//pEk+c53vpMnnngi/fv3z3bbbZfdd989l112mV/SXI0Io+qpjz76KEnSokWLlR6vHP+sb7iV57ds2XKlx5s3b+6bNRSopj1cOae0tLTWawO+mNro45WZM2dO1cNd+/Xr99ULBP6j2u7jY445Jvvuu2/uvPPOdOnSJVdeeWWt1Al8ttrq4wsuuCBrrbVWzj333FqtD/jPaqOPp0+fnoqKilxzzTXZZpttcthhh2XdddfNHXfckSOPPDLz5s2r9bqB5Wraw++9916SZNy4cTnppJPSsmXL9O/fP23atMltt92WE088MUuWLKn9wlnlGtd1AXw1S5cuTfKv2/j8u8rxRYsWfeXzFyxYUNMygc9Q0x4G6l4RfTx37tycdNJJmTNnTo455phqz5ICal9t93HXrl2z3Xbb5dlnn80zzzyTY489NjfddFPWWWedWqkXWFFt9PGDDz6YJ598Mtdcc81n/sImUJya9nF5eXlatmyZ9u3b57e//W3VnUPKy8vz85//PPfdd19+/etf5/zzzy+geqCmPVz5M+hx48Zl8ODBOfzww5Msv+vAWWedlUcffTR33313jj322NounVXMzqh6qvL+1Z+VCi9evDhJ0qxZs5Uer3zoW+W8lZ2/1lpr1bRM4DPUtIeBulfbffzBBx/k2GOPzUsvvZRu3brlvPPOq51Cgc9U23185pln5txzz829996bE044Ic8//3yGDh1aO8UCK1XTPp4zZ04uvfTS9OzZM/vtt18xRQKfq6Z93LBhw/z+97/Pgw8+WO0W9g0bNsy5556bZs2a5eGHH67lqoFKtdHDSbLNNttUBVFJ0qhRo/zkJz9JkjzyyCO1Vi91RxhVTzVv3jwNGzb8zG3GldseP2t7ZKtWrZLkM8+fN29emjdvXguVAitT0x4G6l5t9vGbb76Zfv365aWXXkr37t1zzTXXpHFjG9ihaEV+Pz7zzDPTrFmzjB07tkY1Ap+vpn188cUXZ9myZbngggsKqxH4fEV+P1577bWz+eabZ/bs2e48AgWpaQ9X/gx6m222WeHYJptskpYtW2bGjBm1VC11yU856qkmTZqkbdu2mTlz5kqPz5w5M+uuu+5n3hJk8803r5r37957770sWrQoW2yxRW2VC/ybmvYwUPdqq4+nTZuWE044Ie+//3569+6dX/ziF4IoWEVq2scfffRRnnnmmbRt2zZbb731Cmu3adMm7777bm2XDXxKTft41KhRSZI99thjpcdLSkqyySab5PHHH6+VeoEV1bSPy8rK8uqrr6Z169Yr/VnWwoUL07BhQ5+xoSC19XPqz9pZtXTpUrfRXU3YGVWPlZaWZvbs2Xn99derjc+aNStvvPFGtttuu888t23btmnbtm2mTp2a8vLyascmTZqUJOncuXPtFw1UqUkPA18PNe3j//u//8vxxx+f999/PwMGDMill17qf5JhFatJH7/22ms5+eSTc911161wbO7cuXn77bez2Wab1XrNQHU16ePTTjttpX/WX3/9quPf//73C60fqFkfv/TSSzniiCNy+eWXr3Dsvffey8yZM9O+ffs0atSo1usGlqtJD3fq1ClrrLFGJk+enGXLllU79tprr2X+/PkpKSkppG5WLWFUPXbIIYckSa666qqqQKmioiJXXnllkqRfv36fe/5BBx2Ud999N8OGDasamzdvXm644YasueaaOfjgg4spHEhS8x4G6l5N+ri8vDxnnXVWPvjgg3z/+9/PeeedlwYNGhReM1BdTfp4++23T9u2bTN27NhMmTKlanzp0qW56KKLsnTp0vTt27e44oEkNevj008/faV/KsOo008/Pccdd1yh9QM16+PS0tK0adMmTz75ZCZPnlw1vnjx4gwePDhLlizJUUcdVVzxQI16uEWLFunVq1fefvvt3HjjjVXjS5Ysyf/8z/8kic/Uqwm/eluP7brrrunVq1f+/Oc/p1+/ftlpp53y7LPPZsqUKdlvv/2y9957V8399a9/nWT5B+lKAwcOzKOPPppLLrkkkydPzre+9a2MHj06M2bMyH//939n3XXXXdWXBN8oNe1hoO7VpI/HjBmTF198MU2aNMlaa61VdfzT1l9//RxxxBGr5Frgm6omfdyoUaNccsklOemkk3LcccflgAMOSOvWrfO3v/0tr7zySvbee287KmAV8Lka6r+a9HGTJk0yePDgnHbaaRkwYED233//rLPOOvnb3/6W1157LQceeGD69OlTF5cF3xg1/V587rnn5rnnnsvVV1+dSZMmZeutt85TTz2VadOmpVevXtlnn31W9SVRgAYVFRUVdV0EX92SJUty4403Zvjw4Zk1a1batm2bgw46KAMHDkyTJk2q5lVuZZw+fXq18+fMmZMrr7wy48aNy4IFC7LlllvmhBNOyIEHHrhKrwO+qWraw5923nnnZfjw4XnwwQfTvn37wmsHlvuqfXzJJZfkjjvu+Ny1t9566/zpT38qrnggSc2/H7/44ou59tprM2XKlCxatCibb755+vbtm2OOOcYtgWAVqc3P1Uly8MEH5+WXX/6P84DaU9M+fu655/Kb3/wmzzzzTNWz0A8//PAceeSRadjQzaGgaDXt4Q8//DDXXXddHnvssXzwwQfZZJNNcuihh2bAgAE+U68mhFEAAAAAAAAUxq8FAAAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQGGEUAAAAAAAAhRFGAQAAAAAAUBhhFAAAAAAAAIURRgEAAAAAAFAYYRQAAAAAAACFEUYBAAAAAABQmP8Pi3k7bXKPTjEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 477,
       "width": 849
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf.feature_importances_,\n",
    "                        index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "- **Boosting**: Ensemble method combining several weak learners to form a strong learner.\n",
    "- **Weak learner**: Model doing slightly better than random guessing.\n",
    "- Example of weak learner: Decision stump (CART whose maximum depth is 1).\n",
    "- Train an ensemble of predictors sequentially.\n",
    "- Each predictor tries to correct its predecessor.\n",
    "- Most popular boosting methods:\n",
    "    - AdaBoost,\n",
    "    - Gradient Boosting.\n",
    "\n",
    "# Adaboost\n",
    "- Stands for **Ada**ptive **Boost**ing.\n",
    "- Each predictor pays more attention to the instances wrongly predicted by its predecessor.\n",
    "- Achieved by changing the weights of training instances.\n",
    "- Each predictor is assigned a coefficient $\\alpha$.\n",
    "- $\\alpha$ depends on the predictor's training error.\n",
    "\n",
    "# Learning Rate\n",
    "- An important parameter used in training is the learning rate $\\eta$.\n",
    "- Learning Rate: $0 < \\eta < 1$\n",
    "- $\\eta$ is used to shrink the coefficient $\\alpha$ of a trained predictor\n",
    "- **NOTE:** There is a trade-off between $\\eta$ and the number of estimators.\n",
    "    - A smaller value of $\\eta$ should be compensated by a greater number of estimators.\n",
    "\n",
    "# AdaBoost: Prediction\n",
    "- Classification:\n",
    "    - Weighted majority voting.\n",
    "    - In sklearn: `AdaBoostClassifier`\n",
    "- Regression:\n",
    "    - Weighted average.\n",
    "    - In sklearn: `AdaBoostRegressor`\n",
    "**NOTE:** Individual predictors need not to be CARTS. However, CARTs are used most of the time in Boosting because of their high variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = pd.read_csv('wbc.csv', index_col=0)\n",
    "y = breast_cancer.diagnosis\n",
    "\n",
    "mapping = {'M':1, 'B':0}\n",
    "y = y.map(mapping)\n",
    "\n",
    "X = breast_cancer.drop('diagnosis', axis=1)\n",
    "X = X.iloc[:, :30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set seed for reproducibility\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
    "                                                   test_size=0.3,\n",
    "                                                   stratify=y,\n",
    "                                                   random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a classification-tree 'dt'\n",
    "dt = DecisionTreeClassifier(max_depth=1, random_state=SEED)\n",
    "\n",
    "# Instantiate an AdaBoost classifier 'adab_clf'\n",
    "adb_clf = AdaBoostClassifier(base_estimator=dt, n_estimators=100)\n",
    "\n",
    "# Fit 'adb_clf' to the train set\n",
    "adb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set probabilities of positive class\n",
    "y_pred_proba = adb_clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test-set roc_auc_score\n",
    "adb_clf_roc_auc_score = roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Print adb_clf_roc_auc_score\n",
    "print('ROC AUC score: {:.2f}'.format(adb_clf_roc_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'indian_liver_patient_preprocessed.csv'\n",
    "data = pd.read_csv(url, index_col=0)\n",
    "\n",
    "X = data.drop(labels=['Total_Bilirubin_std',\n",
    "                      'Liver_disease',\n",
    "                     'Direct_Bilirubin_std',\n",
    "                     'Alkaline_Phosphotase_std',\n",
    "                     'Alamine_Aminotransferase_std',\n",
    "                     'Aspartate_Aminotransferase_std',\n",
    "                     'Albumin_std',\n",
    "                     'Albumin_and_Globulin_Ratio_std',\n",
    "                     'Is_male_std'], axis=1)\n",
    "y = data.Liver_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "\n",
    "# Instantiate ada\n",
    "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ada to the training set\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred_proba = adb_clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Evaluate test-set roc_auc_score\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees\n",
    "- Sequential correction of predecessor's errors\n",
    "- Unlike adaboost, gradient boosting does not tweak the weights of training instances\n",
    "- Instead, gradient boosting will fit each predictor and is trained using its predecessor's residual errors as labels\n",
    "- Gradient Boosted Trees: the base learner first explored is a CART\n",
    "- In sklearn: `GradientBoostingRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the auto dataset\n",
    "auto = pd.read_csv(\"auto.csv\")\n",
    "auto_encoded = pd.get_dummies(auto)\n",
    "X = auto_encoded.drop(columns='mpg')\n",
    "y = auto_encoded['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models and utility functions\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Split dataset into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE: 3.18\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a GradientBoostingRegressor 'gbt' with 300 decision stumps\n",
    "gbt = GradientBoostingRegressor(n_estimators=300, max_depth=1, random_state=SEED)\n",
    "\n",
    "# Fit 'gbt' to the training set\n",
    "gbt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = gbt.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RSME\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print the test set RMSE\n",
    "print('Test set RMSE: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bike share dataset\n",
    "bike_share_train = pd.read_csv(\"bike_share_train.csv\")\n",
    "\n",
    "y = bike_share_train[\"count\"]\n",
    "\n",
    "datetime = bike_share_train.datetime\n",
    "bike_share_train[\"year\"] = [x[:4] for x in datetime]\n",
    "bike_share_train[\"month\"] = [x[5:7] for x in datetime]\n",
    "bike_share_train[\"day\"] = [x[8:10] for x in datetime]\n",
    "bike_share_train[\"hour\"] = [x[11:13] for x in datetime]\n",
    "\n",
    "X = bike_share_train.drop(['datetime', 'count', 'registered', 'casual'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate gb\n",
    "gb = GradientBoostingRegressor(n_estimators=200, \n",
    "            max_depth=4,\n",
    "            random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit gb to the training set\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of gb: 49.604\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print RMSE\n",
    "print('Test set RMSE of gb: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting (SGB)\n",
    "\n",
    "### GB: Cons\n",
    "- GB involves an exhaustive search procedure\n",
    "- Each CART is trained to find the best split points and features\n",
    "- May lead to CARTs using the same split points and maybe the same features\n",
    "\n",
    "## SGB\n",
    "- Each tree is trained on a random subset of rows of the training data\n",
    "- The sampled instances (40%-80% of the training set) are sampled without replacement\n",
    "- Features are sampled (without replacement) when choosing split points\n",
    "- Result: further ensemble diversity\n",
    "- Effect: adding further variance to the ensemble of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models and utility functions\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Split dataset into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgbt = GradientBoostingRegressor(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=SEED)\n",
    "# Here, the parameter subsample was set to 0.8 in order for each tree to sample 80% of the data for training. \n",
    "# Finally, the parameter max_features was set to 0.2 so that each tree uses 20% of available features \n",
    "# to perform the best-split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgbt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgbt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RSME: 49.60\n"
     ]
    }
   ],
   "source": [
    "rsme_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "print('Test set RSME: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate sgbr\n",
    "sgbr = GradientBoostingRegressor(max_depth=4, \n",
    "                                 subsample=0.9, \n",
    "                                 max_features=0.75, \n",
    "                                 n_estimators=200, \n",
    "                                 random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit sgbr to the training set\n",
    "sgbr.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = sgbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of sgbr: 47.893\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute test set MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of sgbr: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning a CART's hyperparameters\n",
    "Machine learning models are defined by parameters and hyperparameters:\n",
    "- **parameters:** learned from data\n",
    "    - CART example: split-point of a node, split-feature of a node, ...\n",
    "- **hyperparameters:** not learned from data, set prior to training\n",
    "    - CART example: `max_depth`, `min_samples_leaf`, splitting criterion, ...\n",
    "## What is hyperparameter tuning?\n",
    "- **Problem:** search for a set fo optimal hyperparameters for a learning algorithm.\n",
    "- **Solution:** find a set of optimal hyperparameters that results in an optimal model.\n",
    "- **Optimal model:** yields an optimal **score**.\n",
    "- **Score:** in sklearn defaults to accuracy (classification) and $R^2$ (regression).\n",
    "- Cross validation is used to estimate the generalization performance.\n",
    "## Why tune hyperparameters?\n",
    "- In `sklearn`, a model's default hyperparameters are not optimal for all problems.\n",
    "- Hyperparameters should be tuned to obtain the best model performance.\n",
    "## Approaches to hyperparameter tuning\n",
    "- Grid search\n",
    "- Random search\n",
    "- Bayesian Optimization\n",
    "- Genetic Algorithms\n",
    "- ...\n",
    "## Grid search cross validation\n",
    "- Manually set a grid of discrete hyperparameter values\n",
    "- Set a metric for scoring model performance\n",
    "- Search exhaustively through the grid\n",
    "- For each set of hyperparameters, evaluate each model's cross validation (CV) score\n",
    "- The optimal hyperparameters are those of the model achieving the best CV score\n",
    "    - Grid search suffers from the curse of dimensionality\n",
    "    - The larger the grid, the longer it takes to find the solution\n",
    "## Grid search cross validation: example\n",
    "- Hyperparameters grids:\n",
    "    - `max_depth` = {2,3,4},\n",
    "    - `min_samples_leaf` = {0.05,0.1}\n",
    "- hyperparameter space = { (2,0.05), (2,0.1), (3,0.05), ...}\n",
    "- CV scores = $\\{score_{(2,0.05)}, ...\\}$\n",
    "    - For each combination of hyperparameters, the cross-validation score is evaluated using k-fold CV for example.\n",
    "- optimal hyperparameters = set of hyperparameters corresponding to the best CV score\n",
    "## Inspecting the hyperparameters of a CART in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Set seed to 1 for repoducibility\n",
    "SEED = 1\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier 'dt'\n",
    "dt = DecisionTreeClassifier(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 1, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# Print out dt's hyperparameters\n",
    "print(dt.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "{'ccp_alpha': 0.0, \n",
    " 'class_weight': None, \n",
    " 'criterion': 'gini', \n",
    " 'max_depth': None, \n",
    " 'max_features': None, \n",
    " 'max_leaf_nodes': None, \n",
    " 'min_impurity_decrease': 0.0, \n",
    " 'min_impurity_split': None, \n",
    " 'min_samples_leaf': 1, \n",
    " 'min_samples_split': 2, \n",
    " 'min_weight_fraction_leaf': 0.0, \n",
    " 'random_state': 1, \n",
    " 'splitter': 'best'}\n",
    "```\n",
    "\n",
    "[sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = pd.read_csv('wbc.csv', index_col=0)\n",
    "y = breast_cancer.diagnosis\n",
    "\n",
    "mapping = {'M':1, 'B':0}\n",
    "y = y.map(mapping)\n",
    "\n",
    "X = breast_cancer.drop('diagnosis', axis=1)\n",
    "X = X.iloc[:, :30]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(random_state=1), n_jobs=-1,\n",
       "             param_grid={'max_depth': [3, 4, 5, 6],\n",
       "                         'max_features': [0.2, 0.4, 0.6, 0.8],\n",
       "                         'min_samples_leaf': [0.04, 0.06, 0.08]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the grid of hyperparameters 'params_dt'\n",
    "params_dt = {\n",
    "            'max_depth': [3, 4, 5, 6],\n",
    "            'min_samples_leaf': [0.04, 0.06, 0.08],\n",
    "            'max_features': [0.2, 0.4, 0.6, 0.8]\n",
    "            }\n",
    "# Instantiate a 10-fold CV grid search object 'grid_dt'\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='accuracy',\n",
    "                       cv=10,\n",
    "                       n_jobs=-1)\n",
    "# Fit 'grid_dt' to the training data\n",
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      " {'max_depth': 3, 'max_features': 0.2, 'min_samples_leaf': 0.06}\n"
     ]
    }
   ],
   "source": [
    "# Extract best hyperparameters from 'grid_dt'\n",
    "best_hyperparams = grid_dt.best_params_\n",
    "print('Best hyperparameters:\\n', best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Extract best CV score from 'grid_dt'\n",
    "best_CV_score = grid_dt.best_score_\n",
    "print('Best CV accuracy: {:.2f}'.format(best_CV_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of best model: 0.868\n"
     ]
    }
   ],
   "source": [
    "# Extract best model from 'grid_dt'\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Evaluate test set accuracy\n",
    "test_acc = best_model.score(X_test, y_test)\n",
    "\n",
    "#Print test set accuracy\n",
    "print(\"Test set accuracy of best model: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Indian Liver Patient Records\n",
    "### [Dataset URL](https://www.kaggle.com/uciml/indian-liver-patient-records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'indian_liver_patient_preprocessed.csv'\n",
    "data = pd.read_csv(url, index_col=0)\n",
    "\n",
    "X = data.drop(labels=['Total_Bilirubin_std',\n",
    "                      'Liver_disease',\n",
    "                     'Direct_Bilirubin_std',\n",
    "                     'Alkaline_Phosphotase_std',\n",
    "                     'Alamine_Aminotransferase_std',\n",
    "                     'Aspartate_Aminotransferase_std',\n",
    "                     'Albumin_std',\n",
    "                     'Albumin_and_Globulin_Ratio_std',\n",
    "                     'Is_male_std'], axis=1)\n",
    "y = data.Liver_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Set seed to 1 for repoducibility\n",
    "SEED = 1\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier 'dt'\n",
    "dt = DecisionTreeClassifier(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params_dt\n",
    "params_dt = {'max_depth': [2,3,4], 'min_samples_leaf': [0.12,0.14,0.16,0.18]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1), n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Fit 'grid_dt' to the training data\n",
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.543\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score from sklearn.metrics \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning a Random Forest's Hyperparameters\n",
    "## Random Forests (RF) Hyperparameters\n",
    "- CART hyperparameters\n",
    "- number of estimators\n",
    "- bootstrap\n",
    "- ...\n",
    "\n",
    "**NOTE:** Tuning is expensive\n",
    "- Hyperparameter tuning:\n",
    "    - computationally expensive\n",
    "    - sometimes leads to very slight improvement\n",
    "- Therefore, weigh the impact of tuning on the whole project.\n",
    "## Inspecting RF Hyperparameters in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Instantiate a random forest regressor 'rf'\n",
    "rf = RandomForestRegressor(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=1), n_jobs=-1,\n",
       "             param_grid={'max_depth': [4, 6, 8],\n",
       "                         'max_features': ['log2', 'sqrt'],\n",
       "                         'min_samples_leaf': [0.1, 0.2],\n",
       "                         'n_estimators': [300, 400, 500]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic imports\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Define a grid of hyperparameters 'params_rf'\n",
    "params_rf = {\n",
    "             'n_estimators': [300,400,500],\n",
    "             'max_depth': [4,6,8],\n",
    "             'min_samples_leaf': [0.1,0.2],\n",
    "             'max_features': ['log2', 'sqrt']\n",
    "            }\n",
    "\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       n_jobs=-1,\n",
    "                       verbose=1)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      " {'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 0.1, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# Extract best hyperparameters form 'grid_rf'\n",
    "best_hyperparams = grid_rf.best_params_\n",
    "\n",
    "print('Best hyperparameters:\\n', best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 0.45\n"
     ]
    }
   ],
   "source": [
    "# Extract best model from 'grid_rf'\n",
    "best_model = grid_rf.best_estimator_\n",
    "# Predict the test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "# Print the test set RMSE\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bike share dataset\n",
    "bike_share_train = pd.read_csv(\"bike_share_train.csv\")\n",
    "\n",
    "y = bike_share_train[\"count\"]\n",
    "\n",
    "datetime = bike_share_train.datetime\n",
    "bike_share_train[\"year\"] = [x[:4] for x in datetime]\n",
    "bike_share_train[\"month\"] = [x[5:7] for x in datetime]\n",
    "bike_share_train[\"day\"] = [x[8:10] for x in datetime]\n",
    "bike_share_train[\"hour\"] = [x[11:13] for x in datetime]\n",
    "\n",
    "X = bike_share_train.drop(['datetime', 'count', 'registered', 'casual'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary 'params_rf'\n",
    "params_rf = {\n",
    "             'n_estimators': [100,350,500],\n",
    "             'min_samples_leaf': [2,10,30],\n",
    "             'max_features': ['log2','auto','sqrt']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=1), n_jobs=-1,\n",
       "             param_grid={'max_features': ['log2', 'auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [2, 10, 30],\n",
       "                         'n_estimators': [100, 350, 500]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_rf\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 0.452\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
