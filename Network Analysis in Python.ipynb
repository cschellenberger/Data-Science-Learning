{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis in Python (Part 1)\n",
    "\n",
    "## [DataCamp Course Description](https://www.datacamp.com/courses/network-analysis-in-python-part-1)\n",
    "\n",
    "### Datasets: [Twitter network](https://assets.datacamp.com/production/course_1822/datasets/ego-twitter.p) [GitHub users](https://assets.datacamp.com/production/course_1822/datasets/github_users.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks\n",
    "- Insights into your network data\n",
    "    - Important entities: influencers in a social network for example\n",
    "    - Pathfinding: most efficient transportation path\n",
    "    - Clustering: finding communities\n",
    "    \n",
    "# Network structure\n",
    "- **Nodes** and **Edges**\n",
    "![nodes](http://mathworld.wolfram.com/images/eps-gif/GraphNodesEdges_1000.gif)\n",
    "- Together, nodes and edges make a **Graph**\n",
    "\n",
    "# NetworkX API basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.nodes()` method shows us the nodes that are present in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView((1, 2, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from([1,2,3])\n",
    "G.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an edge between the nodes 1 and 2 `.add_edge()`, we can use the `.edges()` method to return a list of tuples which represent the edges. Each tuple shows the nodes that are present on that edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeView([(1, 2)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata can be stored on the graph as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeDataView({1: {'label': 'blue'}, 2: {}, 3: {}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.node[1]['label'] = 'blue'\n",
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output a **node link diagram rendering** of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nx.draw(G)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Draw the graph to screen\n",
    "nx.draw(G)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[` _output expression_ `for` _iterator variable_ `in` _iterable_ `if` _predicate expression_ `]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-513f957cae3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ego-twitter.p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<decorator-gen-528>\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(func_to_be_decorated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Finally, we call the original function, making sure to close the fobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_to_be_decorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/networkx/readwrite/gpickle.py\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# fixture for nose tests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "T = nx.read_gpickle('ego-twitter.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension to get the nodes of interest: noi\n",
    "noi = [n for n, d in T.nodes(data=True) if d['occupation'] == 'scientist']\n",
    "\n",
    "# Use a list comprehension to get the edges of interest: eoi\n",
    "eoi = [(u, v) for u, v, d in T.edges(data=True) if d['date'] < date(2010, 1, 1)]\n",
    "\n",
    "print(noi, eoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Graphs\n",
    "\n",
    "## Undirected graphs\n",
    "- There is no inherent direction with the association\n",
    "- Facebook social graph\n",
    "\n",
    "```python\n",
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "type(G)\n",
    "```\n",
    "\n",
    "`networkx.classes.graph.Graph`\n",
    "\n",
    "## Directed graphs\n",
    "- There is an inherent direction with the association\n",
    "- Twitter social graph (You may follow without a follow back)\n",
    "\n",
    "```python\n",
    "D = nx.DiGraph()\n",
    "type(D)\n",
    "```\n",
    "\n",
    "`networkx.classes.digraph.DiGraph`\n",
    "\n",
    "## Multi(Di)Graph\n",
    "- Multiple edges between the nodes\n",
    "- Trip records between bike sharing stations\n",
    "\n",
    "```python\n",
    "M = nx.MultiGraph()\n",
    "\n",
    "type(M)\n",
    "```\n",
    "\n",
    "`networkx.classes.multigraph.MultiGraph`\n",
    "\n",
    "```python\n",
    "MD = nx.MultiDiGraph()\n",
    "\n",
    "type(MD)\n",
    "```\n",
    "\n",
    "`networkx.classes.multidigraph.MultiDiGraph`\n",
    "\n",
    "# Weights on graphs\n",
    "- If we want to collapse many edges into one weighted edge\n",
    "\n",
    "# Self-loops\n",
    "- Nodes that are connected to themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the weight of the edge\n",
    "T.edge[1][10]['weight'] = 2\n",
    "\n",
    "# Iterate over all the edges (with metadata)\n",
    "for u, v, d in T.edges(data=True):\n",
    "\n",
    "    # Check if node 293 is involved\n",
    "    if 293 in [u, v]:\n",
    "    \n",
    "        # Set the weight to 1.1\n",
    "        T.edge[u][v]['weight'] = 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll find the `assert` statement useful. An `assert`-ions checks whether the statement placed after it evaluates to `True`, otherwise it will return an `AssertionError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.number_of_selfloops() #42\n",
    "\n",
    "# Define find_selfloop_nodes()\n",
    "def find_selfloop_nodes(G):\n",
    "    \"\"\"\n",
    "    Finds all nodes that have self-loops in the graph G.\n",
    "    \"\"\"\n",
    "    nodes_in_selfloops = []\n",
    "    \n",
    "    # Iterate over all the edges of G\n",
    "    for u, v in G.edges():\n",
    "    \n",
    "    # Check if node u and node v are the same\n",
    "        if u == v:\n",
    "        \n",
    "            # Append node u to nodes_in_selfloops\n",
    "            nodes_in_selfloops.append(u)\n",
    "            \n",
    "    return nodes_in_selfloops\n",
    "\n",
    "# Check whether number of self loops equals the number of nodes in self loops\n",
    "assert T.number_of_selfloops() == len(find_selfloop_nodes(T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Irrational vs. Rational visualizations\n",
    "\n",
    "## Visualizing networks\n",
    "- Matrix plots\n",
    "- Arc plots\n",
    "- Circos plots\n",
    "\n",
    "# Matrix plots\n",
    "- Nodes are the rows and columns of a matrix\n",
    "- The cells are filled in if an edge exists between the pair of nodes\n",
    "- In an undirected graph the graph is symmetrical across the diagonal\n",
    "- In Directed matrices the graph is not necessarily symmetrical\n",
    "- **If the nodes are ordered along the rows and columns—such that the neighbours are listed close to one another—then a matrix plot can be used to visualize clusters or communities of nodes.**\n",
    "\n",
    "# Arc plots\n",
    "- If properly ordered along the horizontal, these plots can visualize the realationship between connectivity and the sorted or grouped property.\n",
    "- Arc plots are a good starting point for visualization because it forms the basis for further analysis.\n",
    "\n",
    "# Circos plot\n",
    "- An esstetic version of the Arc plot where the ends of the horizontal Arc plot are connected into a circle.\n",
    "\n",
    "```python\n",
    "import nxviz as nv\n",
    "import matplotlib.pyplot as plt\n",
    "ap = nv.ArcPlot(G)\n",
    "ap.draw()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nxviz\n",
    "import nxviz as nv\n",
    "\n",
    "# Create the MatrixPlot object: m\n",
    "m = nv.MatrixPlot(T)\n",
    "\n",
    "# Draw m to the screen\n",
    "m.draw()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Convert T to a matrix format: A\n",
    "A = nx.to_numpy_matrix(T)\n",
    "\n",
    "# Convert A back to the NetworkX form as a directed graph: T_conv\n",
    "T_conv = nx.from_numpy_matrix(A, create_using=nx.DiGraph())\n",
    "\n",
    "# Check that the `category` metadata field is lost from each node\n",
    "for n, d in T_conv.nodes(data=True):\n",
    "    assert 'category' not in d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "from nxviz import CircosPlot\n",
    "\n",
    "# Create the CircosPlot object: c\n",
    "c = CircosPlot(T)\n",
    "\n",
    "# Draw c to the screen\n",
    "c.draw()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "from nxviz import ArcPlot\n",
    "\n",
    "# Create the un-customized ArcPlot object: a\n",
    "a = ArcPlot(T)\n",
    "\n",
    "# Draw a to the screen\n",
    "a.draw()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Create the customized ArcPlot object: a2\n",
    "a2 = ArcPlot(T, node_order='category', node_color='category')\n",
    "\n",
    "# Draw a2 to the screen\n",
    "a2.draw()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degree centality\n",
    "- Which nodes are important?\n",
    "    - Degree centrality\n",
    "    - Betweenness centrality\n",
    "    \n",
    "## Degree centrality\n",
    "\n",
    "# $$\\frac{\\text{Number of Neighbours I Have}}{\\text{Number of Neighbours I Could Possibly Have}}$$\n",
    "\n",
    "- Example of nodes with high degree centrality\n",
    "    - Twitter broadcasters\n",
    "    - Airport transportations hubs\n",
    "    - Disease super-spreaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "G.add_nodes_from(np.arange(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in np.arange(2, 10):\n",
    "    G.add_edge(1,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G.neighbors(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G.neighbors(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `degree_centrality()` function, self-loops are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define nodes_with_m_nbrs()\n",
    "def nodes_with_m_nbrs(G, m):\n",
    "    \"\"\"\n",
    "    Returns all nodes in graph G that have m neighbors.\n",
    "    \"\"\"\n",
    "    nodes = set()\n",
    "    \n",
    "    # Iterate over all nodes in G\n",
    "    for n in G.nodes():\n",
    "    \n",
    "        # Check if the number of neighbors of n matches m\n",
    "        if len(G.neighbors(n)) == m:\n",
    "        \n",
    "            # Add the node n to the set\n",
    "            nodes.add(n)\n",
    "            \n",
    "    # Return the nodes with m neighbors\n",
    "    return nodes\n",
    "\n",
    "# Compute and print all nodes in T that have 6 neighbors\n",
    "six_nbrs = nodes_with_m_nbrs(T, 6)\n",
    "print(six_nbrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the degree of every node: degrees\n",
    "degrees = [len(T.neighbors(n)) for n in T.nodes()]\n",
    "\n",
    "# Print the degrees\n",
    "print(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the degree centrality of the Twitter network: deg_cent\n",
    "deg_cent = nx.degree_centrality(T)\n",
    "\n",
    "# Plot a histogram of the degree centrality distribution of the graph.\n",
    "plt.figure()\n",
    "plt.hist(list(deg_cent.values()))\n",
    "plt.show()\n",
    "\n",
    "# Plot a histogram of the degree distribution of the graph\n",
    "plt.figure()\n",
    "plt.hist(degrees)\n",
    "plt.show()\n",
    "\n",
    "# Plot a scatter plot of the centrality distribution and the degree distribution\n",
    "plt.figure()\n",
    "plt.scatter(degrees, list(deg_cent.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph algorithms\n",
    "\n",
    "## Pathfinding\n",
    "- Finding paths\n",
    "    - Optimization: eg. shortest tansportation paths\n",
    "    - Modeling: eg. disease spread, information passing\n",
    "\n",
    "# Breadth-first search (BFS)\n",
    "- Example: Shortest path between two nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path_exists()\n",
    "def path_exists(G,node1, node2):\n",
    "    \"\"\"\n",
    "    This function checks whether a path exists between two nodes (node1, node2) in graph G.\n",
    "    \"\"\"\n",
    "    visited_nodes = set()\n",
    "    \n",
    "    # Initialize the queue of cells to visit with the first node: queue\n",
    "    queue = [node1] \n",
    "    \n",
    "    # Iterate over the nodes in the queue\n",
    "    for node in queue:\n",
    "    \n",
    "        # Get neighbors of the node\n",
    "        neighbors = G.neighbors(node) \n",
    "        \n",
    "        # Check to see if the destination node is in the set of neighbors\n",
    "        if node2 in neighbors:\n",
    "            print('Path exists between nodes {0} and {1}'.format(node1, node2))\n",
    "            return True\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_exists(G, node1, node2):\n",
    "    \"\"\"\n",
    "    This function checks whether a path exists between two nodes (node1, node2) in graph G.\n",
    "    \"\"\"\n",
    "    visited_nodes = set()\n",
    "    queue = [node1]\n",
    "    \n",
    "    for node in queue:  \n",
    "        neighbors = G.neighbors(node)\n",
    "        if node2 in neighbors:\n",
    "            print('Path exists between nodes {0} and {1}'.format(node1, node2))\n",
    "            return True\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            # Add current node to visited nodes\n",
    "            visited_nodes.add(node)\n",
    "            \n",
    "            # Add neighbors of current node that have not yet been visited\n",
    "            queue.extend([n for n in neighbors if n not in visited_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_exists(G, node1, node2):\n",
    "    \"\"\"\n",
    "    This function checks whether a path exists between two nodes (node1, node2) in graph G.\n",
    "    \"\"\"\n",
    "    visited_nodes = set()\n",
    "    queue = [node1]\n",
    "    \n",
    "    for node in queue:  \n",
    "        neighbors = G.neighbors(node)\n",
    "        if node2 in neighbors:\n",
    "            print('Path exists between nodes {0} and {1}'.format(node1, node2))\n",
    "            return True\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            visited_nodes.add(node)\n",
    "            queue.extend([n for n in neighbors if n not in visited_nodes])\n",
    "        \n",
    "        # Check to see if the final element of the queue has been reached\n",
    "        if node == queue[-1]:\n",
    "            print('Path does not exist between nodes {0} and {1}'.format(node1, node2))\n",
    "\n",
    "            # Place the appropriate return statement\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Betweenness centrality\n",
    "\n",
    "## All shortest paths\n",
    "- Set of paths\n",
    "- Each path is shortest path between a given pair of nodes\n",
    "- Done for all node pairs\n",
    "\n",
    "# Definition: \n",
    "\n",
    "# $$\\frac{\\text{num. shortest paths through node}}{\\text{all possible shortest paths}}$$\n",
    "\n",
    "- Captures bottlenecked nodes rather than highly connected nodes.\n",
    "\n",
    "# Application:\n",
    "- Bridges between liberal- and conservative- leaning Twitter users\n",
    "- Critical information transfer links in the Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.barbell_graph(m1=5, m2=1)\n",
    "\n",
    "nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the betweenness centrality of T: bet_cen\n",
    "bet_cen = nx.betweenness_centrality(T)\n",
    "\n",
    "# Compute the degree centrality of T: deg_cen\n",
    "deg_cen = nx.degree_centrality(T)\n",
    "\n",
    "# Create a scatter plot of betweenness centrality and degree centrality\n",
    "plt.scatter(list(bet_cen.values()), list(deg_cen.values()))\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define find_nodes_with_highest_deg_cent()\n",
    "def find_nodes_with_highest_deg_cent(G):\n",
    "\n",
    "    # Compute the degree centrality of G: deg_cent\n",
    "    deg_cent = nx.degree_centrality(G)\n",
    "    \n",
    "    # Compute the maximum degree centrality: max_dc\n",
    "    max_dc = max(list(deg_cent.values()))\n",
    "    \n",
    "    nodes = set()\n",
    "    \n",
    "    # Iterate over the degree centrality dictionary\n",
    "    for k, v in deg_cent.items():\n",
    "    \n",
    "        # Check if the current value has the maximum degree centrality\n",
    "        if v == max_dc:\n",
    "        \n",
    "            # Add the current node to the set of nodes\n",
    "            nodes.add(k)\n",
    "            \n",
    "    return nodes\n",
    "    \n",
    "# Find the node(s) that has the highest degree centrality in T: top_dc\n",
    "top_dc = find_nodes_with_highest_deg_cent(T)\n",
    "print(top_dc)\n",
    "\n",
    "# Write the assertion statement\n",
    "for node in top_dc:\n",
    "    assert nx.degree_centrality(T)[node] == max(nx.degree_centrality(T).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define find_node_with_highest_bet_cent()\n",
    "def find_node_with_highest_bet_cent(G):\n",
    "\n",
    "    # Compute betweenness centrality: bet_cent\n",
    "    bet_cent = nx.betweenness_centrality(G)\n",
    "    \n",
    "    # Compute maximum betweenness centrality: max_bc\n",
    "    max_bc = max(list(bet_cent.values()))\n",
    "    \n",
    "    nodes = set()\n",
    "    \n",
    "    # Iterate over the betweenness centrality dictionary\n",
    "    for k, v in bet_cent.items():\n",
    "    \n",
    "        # Check if the current value has the maximum betweenness centrality\n",
    "        if v == max_bc:\n",
    "        \n",
    "            # Add the current node to the set of nodes\n",
    "            nodes.add(k)\n",
    "            \n",
    "    return nodes\n",
    "\n",
    "# Use that function to find the node(s) that has the highest betweenness centrality in the network: top_bc\n",
    "top_bc = find_node_with_highest_bet_cent(T)\n",
    "\n",
    "# Write an assertion statement that checks that the node(s) is/are correctly identified.\n",
    "for node in top_bc:\n",
    "    assert nx.betweenness_centrality(T)[node] == max(nx.betweenness_centrality(T).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cliques and communities\n",
    "- Social cliques: tightly-knit groups\n",
    "- Network cliques: completely connected graphs\n",
    "\n",
    "- Simplest definition of a clique is an edge\n",
    "- Simplest complex clique: a triangle\n",
    "\n",
    "# Triangle applications\n",
    "- Friend recommendation systems\n",
    "\n",
    "# Clique code\n",
    "```python\n",
    "from itertools import combinations\n",
    "\n",
    "for n1, n2 in combination(G.nodes(), 2):\n",
    "    print(n1, n2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Define is_in_triangle() \n",
    "def is_in_triangle(G, n):\n",
    "    \"\"\"\n",
    "    Checks whether a node `n` in graph `G` is in a triangle relationship or not. \n",
    "    \n",
    "    Returns a boolean.\n",
    "    \"\"\"\n",
    "    in_triangle = False\n",
    "    \n",
    "    # Iterate over all possible triangle relationship combinations\n",
    "    for n1, n2 in combinations(G.neighbors(n), 2):\n",
    "    \n",
    "        # Check if an edge exists between n1 and n2\n",
    "        if G.has_edge(n1, n2):\n",
    "            in_triangle = True\n",
    "            break\n",
    "    return in_triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Write a function that identifies all nodes in a triangle relationship with a given node.\n",
    "def nodes_in_triangle(G, n):\n",
    "    \"\"\"\n",
    "    Returns the nodes in a graph `G` that are involved in a triangle relationship with the node `n`.\n",
    "    \"\"\"\n",
    "    triangle_nodes = set([n])\n",
    "    \n",
    "    # Iterate over all possible triangle relationship combinations\n",
    "    for n1, n2 in combinations(G.neighbors(n), 2):\n",
    "    \n",
    "        # Check if n1 and n2 have an edge between them\n",
    "        if G.has_edge(n1, n2):\n",
    "        \n",
    "            # Add n1 to triangle_nodes\n",
    "            triangle_nodes.add(n1)\n",
    "            \n",
    "            # Add n2 to triangle_nodes\n",
    "            triangle_nodes.add(n2)\n",
    "            \n",
    "    return triangle_nodes\n",
    "    \n",
    "# Write the assertion statement\n",
    "assert len(nodes_in_triangle(T, 1)) == 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Define node_in_open_triangle()\n",
    "def node_in_open_triangle(G, n):\n",
    "    \"\"\"\n",
    "    Checks whether pairs of neighbors of node `n` in graph `G` are in an 'open triangle' relationship with node `n`.\n",
    "    \"\"\"\n",
    "    in_open_triangle = False\n",
    "    \n",
    "    # Iterate over all possible triangle relationship combinations\n",
    "    for n1, n2 in combinations(G.neighbors(n), 2):\n",
    "    \n",
    "        # Check if n1 and n2 do NOT have an edge between them\n",
    "        if not G.has_edge(n1, n2):\n",
    "        \n",
    "            in_open_triangle = True\n",
    "            \n",
    "            break\n",
    "            \n",
    "    return in_open_triangle\n",
    "\n",
    "# Compute the number of open triangles in T\n",
    "num_open_triangles = 0\n",
    "\n",
    "# Iterate over all the nodes in T\n",
    "for n in T.nodes():\n",
    "\n",
    "    # Check if the current node is in an open triangle\n",
    "    if node_in_open_triangle(T, n):\n",
    "    \n",
    "        # Increment num_open_triangles\n",
    "        num_open_triangles += 1\n",
    "        \n",
    "print(num_open_triangles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximal Cliques\n",
    "- Definition: a clique that, when extended by one node is no longer a clique.\n",
    "- Applications: community finding\n",
    "\n",
    "# Communities\n",
    "- Find cliques\n",
    "- Find unions of cliques\n",
    "    - One naive way of identifying communities would be to find these unions of maximal cliques that share some number of members but are also part of some minimum size.\n",
    "- find_cliques finds all **maximal** cliques\n",
    "\n",
    "```python\n",
    "import networkx as nx\n",
    "G = nx.barbell_graph(m1=5, m2=1)\n",
    "nx.find_cliques(G)\n",
    "\n",
    "list(nx.find_cliques(G))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define maximal_cliques()\n",
    "def maximal_cliques(G, size):\n",
    "    \"\"\"\n",
    "    Finds all maximal cliques in graph `G` that are of size `size`.\n",
    "    \"\"\"\n",
    "    mcs = []\n",
    "    for clique in nx.find_cliques(G):\n",
    "        if len(clique) == size:\n",
    "            mcs.append(clique)\n",
    "    return mcs\n",
    "\n",
    "# Check that there are 33 maximal cliques of size 3 in the graph T\n",
    "assert len(maximal_cliques(T, 3)) == 33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgraphs\n",
    "- Visualize portions of a large graph\n",
    "    - Paths\n",
    "    - Communities/cliques\n",
    "    - Degrees of separation from a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.erdos_renyi_graph(n=20, p=0.3)\n",
    "\n",
    "G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = G.neighbors(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(nodes)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.append(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_eight = G.subgraph(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_eight.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_eight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_eight, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_of_interest = [29, 38, 42]\n",
    "\n",
    "# Define get_nodes_and_nbrs()\n",
    "def get_nodes_and_nbrs(G, nodes_of_interest):\n",
    "    \"\"\"\n",
    "    Returns a subgraph of the graph `G` with only the `nodes_of_interest` and their neighbors.\n",
    "    \"\"\"\n",
    "    nodes_to_draw = []\n",
    "    \n",
    "    # Iterate over the nodes of interest\n",
    "    for n in nodes_of_interest:\n",
    "    \n",
    "        # Append the nodes of interest to nodes_to_draw\n",
    "        nodes_to_draw.append(n)\n",
    "        \n",
    "        # Iterate over all the neighbors of node n\n",
    "        for nbr in G.neighbors(n):\n",
    "        \n",
    "            # Append the neighbors of n to nodes_to_draw\n",
    "            nodes_to_draw.append(nbr)\n",
    "            \n",
    "    return G.subgraph(nodes_to_draw)\n",
    "\n",
    "# Extract the subgraph with the nodes of interest: T_draw\n",
    "T_draw = get_nodes_and_nbrs(T, nodes_of_interest)\n",
    "\n",
    "# Draw the subgraph to the screen\n",
    "nx.draw(T_draw)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the nodes of interest: nodes\n",
    "nodes = [n for n, d in T.nodes(data=True) if d['occupation'] == 'celebrity']\n",
    "\n",
    "# Create the set of nodes: nodeset\n",
    "nodeset = set(nodes)\n",
    "\n",
    "# Iterate over nodes\n",
    "for n in nodes:\n",
    "\n",
    "    # Compute the neighbors of n: nbrs\n",
    "    nbrs = T.neighbors(n)\n",
    "    \n",
    "    # Compute the union of nodeset and nbrs: nodeset\n",
    "    nodeset = nodeset.union(nbrs)\n",
    "\n",
    "# Compute the subgraph using nodeset: T_sub\n",
    "T_sub = T.subgraph(nodeset)\n",
    "\n",
    "# Draw T_sub to the screen\n",
    "nx.draw(T_sub)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study\n",
    "## Github user collaboration network\n",
    "- Nodes: users\n",
    "- Edges: collaboration on same GitHub repository\n",
    "- Goals:\n",
    "    - Analyze structure\n",
    "    - Vixualize\n",
    "    - Build simple recommendation system\n",
    "\n",
    "# Review of simple functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.erdos_renyi_graph(n=20, p=0.2)\n",
    "len(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.__version__)    # DataCamp version 11/2018 -- 1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx \n",
    "\n",
    "# Plot the degree distribution of the GitHub collaboration network\n",
    "plt.hist(list(nx.degree_centrality(G).values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Plot the degree distribution of the GitHub collaboration network\n",
    "plt.hist(list(nx.betweenness_centrality(G).values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study\n",
    "## Visualizations\n",
    "### nxviz API Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import nxviz as nv\n",
    "G = nx.erdos_renyi_graph(n=20, p=0.3)\n",
    "circ = nv.CircosPlot(G)    # node_color='key', node_group='key'\n",
    "circ.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connected component subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.erdos_renyi_graph(n=100, p=0.03)\n",
    "nx.connected_component_subgraphs(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.connected_component_subgraphs(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in list(nx.connected_component_subgraphs(G)):\n",
    "    print(len(g.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from nxviz import MatrixPlot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the largest connected component subgraph: largest_ccs\n",
    "largest_ccs = sorted(nx.connected_component_subgraphs(G), key=lambda x: len(x))[-1]\n",
    "\n",
    "# Create the customized MatrixPlot object: h\n",
    "h = MatrixPlot(graph=largest_ccs, node_grouping='grouping')\n",
    "\n",
    "# Draw the MatrixPlot to the screen\n",
    "h.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from nxviz.plots import ArcPlot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Iterate over all the nodes in G, including the metadata\n",
    "for n, d in G.nodes(data=True):\n",
    "\n",
    "    # Calculate the degree of each node: G.node[n]['degree']\n",
    "    G.node[n]['degree'] = nx.degree(G, n)\n",
    "    \n",
    "# Create the ArcPlot object: a\n",
    "a = ArcPlot(graph=G, node_order='degree')\n",
    "\n",
    "# Draw the ArcPlot to the screen\n",
    "a.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from nxviz import CircosPlot\n",
    "import matplotlib.pyplot as plt \n",
    " \n",
    "# Iterate over all the nodes, including the metadata\n",
    "for n, d in G.nodes(data=True):\n",
    "\n",
    "    # Calculate the degree of each node: G.node[n]['degree']\n",
    "    G.node[n]['degree'] = nx.degree(G, n)\n",
    "\n",
    "# Create the CircosPlot object: c\n",
    "c = CircosPlot(graph=G, node_order='degree', node_grouping='grouping', node_color='grouping')\n",
    "\n",
    "# Draw the CircosPlot object to the screen\n",
    "c.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.erdos_renyi_graph(n=100, p=0.15)\n",
    "nx.find_cliques(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the maximal cliques in G: cliques\n",
    "cliques = nx.find_cliques(G)\n",
    "\n",
    "# Count and print the number of maximal cliques in G\n",
    "print(len(list(cliques)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import networkx as nx\n",
    "from nxviz import CircosPlot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find the author(s) that are part of the largest maximal clique: largest_clique\n",
    "largest_clique = sorted(nx.find_cliques(G), key=lambda x:len(x))[-1]\n",
    "\n",
    "# Create the subgraph of the largest_clique: G_lc\n",
    "G_lc = G.subgraph(largest_clique)\n",
    "\n",
    "# Create the CircosPlot object: c\n",
    "c = CircosPlot(graph=G_lc)\n",
    "\n",
    "# Draw the CircosPlot to the screen\n",
    "c.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Tasks\n",
    "\n",
    "- Find important users\n",
    "    - degree_centrality\n",
    "- Find largest communities of collaborators\n",
    "    - maximal clique\n",
    "- Build a collaboration recommendation system\n",
    "    - open triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the degree centralities of G: deg_cent\n",
    "deg_cent = nx.degree_centrality(G)\n",
    "\n",
    "# Compute the maximum degree centrality: max_dc\n",
    "max_dc = max(list(deg_cent.values()))\n",
    "\n",
    "# Find the user(s) that have collaborated the most: prolific_collaborators\n",
    "prolific_collaborators = [n for n, dc in deg_cent.items() if n == max_dc]\n",
    "\n",
    "# Print the most prolific collaborator(s)\n",
    "print(prolific_collaborators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from nxviz import ArcPlot\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Identify the largest maximal clique: largest_max_clique\n",
    "largest_max_clique = set(sorted(nx.find_cliques(G), key=lambda x: len(x))[-1])\n",
    "\n",
    "# Create a subgraph from the largest_max_clique: G_lmc\n",
    "G_lmc = G.subgraph(largest_max_clique)\n",
    "\n",
    "# Go out 1 degree of separation\n",
    "for node in G_lmc.nodes():\n",
    "    G_lmc.add_nodes_from(G.neighbors(node))\n",
    "    G_lmc.add_edges_from(zip([node]*len(G.neighbors(node)), G.neighbors(node)))\n",
    "\n",
    "# Record each node's degree centrality score\n",
    "for n in G_lmc.nodes():\n",
    "    G_lmc.node[n]['degree centrality'] = nx.degree_centrality(G_lmc)[n]\n",
    "        \n",
    "# Create the ArcPlot object: a\n",
    "a = ArcPlot(graph=G_lmc, node_order='degree centrality')\n",
    "\n",
    "# Draw the ArcPlot to the screen\n",
    "a.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize the defaultdict: recommended\n",
    "recommended = defaultdict(int)\n",
    "\n",
    "# Iterate over all the nodes in G\n",
    "for n, d in G.nodes(data=True):\n",
    "\n",
    "    # Iterate over all possible triangle relationship combinations\n",
    "    for n1, n2 in combinations(G.neighbors(n), 2):\n",
    "    \n",
    "        # Check whether n1 and n2 do not have an edge\n",
    "        if not G.has_edge(n1, n2):\n",
    "        \n",
    "            # Increment recommended\n",
    "            recommended[(n1, n2)] += 1\n",
    "\n",
    "# Identify the top 10 pairs of users\n",
    "all_counts = sorted(recommended.values())\n",
    "top10_pairs = [pair for pair, count in recommended.items() if count > all_counts[-10]]\n",
    "print(top10_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis in Python (Part 2)\n",
    "## [DataCamp Link](https://www.datacamp.com/courses/network-analysis-in-python-part-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the degree centrality score of each node to their metadata dictionary\n",
    "dcs = nx.degree_centrality(G)\n",
    "for n in G.nodes():\n",
    "    G.node[n]['centrality'] = dcs[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CircosPlot object: c\n",
    "c = CircosPlot(G, node_color='bipartite', node_grouping='bipartite', node_order='centrality')\n",
    "\n",
    "# Draw c to the screen\n",
    "c.draw()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bipartite Graphs\n",
    "- A graph that is partitioned into two sets\n",
    "- Nodes are only connected to nodes in other partitions\n",
    "- Contrast: \"unipartite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "numbers = range(3)\n",
    "G.add_nodes_from(numbers, bipartite='customers')\n",
    "letters = ['a', 'b']\n",
    "G.add_nodes_from(letters, bipartite='products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_nodes = [n for n, d in G.nodes(data=True) if d['bipartite'] == 'customers']\n",
    "\n",
    "cust_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.bipartite.degree_centrality(G, cust_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define get_nodes_from_partition()\n",
    "def get_nodes_from_partition(G, partition):\n",
    "    # Initialize an empty list for nodes to be returned\n",
    "    nodes = []\n",
    "    # Iterate over each node in the graph G\n",
    "    for n in G.nodes():\n",
    "        # Check that the node belongs to the particular partition\n",
    "        if G.node[n]['bipartite'] == partition:\n",
    "            # If so, append it to the list of nodes\n",
    "             nodes.append(n)\n",
    "    return nodes\n",
    "\n",
    "# Print the number of nodes in the 'projects' partition\n",
    "print(len(get_nodes_from_partition(G, 'projects')))\n",
    "\n",
    "# Print the number of nodes in the 'users' partition\n",
    "print(len(get_nodes_from_partition(G, 'users')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the 'users' nodes: user_nodes\n",
    "user_nodes = get_nodes_from_partition(G, 'users')\n",
    "\n",
    "# Compute the degree centralities: dcs\n",
    "dcs = nx.degree_centrality(G)\n",
    "\n",
    "# Get the degree centralities for user_nodes: user_dcs\n",
    "user_dcs = [dcs[n] for n in user_nodes]\n",
    "\n",
    "# Plot the degree distribution of users_dcs\n",
    "plt.yscale('log')\n",
    "plt.hist(user_dcs, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 'projects' nodes: project_nodes\n",
    "project_nodes = get_nodes_from_partition(G, 'projects')\n",
    "\n",
    "# Compute the degree centralities: dcs\n",
    "dcs = nx.degree_centrality(G)\n",
    "\n",
    "# Get the degree centralities for project_nodes: project_dcs\n",
    "project_dcs = [dcs[n] for n in project_nodes]\n",
    "\n",
    "# Plot the degree distribution of project_dcs\n",
    "plt.yscale('log')\n",
    "plt.hist(project_dcs, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bipartite graphs and recommendation systems\n",
    "- Previously: Recommended users to connect with one another\n",
    "- Graph: \"unipartite\" or (user-only) version\n",
    "- Now: \"bipartite\" or (repo-users) version\n",
    "- Recommending repositories for users to work on\n",
    "\n",
    "# Code: Node sets\n",
    "```python\n",
    "user1_nbrs = G.neighbors('user1')\n",
    "\n",
    "user3_nbrs = G.neighbors('user3')\n",
    "\n",
    "set(user1_nbrs).intersection(user3_nbrs)\n",
    "\n",
    "set(user3_nbrs).difference(user1_nbrs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_partition_nodes(G, node1, node2):\n",
    "    # Check that the nodes belong to the same partition\n",
    "    assert G.node[node1]['bipartite'] == G.node[node2]['bipartite']\n",
    "\n",
    "    # Get neighbors of node 1: nbrs1\n",
    "    nbrs1 = G.neighbors(node1)\n",
    "    # Get neighbors of node 2: nbrs2\n",
    "    nbrs2 = G.neighbors(node2)\n",
    "\n",
    "    # Compute the overlap using set intersections\n",
    "    overlap = set(nbrs1).intersection(nbrs2)\n",
    "    return overlap\n",
    "\n",
    "# Print the number of shared repositories between users 'u7909' and 'u2148'\n",
    "print(len(shared_partition_nodes(G, 'u7909', 'u2148')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_similarity(G, user1, user2, proj_nodes):\n",
    "    # Check that the nodes belong to the 'users' partition\n",
    "    assert G.node[user1]['bipartite'] == 'users'\n",
    "    assert G.node[user2]['bipartite'] == 'users'\n",
    "\n",
    "    # Get the set of nodes shared between the two users\n",
    "    shared_nodes = shared_partition_nodes(G, user1, user2)\n",
    "\n",
    "    # Return the fraction of nodes in the projects partition\n",
    "    return len(shared_nodes) / len(proj_nodes)\n",
    "\n",
    "# Compute the similarity score between users 'u4560' and 'u1880'\n",
    "project_nodes = get_nodes_from_partition(G, 'projects')\n",
    "similarity_score = user_similarity(G, 'u4560', 'u1880', project_nodes)\n",
    "\n",
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def most_similar_users(G, user, user_nodes, proj_nodes):\n",
    "    # Data checks\n",
    "    assert G.node[user]['bipartite'] == 'users'\n",
    "\n",
    "    # Get other nodes from user partition\n",
    "    user_nodes = set(user_nodes)\n",
    "    user_nodes.remove(user)\n",
    "\n",
    "    # Create the dictionary: similarities\n",
    "    similarities = defaultdict(list)\n",
    "    for n in user_nodes:\n",
    "        similarity = user_similarity(G, user, n, proj_nodes)\n",
    "        similarities[similarity].append(n)\n",
    "\n",
    "    # Compute maximum similarity score: max_similarity\n",
    "    max_similarity = max(similarities.keys())\n",
    "\n",
    "    # Return list of users that share maximal similarity\n",
    "    return similarities[max_similarity]\n",
    "\n",
    "user_nodes = get_nodes_from_partition(G, 'users')\n",
    "project_nodes = get_nodes_from_partition(G, 'projects')\n",
    "\n",
    "print(most_similar_users(G, 'u4560', user_nodes, project_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_repositories(G, from_user, to_user):\n",
    "    # Get the set of repositories that from_user has contributed to\n",
    "    from_repos = set(G.neighbors(from_user))\n",
    "    # Get the set of repositories that to_user has contributed to\n",
    "    to_repos = set(G.neighbors(to_user))\n",
    "\n",
    "    # Identify repositories that the from_user is connected to that the to_user is not connected to\n",
    "    return from_repos.difference(to_repos)\n",
    "\n",
    "# Print the repositories to be recommended\n",
    "print(recommend_repositories(G, 'u7909', 'u2148'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept of Projection\n",
    "## When dealing with a bipartite graph\n",
    "- Useful to investigate the relationships between nodes on one partition\n",
    "    - Conditioned on the connections to the nodes in the other partition\n",
    "# Projection\n",
    "- Unipartite representation of bipartite connectivity\n",
    "\n",
    "# Bipartite projection\n",
    "```python\n",
    "G.nodes()\n",
    "\n",
    "G.edges()\n",
    "\n",
    "cust_nodes = [n for n in G.nodes() if G.node[n]['bipartite'] == 'customers']\n",
    "\n",
    "cust_nodes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " List comprehensions can include conditions, so if you want to filter a graph for a certain type of node, you can do: \n",
    " ```python\n",
    " [n for n, d in G.nodes(data=True) if d['key'] == 'some_value']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Plot the degree centrality distribution of both node partitions from the original graph\n",
    "plt.figure()\n",
    "original_dc = nx.bipartite.degree_centrality(G, people)\n",
    "plt.hist(list(original_dc.values()), alpha=0.5)\n",
    "plt.yscale('log')\n",
    "plt.title('Bipartite degree centrality')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the degree centrality distribution of the peopleG graph\n",
    "plt.figure()  \n",
    "people_dc = nx.degree_centrality(peopleG)\n",
    "plt.hist(list(people_dc.values()))\n",
    "plt.yscale('log')\n",
    "plt.title('Degree centrality of people partition')\n",
    "plt.show()\n",
    "\n",
    "# Plot the degree centrality distribution of the clubsG graph\n",
    "plt.figure() \n",
    "clubs_dc = nx.degree_centrality(clubsG)\n",
    "plt.hist(list(clubs_dc.values()))\n",
    "plt.yscale('log')\n",
    "plt.title('Degree centrality of clubs partition')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bipartite graphs as matrices\n",
    "\n",
    "```python\n",
    "cust_nodes = [n for n in G.nodes() if G.node[n]['bipartite'] == 'customers']\n",
    "\n",
    "prod_nodes = [n for n in G.nodes() if G.node[n]['bipartite'] == 'products']\n",
    "\n",
    "mat = nx.bipartite.biadjacency_matrix(G, row_order=cust_nodes, column_order=prod_nodes)\n",
    "\n",
    "mat\n",
    "```\n",
    "\n",
    "# Matrix multiplication in Python\n",
    "\n",
    "```python\n",
    "mat @ mat.T\n",
    "\n",
    "mat.T @ mat\n",
    "```\n",
    "\n",
    "Bipartite graph adjacency matrices are often asymmetric. Bipartite graph adjacency matrices are often asymmetric because there are more ways to construct an asymmetric bipartite graph than a symmetric one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of people and list of clubs from the graph: people_nodes, clubs_nodes\n",
    "people_nodes = get_nodes_from_partition(G, 'people')\n",
    "clubs_nodes = get_nodes_from_partition(G, 'clubs')\n",
    "\n",
    "# Compute the biadjacency matrix: bi_matrix\n",
    "bi_matrix = nx.bipartite.biadjacency_matrix(G, row_order=people_nodes, column_order=clubs_nodes)\n",
    "\n",
    "# Compute the user-user projection: user_matrix\n",
    "user_matrix = bi_matrix @ bi_matrix.T\n",
    "\n",
    "print(user_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Find out the names of people who were members of the most number of clubs\n",
    "diag = user_matrix.diagonal()\n",
    "indices = np.where(diag == diag.max())[0]  \n",
    "print('Number of clubs: {0}'.format(diag.max()))\n",
    "print('People with the most number of memberships:')\n",
    "for i in indices:\n",
    "    print('- {0}'.format(people_nodes[i]))\n",
    "\n",
    "# Set the diagonal to zero and convert it to a coordinate matrix format\n",
    "user_matrix.setdiag(0)\n",
    "users_coo = user_matrix.tocoo()\n",
    "\n",
    "# Find pairs of users who shared membership in the most number of clubs\n",
    "indices = np.where(users_coo.data == users_coo.data.max())[0]\n",
    "print('People with most number of shared memberships:')\n",
    "for idx in indices:\n",
    "    print('- {0}, {1}'.format(people_nodes[users_coo.row[idx]], people_nodes[users_coo.col[idx]])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing network data with pandas\n",
    "## CSV files for network data storage\n",
    "- Advantages\n",
    "    - Human-radable\n",
    "    - Do further analysis with pandas\n",
    "- Disadvantages\n",
    "    - Repetitive; disk space\n",
    "### We require:\n",
    "- Two DataFrames: node and edge lists\n",
    "\n",
    "# Node list\n",
    "- Each row is one node\n",
    "- The columns represent metadata attached to that node\n",
    "\n",
    "# Edge list\n",
    "- Each row is one edge\n",
    "- The columns represent the metadata attached to that edge\n",
    "\n",
    "# Pandas and graphs\n",
    "```python\n",
    "G.nodes(data=True)\n",
    "\n",
    "nodelist = []\n",
    "\n",
    "for n, d in G.nodes(data=True):\n",
    "    node_data = dict()\n",
    "    node_data['node'] = n\n",
    "    node_data.update(d)\n",
    "    nodelist.append(node_data)\n",
    "    \n",
    "nodelist\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(nodelist)\n",
    "\n",
    "pd.DataFrame(nodelist).to_csv('my_file.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store each edge as a record: nodelist\n",
    "nodelist = []\n",
    "for n, d in G_people.nodes(data=True):\n",
    "    # nodeinfo stores one \"record\" of data as a dict\n",
    "    nodeinfo = {'person': n} \n",
    "    \n",
    "    # Update the nodeinfo dictionary \n",
    "    nodeinfo.update(d)\n",
    "    \n",
    "    # Append the nodeinfo to the node list\n",
    "    nodelist.append(nodeinfo)\n",
    "    \n",
    "\n",
    "# Create a pandas DataFrame of the nodelist: node_df\n",
    "node_df = pd.DataFrame(nodelist)\n",
    "print(node_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store each edge as a record: edgelist\n",
    "edgelist = []\n",
    "for n1, n2, d in G_people.edges(data=True):\n",
    "    # Initialize a dictionary that shows edge information: edgeinfo\n",
    "    edgeinfo = {'node1':n1, 'node2':n2}\n",
    "    \n",
    "    # Update the edgeinfo data with the edge metadata\n",
    "    edgeinfo.update(d)\n",
    "    \n",
    "    # Append the edgeinfo to the edgelist\n",
    "    edgelist.append(edgeinfo)\n",
    "    \n",
    "# Create a pandas DataFrame of the edgelist: edge_df\n",
    "edge_df = pd.DataFrame(edgelist)\n",
    "print(edge_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to graph differences\n",
    "## Time series analysis\n",
    "- How some number changes as a function of time\n",
    "    - Is there an upward or downward trend?\n",
    "- Rate of change of things over a sliding window of time\n",
    "- Examples:\n",
    "    - Track weight over time\n",
    "    - Track stock investment portfolio value over time\n",
    "    \n",
    "# Evolving graphs\n",
    "- Graphs that change over time: communication networks\n",
    "- Assumptions:\n",
    "    - Edge changes over time; assume nodes stay constant\n",
    "        - This becomes easier to analyze moving forward\n",
    "    - Both edges and nodes change over time\n",
    "\n",
    "# Graph differences\n",
    "- Graphs are comprised of:\n",
    "    - A node set\n",
    "    - An edge set\n",
    "- If a node set doesn't change:\n",
    "    - Changing only the edge set will result in a change in the graph\n",
    "- Analogy: set differences\n",
    "\n",
    "```python\n",
    "set(c1, c2, c3).difference(set(c2, c3, c4)) = set(c1)\n",
    "set(c2, c3, c4).difference(set(c1, c2, c3)) = set(c4)\n",
    "```\n",
    "\n",
    "- In NetworkX: `.difference(G1, G2)` function\n",
    "    - Assumes `G1` and `G2` have equal node sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "\n",
    "months = range(4, 11)\n",
    "\n",
    "# Initialize an empty list: Gs\n",
    "Gs = [] \n",
    "for month in months:\n",
    "    # Instantiate a new undirected graph: G\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add in all nodes that have ever shown up to the graph\n",
    "    G.add_nodes_from(data['sender'])\n",
    "    G.add_nodes_from(data['recipient'])\n",
    "    \n",
    "    # Filter the DataFrame so that there's only the given month\n",
    "    df_filtered = data[data['month'] == month]\n",
    "    \n",
    "    # Add edges from filtered DataFrame\n",
    "    G.add_edges_from(zip(df_filtered['sender'], df_filtered['recipient']))\n",
    "    \n",
    "    # Append G to the list of graphs\n",
    "    Gs.append(G)\n",
    "    \n",
    "print(len(Gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx  \n",
    "# Instantiate a list of graphs that show edges added: added\n",
    "added = []\n",
    "# Instantiate a list of graphs that show edges removed: removed\n",
    "removed = []\n",
    "# Here's the fractional change over time\n",
    "fractional_changes = []\n",
    "window = 1  \n",
    "i = 0      \n",
    "\n",
    "for i in range(len(Gs) - window):\n",
    "    g1 = Gs[i]\n",
    "    g2 = Gs[i + window]\n",
    "        \n",
    "    # Compute graph difference here\n",
    "    added.append(nx.difference(g2, g1))   \n",
    "    removed.append(nx.difference(g1, g2))\n",
    "    \n",
    "    # Compute change in graph size over time\n",
    "    fractional_changes.append((len(g2.edges()) - len(g1.edges())) / len(g1.edges()))\n",
    "    \n",
    "# Print the fractional change\n",
    "print(fractional_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "# Plot the number of edges added over time\n",
    "edges_added = [len(g.edges()) for g in added]\n",
    "plot1 = ax1.plot(edges_added, label='added', color='orange')\n",
    "\n",
    "# Plot the number of edges removed over time\n",
    "edges_removed = [len(g.edges()) for g in removed]\n",
    "plot2 = ax1.plot(edges_removed, label='removed', color='purple')\n",
    "\n",
    "# Set yscale to logarithmic scale\n",
    "ax1.set_yscale('log')  \n",
    "ax1.legend()\n",
    "\n",
    "# 2nd axes shares x-axis with 1st axes object\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot the fractional changes over time\n",
    "plot3 = ax2.plot(fractional_changes, label='fractional change', color='green')\n",
    "\n",
    "# Here, we create a single legend for both plots\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines1 + lines2, labels1 + labels2, loc=0)\n",
    "plt.axhline(0, color='green', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving graph statistics\n",
    "## Graph summary statistics:\n",
    "- Number of nodes\n",
    "- Number of edges\n",
    "- Degree distribution\n",
    "- Centality distribution\n",
    "\n",
    "- For simple metrics, use edgelist data\n",
    "- For graph theoretic metrics, use graph object\n",
    "\n",
    "# Cumulative distribution\n",
    "- Compact way of representing the distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# Create a list of the number of edges per month\n",
    "edge_sizes = [len(g.edges()) for g in Gs]\n",
    "\n",
    "# Plot edge sizes over time\n",
    "plt.plot(edge_sizes)\n",
    "plt.xlabel('Time elapsed from first month (in months).') \n",
    "plt.ylabel('Number of edges')                           \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a list of degree centrality scores month-by-month\n",
    "cents = []\n",
    "for G in Gs:\n",
    "    cent = nx.degree_centrality(G)\n",
    "    cents.append(cent)\n",
    "\n",
    "\n",
    "# Plot ECDFs over time\n",
    "fig = plt.figure()\n",
    "for i in range(len(cents)):\n",
    "    x, y = ECDF(cents[i].values()) \n",
    "    plt.plot(x, y, label='Month {0}'.format(i+1)) \n",
    "plt.legend()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zooming in and out: Overall graph summary\n",
    "\n",
    "## Graph exploration at scales\n",
    "- Exploration at global and local scales\n",
    "- Global: Centrality distributions\n",
    "- Local: Connectivity and structures\n",
    "\n",
    "# Zooming on modes\n",
    "- Isolate a given node or set of nodes\n",
    "- Plot node statistics over time\n",
    "\n",
    "# Summarizing evolving node statistics\n",
    "- Customer-product dataset\n",
    "    - Investigate how purchasing patterns have changed over time\n",
    "- `customer1` - node of interest\n",
    "\n",
    "```python\n",
    "Gs = [....]\n",
    "noi = 'customer1'\n",
    "degs = []\n",
    "\n",
    "for g in Gs:\n",
    "    # Get the degree of the node\n",
    "    degs.append(len(g.neighbors(noi)))\n",
    "plt.plot(degs)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "# Default dictionaries\n",
    "\n",
    "```python\n",
    "from collections import defaultdict\n",
    "d = defaultdict(list)\n",
    "d['heathrow'].append(0.31)\n",
    "d['heathrow'].append(0.84)\n",
    "\n",
    "d\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 unique degree centrality scores: top_dcs\n",
    "top_dcs = sorted(set(nx.degree_centrality(G).values()), reverse=True)[:5]\n",
    "\n",
    "# Create list of nodes that have the top 5 highest overall degree centralities\n",
    "top_connected = []\n",
    "for n, dc in nx.degree_centrality(G).items():\n",
    "    if dc in top_dcs:\n",
    "        top_connected.append(n)\n",
    "        \n",
    "# Print the number of nodes that share the top 5 degree centrality scores\n",
    "print(len(top_connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Create a defaultdict in which the keys are nodes and the values are a list of connectivity scores over time\n",
    "connectivity = defaultdict(list)\n",
    "for n in top_connected:\n",
    "    for g in Gs:\n",
    "        connectivity[n].append(len(g.neighbors(n)))\n",
    "\n",
    "# Plot the connectivity for each node\n",
    "fig = plt.figure() \n",
    "for n, conn in connectivity.items(): \n",
    "    plt.plot(conn, label=n) \n",
    "plt.legend()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the case study\n",
    "## College forum posting dataset\n",
    "- Node partitions: students, forums\n",
    "- Activities in the chapter:\n",
    "    - Constructing a graph from a pandas DataFrame\n",
    "    - Computing unipartite projections of a bipartite graph\n",
    "    - Visualization\n",
    "    - Time series filtering & analysis\n",
    "- Recap previously used functions\n",
    "\n",
    "# Graphs from DataFrames\n",
    "```python\n",
    "df   # Our pandas DataFrame\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(df['products'], bipartite='products')\n",
    "G.add_nodes_from(df['customers'], bipartite='customers')\n",
    "\n",
    "G.nodes()\n",
    "\n",
    "G.edges() # Just a sanity check to ensure the list is empty\n",
    "```\n",
    "\n",
    "# Import edges\n",
    "```python\n",
    "G.add_edges_from(zip(df['customers'], df['products']))\n",
    "\n",
    "G.edges()\n",
    "```\n",
    "\n",
    "# Bipartite projections\n",
    "```python\n",
    "cust_nodes = [n for n in G.nodes() if G.node[n]['bipartite'] == 'customers']\n",
    "\n",
    "prod_nodes = [n for n in G.nodes() if G.node[n]['bipartite'] == 'products']\n",
    "\n",
    "prodG = nx.bipartite.projected_graph(G, nodes=prod_nodes)\n",
    "\n",
    "custG = nx.bipartite.projected_graph(G, nodes=cust_nodes)\n",
    "\n",
    "prodG.nodes()\n",
    "\n",
    "custG.nodes() # Ensure the correct node partition\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Instantiate a new Graph: G\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes from each of the partitions\n",
    "G.add_nodes_from(data['student'], bipartite='student')\n",
    "G.add_nodes_from(data['forum'], bipartite='forum')\n",
    "\n",
    "# Add in each edge along with the date the edge was created\n",
    "for r, d in data.iterrows():\n",
    "    G.add_edge(d['student'], d['forum'], date=d['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Get the student partition's nodes: student_nodes\n",
    "student_nodes = [n for n, d in G.nodes(data=True) if d['bipartite'] == 'student']\n",
    "\n",
    "# Create the students nodes projection as a graph: G_students\n",
    "G_students = nx.bipartite.projected_graph(G, nodes=student_nodes)\n",
    "\n",
    "# Calculate the degree centrality using nx.degree_centrality: dcs\n",
    "dcs = nx.degree_centrality(G_students)\n",
    "\n",
    "# Plot the histogram of degree centrality values\n",
    "plt.hist(list(dcs.values()))\n",
    "plt.yscale('log')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx\n",
    "\n",
    "# Get the forums partition's nodes: forum_nodes\n",
    "forum_nodes = [n for n, d in G.nodes(data=True) if d['bipartite'] == 'forum']\n",
    "\n",
    "# Create the forum nodes projection as a graph: G_forum\n",
    "G_forum = nx.bipartite.projected_graph(G, nodes=forum_nodes)\n",
    "\n",
    "# Calculate the degree centrality using nx.degree_centrality: dcs\n",
    "dcs = nx.degree_centrality(G_forum)\n",
    "\n",
    "# Plot the histogram of degree centrality values\n",
    "plt.hist(list(dcs.values()))\n",
    "plt.yscale('log') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time based filtering\n",
    "- Filtering\n",
    "- Datetime module\n",
    "- Visualization\n",
    "\n",
    "# Filtering edges\n",
    "```python\n",
    "[(u, v) for u, v, d in G.edges(data=True) if d['sale_count'] >= 10]\n",
    "```\n",
    "\n",
    "# Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "year = 2011\n",
    "month = 11\n",
    "day1 = 10\n",
    "day2 = 6\n",
    "\n",
    "date1 = datetime(year, month, day1)\n",
    "date2 = datetime(year, month, day2)\n",
    "\n",
    "date1 > date2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph visualization\n",
    "```python\n",
    "from nxviz import CircosPlot\n",
    "\n",
    "c = CircosPlot(G, node_grouping='bipartite', node_color='bipartite')\n",
    "\n",
    "c.draw()\n",
    "\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "\n",
    "# Instantiate a new graph: G_sub\n",
    "G_sub = nx.Graph()\n",
    "\n",
    "# Add nodes from the original graph\n",
    "G_sub.add_nodes_from(G.nodes(data=True))\n",
    "\n",
    "# Add edges using a list comprehension with one conditional on the edge dates, that the date of the edge is earlier than 2004-05-16.\n",
    "G_sub.add_edges_from([(u, v, d) for u, v, d in G.edges(data=True) if d['date'] < datetime(2004,5,16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from nxviz import CircosPlot\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute degree centrality scores of each node\n",
    "dcs = nx.bipartite.degree_centrality(G, nodes=forum_nodes)\n",
    "for n, d in G_sub.nodes(data=True):\n",
    "    G_sub.node[n]['dc'] = dcs[n]\n",
    "\n",
    "# Create the CircosPlot object: c\n",
    "c = CircosPlot(G_sub, node_grouping='bipartite', node_color='bipartite', node_order='dc')\n",
    "\n",
    "# Draw c to screen\n",
    "c.draw()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series analysis\n",
    "- Global vs. local analysis\n",
    "- Analyze evolving graph statistics\n",
    "- Make plots of key evolving stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 11, 10, 0, 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 11, 14, 0, 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = 4\n",
    "\n",
    "td = timedelta(days)\n",
    "\n",
    "date1 + td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from datetime import timedelta  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define current day and timedelta of 2 days\n",
    "curr_day = dayone\n",
    "td = timedelta(days=2)\n",
    "\n",
    "# Initialize an empty list of posts by day\n",
    "n_posts = []\n",
    "while curr_day < lastday:\n",
    "    if curr_day.day == 1:\n",
    "        print(curr_day) \n",
    "    # Filter edges such that they are within the sliding time window: edges\n",
    "    edges = [(u, v, d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td]\n",
    "    \n",
    "    # Append number of edges to the n_posts list\n",
    "    n_posts.append(len(edges))\n",
    "    \n",
    "    # Increment the curr_day by the time delta\n",
    "    curr_day += td\n",
    "    \n",
    "# Create the plot\n",
    "plt.plot(n_posts)  \n",
    "plt.xlabel('Days elapsed')\n",
    "plt.ylabel('Number of posts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize a new list: mean_dcs\n",
    "mean_dcs = []\n",
    "curr_day = dayone\n",
    "td = timedelta(days=2)\n",
    "\n",
    "while curr_day < lastday:\n",
    "    if curr_day.day == 1:\n",
    "        print(curr_day)  \n",
    "    # Instantiate a new graph containing a subset of edges: G_sub\n",
    "    G_sub = nx.Graph()\n",
    "    # Add nodes from G\n",
    "    G_sub.add_nodes_from(G.nodes(data=True))\n",
    "    # Add in edges that fulfill the criteria\n",
    "    G_sub.add_edges_from([(u, v, d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td])\n",
    "    \n",
    "    # Get the students projection\n",
    "    G_student_sub = nx.bipartite.projected_graph(G_sub, nodes=student_nodes)\n",
    "    # Compute the degree centrality of the students projection\n",
    "    dc = nx.degree_centrality(G_student_sub)\n",
    "    # Append mean degree centrality to the list mean_dcs\n",
    "    mean_dcs.append(np.mean(list(dc.values())))\n",
    "    # Increment the time\n",
    "    curr_day += td\n",
    "    \n",
    "plt.plot(mean_dcs)\n",
    "plt.xlabel('Time elapsed')\n",
    "plt.ylabel('Degree centrality.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from datetime import timedelta\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "most_popular_forums = []\n",
    "highest_dcs = []\n",
    "curr_day = dayone \n",
    "td = timedelta(days=1)  \n",
    "\n",
    "while curr_day < lastday:  \n",
    "    if curr_day.day == 1:  \n",
    "        print(curr_day)  \n",
    "    G_sub = nx.Graph()\n",
    "    G_sub.add_nodes_from(G.nodes(data=True))   \n",
    "    G_sub.add_edges_from([(u, v, d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td])\n",
    "    \n",
    "    # Get the degree centrality \n",
    "    dc = nx.bipartite.degree_centrality(G_sub, nodes=forum_nodes)\n",
    "    # Filter the dictionary such that there's only forum degree centralities\n",
    "    forum_dcs = {n:dc for n, dc in dc.items() if n in forum_nodes}\n",
    "    # Identify the most popular forum(s) \n",
    "    most_popular_forum = [n for n, dc in dc.items() if dc == max(forum_dcs.values()) and dc != 0] \n",
    "    most_popular_forums.append(most_popular_forum) \n",
    "    # Store the highest dc values in highest_dcs\n",
    "    highest_dcs.append(max(forum_dcs.values()))\n",
    "    \n",
    "    curr_day += td  \n",
    "    \n",
    "plt.figure(1) \n",
    "plt.plot([len(forums) for forums in most_popular_forums], color='blue', label='Forums')\n",
    "plt.ylabel('Number of Most Popular Forums')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(highest_dcs, color='orange', label='DC Score')\n",
    "plt.ylabel('Top Degree Centrality Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On a per-day basis, it would be interesting to see which forums were the most popular over time. Some further questions might include - was it the same set over time? Or were some forums really popular early on and others popular later on?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
