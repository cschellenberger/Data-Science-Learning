{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning\n",
    "## [DataCamp Course Dashboard](https://www.datacamp.com/courses/deep-learning-in-python)\n",
    "\n",
    "### Imagine you work for a bank\n",
    "- You need to predict how many transactions each customer will make next year\n",
    "- You have features like `age`, `bank_balance`, `retirement_status`, etc.\n",
    "\n",
    "#### How would a linear regression model work through this problem?\n",
    "- The LR model would look at the influence of each feature individually and not the interactions between the features. This is not ideal from an intutive standpoint.\n",
    "\n",
    "# Interactions\n",
    "- Neural networks account for interactions really well\n",
    "- Deep learning uses especially powerful neural networks\n",
    "\n",
    "# Course structure\n",
    "- First two chapters focus on conceptual knowledge\n",
    "    - Debug and tune deep learning models on conventional prediction problems\n",
    "    - Lay the foundation for progressing towards modern applications\n",
    "    \n",
    "## Build deep learning models with keras\n",
    "```python\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "predictors = np.loadtxt('predictors_data.csv', delimiter=',')\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "```\n",
    "\n",
    "## Deep learning models capture interactions\n",
    "- We generate a function that describes the interaction of variables and use that function to predict the outcome of the response variable.\n",
    "- The input layer describes our predictive features (`age`, `bank_balance`, `retirement_status`, etc)\n",
    "- The output layer describes our response variable or what we want to predict.\n",
    "- All other layers are called the hidden layers because these are non-empirical values that are calculated by the model to account for the interaction between variables in the input layer and more accurately predict the output layer.\n",
    "\n",
    "# Forward propagation\n",
    "- First step of the **forward propagation algorithm** is to draw lines between the input layer and the nodes of the hidden layer.\n",
    "- Each line is given a weight to account for the strength of that interaction.\n",
    "- Next, each input layer value is multiplied by its line weight and added to all other input layer calculations corresponding to that node.\n",
    "- This process to repeated to draw lines, assign weights, and apply calculations to yeild the output layer value.\n",
    "\n",
    "    - Multiply - add process\n",
    "    - Dot product\n",
    "    - Forward propagation for one data point at a time\n",
    "    - Output is the prediction for that data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer values:  [5 1]\n",
      "output value:  9\n"
     ]
    }
   ],
   "source": [
    "# Forward propagation code\n",
    "\n",
    "import numpy as np\n",
    "input_data = np.array([2, 3])\n",
    "weights = {'node_0': np.array([1, 1]),\n",
    "          'node_1': np.array([-1, 1]),\n",
    "          'output': np.array([2, -1])}\n",
    "node_0_value = (input_data * weights['node_0']).sum()\n",
    "node_1_value = (input_data * weights['node_1']).sum()\n",
    "\n",
    "hidden_layer_values = np.array([node_0_value, node_1_value])\n",
    "print('hidden layer values: ', hidden_layer_values)\n",
    "\n",
    "output = (hidden_layer_values * weights['output']).sum()\n",
    "print('output value: ', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-39\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array([3, 5])\n",
    "weights = {'node_0': np.array([2, 4]), \n",
    "           'node_1': np.array([ 4, -5]), \n",
    "           'output': np.array([2, 7])}\n",
    "\n",
    "# Calculate node 0 value: node_0_value\n",
    "node_0_value = (input_data * weights['node_0']).sum()\n",
    "\n",
    "# Calculate node 1 value: node_1_value\n",
    "node_1_value = (input_data * weights['node_1']).sum()\n",
    "\n",
    "# Put node values into array: hidden_layer_outputs\n",
    "hidden_layer_outputs = np.array([node_0_value, node_1_value])\n",
    "\n",
    "# Calculate output: output\n",
    "output = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "# Print output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions\n",
    "\n",
    "- These functions allow the model to capture nonlinearities.\n",
    "- Applied to node inputs to produce node output\n",
    "- `tanh()` was a very popular activation function\n",
    "- Today, ReLU (Rectified Linear Activation) is the industry standard activation function\n",
    "$$RELU(x) = \\left\\{\\begin{matrix}\n",
    "0 \\text{ if } x<0\\\\ \n",
    "x \\text{ if } x\\geq 0\n",
    "\\end{matrix}\\right.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer outputs:  [0.99505475 0.99999997]\n",
      "output value:  0.9901095378334199\n"
     ]
    }
   ],
   "source": [
    "# Activation function code\n",
    "\n",
    "import numpy as np\n",
    "input_data = np.array([-1, 2])\n",
    "weights = {'node_0': np.array([3, 3]),\n",
    "          'node_1': np.array([1, 5]),\n",
    "          'output': np.array([2, -1])}\n",
    "node_0_input = (input_data * weights['node_0']).sum()\n",
    "\n",
    "node_0_output = np.tanh(node_0_input)\n",
    "\n",
    "node_1_input = (input_data * weights['node_1']).sum()\n",
    "\n",
    "node_1_output = np.tanh(node_1_input)\n",
    "\n",
    "hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "print('hidden layer outputs: ', hidden_layer_outputs)\n",
    "\n",
    "output = (hidden_layer_outputs * weights['output']).sum()\n",
    "print('output value: ', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rectified linear activation function (called ReLU) has been shown to lead to very high-performance networks. This function takes a single number as an input, returning 0 if the input is negative, and the input if the input is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output layer value: 52 \n",
      "Without the activation function, this prediction would be negative.\n"
     ]
    }
   ],
   "source": [
    "def relu(input):\n",
    "    '''Define your relu activation function here'''\n",
    "    # Calculate the value for the output of the relu function: output\n",
    "    output = max(input, 0)\n",
    "    \n",
    "    # Return the value just calculated\n",
    "    return(output)\n",
    "\n",
    "input_data = np.array([3, 5])\n",
    "weights = {'node_0': np.array([2, 4]), \n",
    "           'node_1': np.array([ 4, -5]), \n",
    "           'output': np.array([2, 7])}\n",
    "\n",
    "# Calculate node 0 value: node_0_output\n",
    "node_0_input = (input_data * weights['node_0']).sum()\n",
    "node_0_output = relu(node_0_input)\n",
    "\n",
    "# Calculate node 1 value: node_1_output\n",
    "node_1_input = (input_data * weights['node_1']).sum()\n",
    "node_1_output = relu(node_1_input)\n",
    "\n",
    "# Put node values into array: hidden_layer_outputs\n",
    "hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "\n",
    "# Calculate model output (do not apply relu)\n",
    "model_output = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "# Print model output\n",
    "print('output layer value:', model_output, '\\nWithout the activation function, \\\n",
    "this prediction would be negative.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52, 63, 0, 148]\n"
     ]
    }
   ],
   "source": [
    "input_data = [np.array([3, 5]), np.array([ 1, -1]), np.array([0, 0]), np.array([8, 4])]\n",
    "weights = {'node_0': np.array([2, 4]), \n",
    "           'node_1': np.array([ 4, -5]), \n",
    "           'output': np.array([2, 7])}\n",
    "\n",
    "# Define predict_with_network()\n",
    "def predict_with_network(input_data_row, weights):\n",
    "\n",
    "    # Calculate node 0 value\n",
    "    node_0_input = (input_data_row * weights['node_0']).sum()\n",
    "    node_0_output = relu(node_0_input)\n",
    "\n",
    "    # Calculate node 1 value\n",
    "    node_1_input = (input_data_row * weights['node_1']).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_layer_outputs\n",
    "    hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "    \n",
    "    # Calculate model output\n",
    "    input_to_final_layer = (hidden_layer_outputs * weights['output']).sum()\n",
    "    model_output = relu(input_to_final_layer)\n",
    "    \n",
    "    # Return model output\n",
    "    return(model_output)\n",
    "\n",
    "\n",
    "# Create empty list to store prediction results\n",
    "results = []\n",
    "for input_data_row in input_data:\n",
    "    # Append prediction to results\n",
    "    results.append(predict_with_network(input_data_row, weights))\n",
    "\n",
    "# Print results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeper networks\n",
    "## Multiple hidden layers\n",
    "## Representation learning\n",
    "- Deep networks internally build representations of patterns in the data.\n",
    "- Partially replace the need for feature engineering\n",
    "- Subsequent layers build increasingly sophisticated representations of raw data\n",
    "\n",
    "# Deep learning\n",
    "- Modeler doesn't need to specify the interactions\n",
    "- When you train the model, the neural network gets weights that find the relevant patterns to make better predictions\n",
    "\n",
    "*Identity function* - each node's output will be the same as its input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output value is: 182\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array([3, 5])\n",
    "weights = {'node_0_0': np.array([2, 4]),\n",
    "           'node_0_1': np.array([ 4, -5]),\n",
    "           'node_1_0': np.array([-1,  2]),\n",
    "           'node_1_1': np.array([1, 2]),\n",
    "           'output': np.array([2, 7])}\n",
    "\n",
    "def predict_with_network(input_data):\n",
    "    # Calculate node 0 in the first hidden layer\n",
    "    node_0_0_input = (input_data * weights['node_0_0']).sum()\n",
    "    node_0_0_output = relu(node_0_0_input)\n",
    "\n",
    "    # Calculate node 1 in the first hidden layer\n",
    "    node_0_1_input = (input_data * weights['node_0_1']).sum()\n",
    "    node_0_1_output = relu(node_0_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_0_outputs\n",
    "    hidden_0_outputs = np.array([node_0_0_output, node_0_1_output])\n",
    "    \n",
    "    # Calculate node 0 in the second hidden layer\n",
    "    node_1_0_input = (hidden_0_outputs * weights['node_1_0']).sum()\n",
    "    node_1_0_output = relu(node_1_0_input)\n",
    "\n",
    "    # Calculate node 1 in the second hidden layer\n",
    "    node_1_1_input = (hidden_0_outputs * weights['node_1_1']).sum()\n",
    "    node_1_1_output = relu(node_1_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_1_outputs\n",
    "    hidden_1_outputs = np.array([node_1_0_output, node_1_1_output])\n",
    "\n",
    "    # Calculate model output: model_output\n",
    "    model_output = (hidden_1_outputs * weights['output']).sum()\n",
    "    \n",
    "    # Return model_output\n",
    "    return(model_output)\n",
    "\n",
    "output = predict_with_network(input_data)\n",
    "print('The output value is:', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The need for optimization\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
